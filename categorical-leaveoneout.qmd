---
pagetitle: "Feature Engineering A-Z | Leave One Out Encoding"
---

# Leave One Out Encoding {#sec-categorical-leave-one-out}

::: {style="visibility: hidden; height: 0px;"}
## Leave One Out Encoding
:::

Leave One Out Encoding, is a variation on [target encoding](@sec-categorical-target).
Where target encoding takes the mean of all rows within each target level, it instead excludes the value of the current row.

One of the main downsides to this approach is that since it needs the target which is most often the outcome and such not available for the test data set, it will thus not be able to do the row-wise adjustment and will behave exactly as the target encoding for the test data set.

What this does in practice is that it shifts the influence of outliers within each level away from the whole group and onto the outlier itself.
Consider a level that has the following target values `100, 10, 6, 5, 3, 8`.
The target encoded value would be `22` and the leave one out values would be different, but the most different one is the outlier at 100.

```{r}
#| label: example
#| echo: false
#| message: false
library(tidyverse)

tibble(
 values = c(100, 10, 6, 5, 3, 8)
) |>
  mutate(target = mean(values)) |>
  mutate(`leave one out` = (sum(values) - values) / (n() - 1)) |>
  knitr::kable()
```

Thus we have that target encoding is influenced differently than leave one out encoding is.
Which type of influence is better is up to you, the practitioner to determine based on your data and modeling problem.

## Pros and Cons

### Pros

-   Doesn't hide the effort of outliers as compared to target encoding.
-   Can deal with categorical variables with many levels
-   Can deal with unseen levels in a sensible way

### Cons

-   Only have a meaningful difference compared to target encoding to training data set.
-   Can be prone to overfitting

## R Examples

Has not yet been implemented. 

See <https://github.com/EmilHvitfeldt/feature-engineering-az/issues/40> for progress.

## Python Examples

```{python}
#| label: python-setup
#| echo: false
import pandas as pd
from sklearn import set_config

set_config(transform_output="pandas")
pd.set_option('display.precision', 3)
```

We are using the `ames` data set for examples.
{category_encoders} provided the `LeaveOneOutEncoder()` method we can use.
For this to work, we need to remember to specify an outcome when we `fit()`.

```{python}
#| label: leaveoneoutencoder
from feazdata import ames
from sklearn.compose import ColumnTransformer
from category_encoders.leave_one_out import LeaveOneOutEncoder

from sklearn.preprocessing import TargetEncoder

ct = ColumnTransformer(
    [('loo', LeaveOneOutEncoder(), ['Neighborhood'])], 
    remainder="passthrough")

ct.fit(ames, y=ames[["Sale_Price"]].values.flatten())
ct.transform(ames).filter(regex="loo.*")
```
