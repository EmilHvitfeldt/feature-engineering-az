# Manual Text Features {#sec-text-manual}

When talking about manual text features, we are talking about hand-crafted metrics or counts based on the text. you will be able to find some off-the-shelf features that fit into this category. But generally, this is where you can use your domain knowledge to extract useful information.

Typical of-the-shelf counts are generally counted. So it will be counts of words, sentences, linebreaks, commas, hashtags, emojis, and punctuation. A lot of these will be proxies for text length so some kind of normalization will be useful here. Normalizing in this setting is typically done by dividing by the text length, which then gives different interpretations as we are no longer looking at the "number of words", and now finding "the inverse of average word length".

The above features are easy to calculate and will therefore not be hard to include in your model. But this is where creativity and domain knowledge shine!

TODO: find a good reference for "What is a word?"

One thing you might need to do when working with these hand-crafted features is knowledge about working with *regular expressions*.

## Pros and Cons

### Pros

- Clear and actionable features
- High interpretability

### Cons

- Can be time-consuming to create
- Computational speed depends on the feature
- Will likely need to 

## R Examples

TODO: find a better data set

The [textfeatures]() package is one package in R that contains a bunch of general features that may or may not be useful.

```{r}
#| message: false
library(textfeatures)
library(modeldata)

textfeatures(modeldata::tate_text$medium, word_dims = 0) |>
  dplyr::glimpse()
```

TODO: Come up with domain-specific examples

## Python Examples

