[
  {
    "objectID": "missing.html",
    "href": "missing.html",
    "title": "41¬† Missing Overview",
    "section": "",
    "text": "41.1 Missing Overview",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Missing Overview</span>"
    ]
  },
  {
    "objectID": "missing.html#imputation",
    "href": "missing.html#imputation",
    "title": "41¬† Missing Overview",
    "section": "41.2 Imputation",
    "text": "41.2 Imputation\nOne of the most common ways of dealing with missing values is to fill them in with some values. The types of methods that do this can be split into two groups. Simple imputation in Chapter 42 is when you use the values in the variable to impute its missing values, which is where mean and mode imputation are found. Anything more complicated than this will be found in Chapter 43. This is where multiple columns are used to determine the type of imputation needed.",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Missing Overview</span>"
    ]
  },
  {
    "objectID": "missing.html#indication",
    "href": "missing.html#indication",
    "title": "41¬† Missing Overview",
    "section": "41.3 Indication",
    "text": "41.3 Indication\nIf you suspect that the data is not missing at random, it might be worthwhile to include the missingness as an indicator in your data. We will see how we can do that in Chapter 44.",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Missing Overview</span>"
    ]
  },
  {
    "objectID": "missing.html#removal",
    "href": "missing.html#removal",
    "title": "41¬† Missing Overview",
    "section": "41.4 Removal",
    "text": "41.4 Removal\nAs a last resort, you might want to remove variables or rows with missing data, we will see how that is done in Chapter 45. This chapter is put last in this section, as it is generally not the preferred action, and all other avenues should be considered before removal is done.\n\n\n\n\nRUBIN, DONALD B. 1976. ‚ÄúInference and missing data.‚Äù Biometrika 63 (3): 581‚Äì92. https://doi.org/10.1093/biomet/63.3.581.",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Missing Overview</span>"
    ]
  },
  {
    "objectID": "missing.html#footnotes",
    "href": "missing.html#footnotes",
    "title": "41¬† Missing Overview",
    "section": "",
    "text": "Optical Character Recognition is used to extract text from images.‚Ü©Ô∏é",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>41</span>¬† <span class='chapter-title'>Missing Overview</span>"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Introduction",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#how-to-deal-with",
    "href": "introduction.html#how-to-deal-with",
    "title": "Introduction",
    "section": "How to Deal With ‚Ä¶",
    "text": "How to Deal With ‚Ä¶\nThis book is structured according to the types of data and problems you will encounter. Each section specifies a type of data or problem, and each chapter details a method or group of methods that can be useful in dealing with that type. So for example 1¬† Numeric Overview contains methods that deal with numeric variables such as 2¬† Logarithms and 9¬† Max Abs, and 14¬† Categorical Overview contains methods that deal with categorical variables such as 17¬† Dummy Encoding and 23¬† Hashing Encoding. There should be sections and chapters for most methods you will find in practice that aren‚Äôt too domain-specific.\nIt is because of this structure that this book is most suited as reference material, each time you encounter some data you are unsure how to deal with, you find the corresponding section and study the methods listed to see which would be best for your use case. This isn‚Äôt to say that you can‚Äôt read this book from end to end. The sections have been ordered roughly such that earlier chapters are broadly useful and later chapters touch on less used data types and problems.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#sec-modeling",
    "href": "introduction.html#sec-modeling",
    "title": "Introduction",
    "section": "Where does feature engineering fit into the modeling workflow?",
    "text": "Where does feature engineering fit into the modeling workflow?\nWhen we talk about the modeling workflow, it starts at the data source and ends with a fitted model. The fitted model in this instance should be created such that it can be used for the downstream task, be it inference or prediction.\n\n\n\n\n\n\nInference and Prediction\n\n\n\nIn some data science organizations, the term ‚Äúinference‚Äù is frequently used interchangeably with ‚Äúprediction,‚Äù denoting the process of generating prediction outputs from a trained model. However, in this book, we will use ‚Äúinference‚Äù specifically to refer to statistical inference, which involves drawing conclusions about populations or scientific truths from data analysis.\n\n\nWe want to make sure that the feature engineering methods we are applying are done correctly to avoid problems with the modeling. Things we especially want to avoid are data leakage, overfitting, and high computational cost.\n\n\n\n\n\n\nTODO\n\n\n\nAdd diagram of modeling workflow from data source to model\n\n\nWhen applying feature engineering methods, we need to think about trained and untrained methods. Trained methods will perform a calculation doing the training of the method, and then using the extracted values to perform the transformation again. We see this in 7¬† Normalization, where we explore centering. To implement centering, we adjust each variable by subtracting its mean value, computed using the training dataset. Since this value needs to be calculated, it becomes a trained method. Examples of untrained methods are logarithmic transformation as seen in 2¬† Logarithms and datetime value extraction as seen in 38¬† Value Extraction. These methods are static in nature, meaning their execution can be applied at the observation-level without parameter-level inferences.\nIn practice, this means that untrained methods can be applied before the data-splitting procedure, as it would give the same results regardless of when it was done. Trained methods have to be performed after the data-splitting to ensure you don‚Äôt have data leakage. The wrinkle to this is that untrained methods applied to variables that have already been transformed by a trained method will have to also be done after the data-splitting.\n\n\n\n\n\n\nTODO\n\n\n\nadd a diagram for untrained/trained rule\n\n\nSome untrained methods have a high computational cost, such as BERT from 60¬† üèóÔ∏è BERT. If you are unsure about when to apply a feature engineering method, a general rule of thumb that errs on the side of caution is to apply the method after the data-splitting procedure.\nIn the examples of this book, we will show how to perform methods and techniques using {recipes} on the R side, as they can be used together with the rest of tidymodels to make sure the calculations are done correctly. On the Python side, we show the methods by using transformers, that should then be used inside a sklearn.pipeline.Pipeline() to make sure the calculations are done correctly.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#why-do-we-use-thresholds",
    "href": "introduction.html#why-do-we-use-thresholds",
    "title": "Introduction",
    "section": "Why do we use thresholds?",
    "text": "Why do we use thresholds?\nOftentimes, when we use a method that selects something with a quantity, we end up doing it with a threshold instead of counting directly. The answer to this is purely practical, as it leaves less ambiguity. When selecting these features to keep in a feature selection routine 65¬† Too Many Overview is a good example. It is easier to write the code that selects every feature that has more than X amount of variability. On the other hand, if we said ‚ÄúGive me the 25 most useful features‚Äù, we might have 4 variables tied for 25th place. Now we have another problem. Does it keep all of them in, leaving 28 variables? If we do that, we violate our request of 25 variables. What if we select the first? Then we arbitrarily give a bias towards variables early in the data set. What if we randomly select among the ties? Then we introduce randomness into the method.\nIt is for the above reasons that many methods in feature engineering and machine learning use thresholds instead of precise numbers.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#sec-terminology",
    "href": "introduction.html#sec-terminology",
    "title": "Introduction",
    "section": "Terminology",
    "text": "Terminology\nBelow are some terminology clarifications since the term usage in this book may differ from other books. When a method is known by multiple names, the additional name(s) will be listed at the beginning of each chapter. The index will likewise point you to the right chapter regardless of which name you use.\n\nEDA\nOtherwise known as exploratory data analysis is the part of the modeling process where you look at the data very carefully. This will be done in part using descriptive statistics and visualization. This should be done after splitting the data, and only on the training data set. A project may be scraped at this stage due to the limited usefulness of the data. Spending a lot of time in EDA is almost always fruitful as you gain insight into how to use and transform the data best with feature engineering methods.\n\n\nObservations\nThis book will mostly be working with rectangular data. In this context, each observation is defined as a row, with the columns holding the specific characteristics for each observation.\nThe observational unit can change depending on the data. Consider the following examples consisting of restaurants:\n\nIf we were looking at a data set of restaurant health code inspections, you are likely to see the data with one row per inspection\nIf your data set represented general business information about each restaurant, each observation may represent one unique restaurant\nIf you were a restaurant owner planning future schedules, you could think of each day/week as an observation\n\nReading this book will not tell you how to think about your data; You alone possess the subject matter expertise specific to your data set and problem statement. However, once your data is in the right format and order, we can expose you to possible feature engineering methods.\n\n\nLearned\nSome methods require information to be transformed that we are not able to supply beforehand. In the case of centering of numeric variables described in 7¬† Normalization, you need to know the mean value of the training data set to apply this transformation. This means is the sufficient information needed to perform the calculations and is the reason why the method is a learned method.\nIn contrast, taking the square root of a variable as described in 3¬† Square Root isn‚Äôt a learned method as there isn‚Äôt any sufficient information needed. The method can be applied immediately.\n\n\nSupervised / Unsupervised\nSome methods use the outcome to guide the calculations. If the outcome is used, the method is said to be supervised. Most methods are unsupervised.\n\n\nLevels\nVariables that contain non-numeric information are typically called qualitative or categorical variables. These can be things such as eye color, street names, names, grades, car models and subscription types. Where there is a finite known set of values a categorical variable can take, we call these values the levels of that variable. So the levels of the variables containing weekdays are ‚ÄúMonday‚Äù, ‚ÄúTuesday‚Äù, ‚ÄúWednesday‚Äù, ‚ÄúThursday‚Äù, ‚ÄúFriday‚Äù, ‚ÄúSaturday‚Äù, and ‚ÄúSunday‚Äù. But the names of our subscribers don‚Äôt have levels as we don‚Äôt know all of them.\nWe will sometimes bend this definition, as it is sometimes useful to pretend that a variable has a finite known set of values, even if it doesn‚Äôt.\n\n\nLinear models\nWe talk about linear models as models that are specified as a linear combination of features. These models tend to be simple, and fast to use, but having the limitation of ‚Äúlinear combination of features‚Äù means that they struggle when non-linear effects exist in the data set.\n\n\nEmbedding\nThe word embedding is frequently utilized in machine learning and artificial intelligence documentation, however, we will use it to refer to the numeric transformation of data point. We see this often in text embeddings, where a free-from-text field is turned into a fixed-length numerical vector.\nSomething being an embedding doesn‚Äôt mean that it is useful. However, with care and signal, useful representations of the data can be created. The reason why we have embeddings in the first place is that most machine learning models require numerical features for the models to work.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "missing-model.html",
    "href": "missing-model.html",
    "title": "43¬† Model Based Imputation",
    "section": "",
    "text": "43.1 Model Based Imputation",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Model Based Imputation</span>"
    ]
  },
  {
    "objectID": "missing-model.html#pros-and-cons",
    "href": "missing-model.html#pros-and-cons",
    "title": "43¬† Model Based Imputation",
    "section": "43.2 Pros and Cons",
    "text": "43.2 Pros and Cons\n\n43.2.1 Pros\n\nLikely get better performance than simple imputation\n\n\n\n43.2.2 Cons\n\nMore complex model\nlower interpretability",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Model Based Imputation</span>"
    ]
  },
  {
    "objectID": "missing-model.html#r-examples",
    "href": "missing-model.html#r-examples",
    "title": "43¬† Model Based Imputation",
    "section": "43.3 R Examples",
    "text": "43.3 R Examples\nThere are a number of steps in the recipes package that fall under this category. Within that, we have step_impute_bag(), step_impute_knn(), and step_impute_linear().\n\n\n\n\n\n\nTODO\n\n\n\nfind a better data set\n\n\nBelow we are showing how we can impute using a K-nearest neighbor model using step_impute_knn(). We specify the variable to impute on first, and then with impute_with we specify which variables are used as predictors in the model.\n\nlibrary(recipes)\n\nimpute_knn_rec &lt;- recipe(mpg ~ ., data = mtcars) |&gt;\n  step_impute_knn(disp, neighbors = 1, impute_with = imp_vars(vs, am, hp, drat))\n\nimpute_knn_rec |&gt;\n  prep() |&gt;\n  juice()\n\n# A tibble: 32 √ó 11\n     cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb   mpg\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     6  160    110  3.9   2.62  16.5     0     1     4     4  21  \n 2     6  160    110  3.9   2.88  17.0     0     1     4     4  21  \n 3     4  108     93  3.85  2.32  18.6     1     1     4     1  22.8\n 4     6  258    110  3.08  3.22  19.4     1     0     3     1  21.4\n 5     8  360    175  3.15  3.44  17.0     0     0     3     2  18.7\n 6     6  225    105  2.76  3.46  20.2     1     0     3     1  18.1\n 7     8  360    245  3.21  3.57  15.8     0     0     3     4  14.3\n 8     4  147.    62  3.69  3.19  20       1     0     4     2  24.4\n 9     4  141.    95  3.92  3.15  22.9     1     0     4     2  22.8\n10     6  168.   123  3.92  3.44  18.3     1     0     4     4  19.2\n# ‚Ñπ 22 more rows",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Model Based Imputation</span>"
    ]
  },
  {
    "objectID": "missing-model.html#python-examples",
    "href": "missing-model.html#python-examples",
    "title": "43¬† Model Based Imputation",
    "section": "43.4 Python Examples",
    "text": "43.4 Python Examples",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>43</span>¬† <span class='chapter-title'>Model Based Imputation</span>"
    ]
  }
]