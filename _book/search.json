[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Feature Engineering A-Z",
    "section": "",
    "text": "Preface\nWelcome to “Feature Engineering A-Z”! This book is written to be used as a reference guide to nearly all feature engineering methods you will encounter. This is reflected in the chapter structure. Any question a practitioner is having should be answered by looking at the index and finding the right chapter.\nEach section tries to be as comprehensive as possible with the number of different methods and solutions that are presented. A section on dimensionality reduction should list all the practical methods that could be used, as well as a comparison between the methods to help the reader decide what would be most appropriate. This does not mean that all methods are recommended to use. A number of these methods have little and narrow use cases. Methods that are deemed too domain-specific have been excluded from this book.\nEach chapter will cover a specific method or small group of methods. This will include motivations and explanations for the method. Whenever possible each method will be accompanied by mathematical formulas and visualizations to illustrate the mechanics of the method. A small pros and cons list is provided for each method. Lastly, each section will include code snippets showcasing how to implement the methods. This is done in R and Python, using tidymodels and scikit-learn respectively. This book is a methods book first, and a coding book second.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#preface-1",
    "href": "index.html#preface-1",
    "title": "Feature Engineering A-Z",
    "section": "Preface",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#what-does-this-book-not-cover",
    "href": "index.html#what-does-this-book-not-cover",
    "title": "Feature Engineering A-Z",
    "section": "What does this book not cover?",
    "text": "What does this book not cover?\nTo keep the scope of this book as focused as possible, the following topics will not be covered in this book:\n\nwhole process modeling\ncase studies\ndeployment details\ndomain-specific methods\n\nFor whole process modeling see instead “Hands-On Machine Learning with Scikit-learn, Keras & Tensorflow” (2017), “Tidy modeling with R” (2022), “Approaching (almost) any machine learning problem” (2020) and “Applied Predictive Modeling” (2013) are all great resources. For feature engineering books that tell more of a story by going through case studies, I recommended: “Python Feature Engineering Cookbook” (2020), “Feature Engineering Bookcamp” (2022) And “Feature Engineering and Selection” (2019). I have found that books on deployment domain-specific methods are highly related to the field and stack that you are using and am not able to give broad advice.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#who-is-this-book-for",
    "href": "index.html#who-is-this-book-for",
    "title": "Feature Engineering A-Z",
    "section": "Who is this book for?",
    "text": "Who is this book for?\nThis book is designed to be used by people involved in the modeling of data. These can include but are not limited to data scientists, students, professors, data analysts and machine learning engineers. The reference style nature of the book makes it useful for beginners and seasoned professionals. A background in the basics of modeling, statistics and machine learning would be helpful. Feature engineering as a practice is tightly connected to the rest of the machine learning pipeline so knowledge of the other components is key.\nMany educational resources skip over the finer details of feature engineering methods, which is where this book tries to fill the gap.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Feature Engineering A-Z",
    "section": "License",
    "text": "License\nThis book is licensed to you under Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#rendering-details",
    "href": "index.html#rendering-details",
    "title": "Feature Engineering A-Z",
    "section": "Rendering details",
    "text": "Rendering details\nThis book is rendered using quarto (1.4.549), R (4.3.2) and Python (3.12.1). The website source is hosted on Github.\nThe following R packages are used to render the book, with tidymodels, recipes, embed, themis, textrecipes and timetk being the main packages.\n\n\n\n\n\n\n\n\ncorrr (0.4.4)\nembed (1.1.3)\nextrasteps (0.0.0.9000)\n\n\nggforce (0.4.2)\nggraph (2.1.0)\njaneaustenr (1.0.0)\n\n\njsonlite (1.8.8)\nlme4 (1.1-35.1)\nMatrix (1.6-5)\n\n\npatchwork (1.2.0)\nreadr (2.1.5)\nremotes (2.4.2.1)\n\n\nreshape (0.8.9)\nreticulate (1.35.0)\nrmarkdown (2.25)\n\n\nsplines2 (0.5.1)\ntext2vec (0.6.4)\ntextfeatures (0.3.3)\n\n\ntextrecipes (1.0.6)\ntidymodels (1.1.1)\ntidyverse (2.0.0)\n\n\n\n\n\n\n\n\nThe following Python libraries are used to render the book, with scikit-learn and feature-engine being the main ones.\n\n\n\n\n\n\n\n\nappnope (0.1.4)\nasttokens (2.4.1)\ncategory-encoders (2.6.3)\n\n\ncffi (1.16.0)\ncolorama (0.4.6)\ncomm (0.2.1)\n\n\ndebugpy (1.8.1)\ndecorator (5.1.1)\nexecuting (2.0.1)\n\n\nfeature-engine (1.6.2)\nfeazdata (0.0.1)\nipykernel (6.29.2)\n\n\nipython (8.21.0)\njedi (0.19.1)\njoblib (1.3.2)\n\n\njupyter-client (8.6.0)\njupyter-core (5.7.1)\nmatplotlib-inline (0.1.6)\n\n\nnest-asyncio (1.6.0)\nnumpy (1.26.4)\npackaging (23.2)\n\n\npandas (2.2.0)\nparso (0.8.3)\npatsy (0.5.6)\n\n\npexpect (4.9.0)\nplatformdirs (4.2.0)\nprompt-toolkit (3.0.43)\n\n\npsutil (5.9.8)\nptyprocess (0.7.0)\npure-eval (0.2.2)\n\n\npycparser (2.21)\npygments (2.17.2)\npython-dateutil (2.8.2)\n\n\npytz (2024.1)\npywin32 (306)\npyyaml (6.0.1)\n\n\npyzmq (25.1.2)\nscikit-learn (1.4.0)\nscipy (1.12.0)\n\n\nsix (1.16.0)\nstack-data (0.6.3)\nstatsmodels (0.14.1)\n\n\nthreadpoolctl (3.3.0)\ntornado (6.4)\ntraitlets (5.14.1)\n\n\ntzdata (2024.1)\nwcwidth (0.2.13)",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#can-i-contribute",
    "href": "index.html#can-i-contribute",
    "title": "Feature Engineering A-Z",
    "section": "Can I contribute?",
    "text": "Can I contribute?\nPlease feel free to improve the quality of this content by submitting pull requests. A merged PR will make you appear in the contributor list. It will, however, be considered a donation of your work to this project. You are still bound by the conditions of the license, meaning that you are not considered an author, copyright holder, or owner of the content once it has been merged in.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Feature Engineering A-Z",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nI’m so thankful for the contributions, help, and perspectives of people who have supported us in this project. There are several I would like to thank in particular.\nI would like to thank my Posit colleagues on the tidymodels team (Hannah Frick, Max Kuhn, and Simon Couch) as well as the rest of our coworkers on the Posit open-source team. I also thank Javier Orraca-Deatcu, Matt Dancho and Mike Mahoney for looking over some of the chapters before the first release.\nThis book was written in the open, and multiple people contributed via pull requests or issues. Special thanks goes to the one people who contributed via GitHub pull requests (in alphabetical order by username): Javier Orraca-Deatcu (@JavOrraca).\n\n\n\n\nGalli, S. 2020. Python Feature Engineering Cookbook: Over 70 Recipes for Creating, Engineering, and Transforming Features to Build Machine Learning Models. Packt Publishing. https://books.google.com/books?id=2c_LDwAAQBAJ.\n\n\nGéron, Aurélien. 2017. Hands-on Machine Learning with Scikit-Learn and TensorFlow : Concepts, Tools, and Techniques to Build Intelligent Systems. Sebastopol, CA: O’Reilly Media.\n\n\nKuhn, M., and K. Johnson. 2013. Applied Predictive Modeling. SpringerLink : Bücher. Springer New York. https://books.google.com/books?id=xYRDAAAAQBAJ.\n\n\n———. 2019. Feature Engineering and Selection: A Practical Approach for Predictive Models. Chapman & Hall/CRC Data Science Series. CRC Press. https://books.google.com/books?id=q5alDwAAQBAJ.\n\n\nKuhn, M., and J. Silge. 2022. Tidy Modeling with r. O’Reilly Media. https://books.google.com/books?id=98J6EAAAQBAJ.\n\n\nOzdemir, S. 2022. Feature Engineering Bookcamp. Manning. https://books.google.com/books?id=3n6HEAAAQBAJ.\n\n\nThakur, A. 2020. Approaching (Almost) Any Machine Learning Problem. Amazon Digital Services LLC - Kdp. https://books.google.com/books?id=ZbgAEAAAQBAJ.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Introduction",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#how-to-deal-with",
    "href": "introduction.html#how-to-deal-with",
    "title": "Introduction",
    "section": "How to Deal With …",
    "text": "How to Deal With …\nThis book is structured according to the types of data and problems you will encounter. Each section specifies a type of data or problem, and each chapter details a method or group of methods that can be useful in dealing with that type. So for example 1  Numeric Overview contains methods that deal with numeric variables such as 2  Logarithms and 9  Max Abs Scaling, and 14  Categorical Overview contains methods that deal with categorical variables such as 17  Dummy Encoding and 23  Hashing Encoding. There should be sections and chapters for most methods you will find in practice that aren’t too domain-specific.\nIt is because of this structure that this book is most suited as reference material, each time you encounter some data you are unsure how to deal with, you find the corresponding section and study the methods listed to see which would be best for your use case. This isn’t to say that you can’t read this book from end to end. The sections have been ordered roughly such that earlier chapters are broadly useful and later chapters touch on less used data types and problems.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#sec-modeling",
    "href": "introduction.html#sec-modeling",
    "title": "Introduction",
    "section": "Where does feature engineering fit into the modeling workflow?",
    "text": "Where does feature engineering fit into the modeling workflow?\nWhen we talk about the modeling workflow, it starts at the data source and ends with a fitted model. The fitted model in this instance should be created such that it can be used for the downstream task, be it inference or prediction.\n\n\n\n\n\n\nInference and Prediction\n\n\n\nIn some data science organizations, the term “inference” is frequently used interchangeably with “prediction,” denoting the process of generating prediction outputs from a trained model. However, in this book, we will use “inference” specifically to refer to statistical inference, which involves drawing conclusions about populations or scientific truths from data analysis.\n\n\nWe want to make sure that the feature engineering methods we are applying are done correctly to avoid problems with the modeling. Things we especially want to avoid are data leakage, overfitting, and high computational cost.\n\n\n\n\n\n\nTODO\n\n\n\nAdd diagram of modeling workflow from data source to model\n\n\nWhen applying feature engineering methods, we need to think about trained and untrained methods. Trained methods will perform a calculation doing the training of the method, and then using the extracted values to perform the transformation again. We see this in 7  Normalization, where we explore centering. To implement centering, we adjust each variable by subtracting its mean value, computed using the training dataset. Since this value needs to be calculated, it becomes a trained method. Examples of untrained methods are logarithmic transformation as seen in 2  Logarithms and datetime value extraction as seen in 38  Value Extraction. These methods are static in nature, meaning their execution can be applied at the observation-level without parameter-level inferences.\nIn practice, this means that untrained methods can be applied before the data-splitting procedure, as it would give the same results regardless of when it was done. Trained methods have to be performed after the data-splitting to ensure you don’t have data leakage. The wrinkle to this is that untrained methods applied to variables that have already been transformed by a trained method will have to also be done after the data-splitting.\n\n\n\n\n\n\nTODO\n\n\n\nadd a diagram for untrained/trained rule\n\n\nSome untrained methods have a high computational cost, such as BERT from 60  🏗️ BERT. If you are unsure about when to apply a feature engineering method, a general rule of thumb that errs on the side of caution is to apply the method after the data-splitting procedure.\nIn the examples of this book, we will show how to perform methods and techniques using {recipes} on the R side, as they can be used together with the rest of tidymodels to make sure the calculations are done correctly. On the Python side, we show the methods by using transformers, that should then be used inside a sklearn.pipeline.Pipeline() to make sure the calculations are done correctly.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#why-do-we-use-thresholds",
    "href": "introduction.html#why-do-we-use-thresholds",
    "title": "Introduction",
    "section": "Why do we use thresholds?",
    "text": "Why do we use thresholds?\nOftentimes, when we use a method that selects something with a quantity, we end up doing it with a threshold instead of counting directly. The answer to this is purely practical, as it leaves less ambiguity. When selecting these features to keep in a feature selection routine 65  Too Many Overview is a good example. It is easier to write the code that selects every feature that has more than X amount of variability. On the other hand, if we said “Give me the 25 most useful features”, we might have 4 variables tied for 25th place. Now we have another problem. Does it keep all of them in, leaving 28 variables? If we do that, we violate our request of 25 variables. What if we select the first? Then we arbitrarily give a bias towards variables early in the data set. What if we randomly select among the ties? Then we introduce randomness into the method.\nIt is for the above reasons that many methods in feature engineering and machine learning use thresholds instead of precise numbers.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#sec-terminology",
    "href": "introduction.html#sec-terminology",
    "title": "Introduction",
    "section": "Terminology",
    "text": "Terminology\nBelow are some terminology clarifications since the term usage in this book may differ from other books. When a method is known by multiple names, the additional name(s) will be listed at the beginning of each chapter. The index will likewise point you to the right chapter regardless of which name you use.\n\nEDA\nOtherwise known as exploratory data analysis is the part of the modeling process where you look at the data very carefully. This will be done in part using descriptive statistics and visualization. This should be done after splitting the data, and only on the training data set. A project may be scraped at this stage due to the limited usefulness of the data. Spending a lot of time in EDA is almost always fruitful as you gain insight into how to use and transform the data best with feature engineering methods.\n\n\nObservations\nThis book will mostly be working with rectangular data. In this context, each observation is defined as a row, with the columns holding the specific characteristics for each observation.\nThe observational unit can change depending on the data. Consider the following examples consisting of restaurants:\n\nIf we were looking at a data set of restaurant health code inspections, you are likely to see the data with one row per inspection\nIf your data set represented general business information about each restaurant, each observation may represent one unique restaurant\nIf you were a restaurant owner planning future schedules, you could think of each day/week as an observation\n\nReading this book will not tell you how to think about your data; You alone possess the subject matter expertise specific to your data set and problem statement. However, once your data is in the right format and order, we can expose you to possible feature engineering methods.\n\n\nLearned\nSome methods require information to be transformed that we are not able to supply beforehand. In the case of centering of numeric variables described in 7  Normalization, you need to know the mean value of the training data set to apply this transformation. This means is the sufficient information needed to perform the calculations and is the reason why the method is a learned method.\nIn contrast, taking the square root of a variable as described in 3  Square Root isn’t a learned method as there isn’t any sufficient information needed. The method can be applied immediately.\n\n\nSupervised / Unsupervised\nSome methods use the outcome to guide the calculations. If the outcome is used, the method is said to be supervised. Most methods are unsupervised.\n\n\nLevels\nVariables that contain non-numeric information are typically called qualitative or categorical variables. These can be things such as eye color, street names, names, grades, car models and subscription types. Where there is a finite known set of values a categorical variable can take, we call these values the levels of that variable. So the levels of the variables containing weekdays are “Monday”, “Tuesday”, “Wednesday”, “Thursday”, “Friday”, “Saturday”, and “Sunday”. But the names of our subscribers don’t have levels as we don’t know all of them.\nWe will sometimes bend this definition, as it is sometimes useful to pretend that a variable has a finite known set of values, even if it doesn’t.\n\n\nLinear models\nWe talk about linear models as models that are specified as a linear combination of features. These models tend to be simple, and fast to use, but having the limitation of “linear combination of features” means that they struggle when non-linear effects exist in the data set.\n\n\nEmbedding\nThe word embedding is frequently utilized in machine learning and artificial intelligence documentation, however, we will use it to refer to the numeric transformation of data point. We see this often in text embeddings, where a free-from-text field is turned into a fixed-length numerical vector.\nSomething being an embedding doesn’t mean that it is useful. However, with care and signal, useful representations of the data can be created. The reason why we have embeddings in the first place is that most machine learning models require numerical features for the models to work.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "numeric.html",
    "href": "numeric.html",
    "title": "1  Numeric Overview",
    "section": "",
    "text": "1.1 Numeric Overview",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Numeric Overview</span>"
    ]
  },
  {
    "objectID": "numeric.html#distributional-problems",
    "href": "numeric.html#distributional-problems",
    "title": "1  Numeric Overview",
    "section": "1.2 Distributional problems",
    "text": "1.2 Distributional problems\n\nlogarithm\nsqrt\nBoxCox\nYeo-Johnson\nPercentile",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Numeric Overview</span>"
    ]
  },
  {
    "objectID": "numeric.html#sec-numeric-scaling-issues",
    "href": "numeric.html#sec-numeric-scaling-issues",
    "title": "1  Numeric Overview",
    "section": "1.3 Scaling issues",
    "text": "1.3 Scaling issues\nThe topic of feature scaling is important and used widely in all of machine learning. This chapter will go over what feature scaling is and why we want to use it. The following chapters will each go over a different method of feature scaling.\n\n\n\n\n\n\nNote\n\n\n\nThere is some disagreement about the naming of these topics. These types of methods are called feature scaling and scaling in different fields. This book will call this general class of methods feature scaling and will make notes for each specific method and what other names they go by.\n\n\nIn this book, we will define feature scaling as an operation that modifies variables using multiplication and addition. While broadly defined, the methods typically reduce to the following form:\n\\[\nX_{scaled} = \\dfrac{X - a}{b}\n\\tag{1.1}\\]\nThe main difference between the methods is how \\(a\\) and \\(b\\) are calculated. These are learned transformation methods. We use the training data to derive the right values of \\(a\\) and \\(b\\), and then these values are used to perform the transformations when applied to new data. The different methods might differ on what property is desired for the transformed variables, same range or same spread, but they never change the distribution itself. The power transformations we saw in Chapter 4 and Chapter 5, distort the transformations, where these feature scalings essentially perform a “zooming” effect.\n\n\n\nTable 1.1: All feature scaling methods\n\n\n\n\n\n\n\n\n\nMethod\nDefinition\n\n\n\n\nCentering\n\\(X_{scaled} = X - \\text{mean}(X)\\)\n\n\nScaling\n\\(X_{scaled} = \\dfrac{X}{\\text{sd}(X)}\\)\n\n\nMax-Abs\n\\(X_{scaled} = \\dfrac{X}{\\text{max}(\\text{abs}(X))}\\)\n\n\nNormalization\n\\(X_{scaled} = \\dfrac{X - \\text{mean}(X)}{\\text{sd}(X)}\\)\n\n\nMin-Max\n\\(X_{scaled} = \\dfrac{X - \\text{min}(X)}{\\text{max}(X) - \\text{min}(X)}\\)\n\n\nRobust\n\\(X_{scaled} = \\dfrac{X - \\text{median}(X)}{\\text{Q3}(X) - \\text{Q1}(X)}\\)\n\n\n\n\n\n\nWe see here that all the methods in Table 1.1 follow Equation 1.1. Sometimes \\(a\\) and \\(b\\) take a value of 0, which is perfectly fine. Centering and scaling when used together is equal to normalization. They are kept separate in the table since they are sometimes used independently. Centering, scaling, and normalization will all be discussed in Chapter 7.\nThere are two main reasons why we want to perform feature scaling. Firstly, many different types of models take the magnitude of the variables into account when fitting the models, so having variables on different scales can be disadvantageous because some variables have high priorities. In turn, we get that the other variables have low priority. Models that work using Euclidean distances like KNN models are affected by this change. Regularized models such as lasso and ridge regression also need to be scaled since the regularization depends on the magnitude of the estimates. Secondly, some algorithms converge much faster when all the variables are on the same scale. These types of models produce the same fit, just at a slower pace than if you don’t scale the variables. Any algorithms using Gradient Descent fit into this category.\n\n\n\n\n\n\nTODO\n\n\n\nHave a KNN diagram show why this is important\n\n\nList which types of models need feature scaling. Should be a 2 column list. Left=name, right=comment %in% c(no effect, different fit, slow down)",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Numeric Overview</span>"
    ]
  },
  {
    "objectID": "numeric.html#non-linear-effect",
    "href": "numeric.html#non-linear-effect",
    "title": "1  Numeric Overview",
    "section": "1.4 Non-linear effect",
    "text": "1.4 Non-linear effect\n\nbinning\nsplines\npolynomial\n\n\n\n\n\n\n\nTODO\n\n\n\nShow different distributions, and how well the different methods do at dealing with them",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Numeric Overview</span>"
    ]
  },
  {
    "objectID": "numeric.html#sec-numeric-outliers-issues",
    "href": "numeric.html#sec-numeric-outliers-issues",
    "title": "1  Numeric Overview",
    "section": "1.5 Outliers",
    "text": "1.5 Outliers",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Numeric Overview</span>"
    ]
  },
  {
    "objectID": "numeric.html#other",
    "href": "numeric.html#other",
    "title": "1  Numeric Overview",
    "section": "1.6 Other",
    "text": "1.6 Other\nThere are any number of transformations we can apply to numeric data, other functions include:\n\nhyperbolic\nRelu\ninverse\ninverse logit\nlogit",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Numeric Overview</span>"
    ]
  },
  {
    "objectID": "numeric-logarithms.html",
    "href": "numeric-logarithms.html",
    "title": "2  Logarithms",
    "section": "",
    "text": "2.1 Logarithms",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Logarithms</span>"
    ]
  },
  {
    "objectID": "numeric-logarithms.html#pros-and-cons",
    "href": "numeric-logarithms.html#pros-and-cons",
    "title": "2  Logarithms",
    "section": "2.2 Pros and Cons",
    "text": "2.2 Pros and Cons\n\n2.2.1 Pros\n\nA non-trained operation, can easily be applied to training and testing data sets alike\n\n\n\n2.2.2 Cons\n\nNeeds offset to deal with negative data\nIs not a universal fix. While it can make skewed distributions less skewed. It has the opposite effect on a distribution that isn’t skewed. See the effect below on 10,000 uniformly distributed values",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Logarithms</span>"
    ]
  },
  {
    "objectID": "numeric-logarithms.html#r-examples",
    "href": "numeric-logarithms.html#r-examples",
    "title": "2  Logarithms",
    "section": "2.3 R Examples",
    "text": "2.3 R Examples\nWe will be using the ames data set for these examples.\n\nlibrary(recipes)\nlibrary(modeldata)\n\names |&gt;\n  select(Lot_Area, Wood_Deck_SF, Sale_Price)\n\n# A tibble: 2,930 × 3\n   Lot_Area Wood_Deck_SF Sale_Price\n      &lt;int&gt;        &lt;int&gt;      &lt;int&gt;\n 1    31770          210     215000\n 2    11622          140     105000\n 3    14267          393     172000\n 4    11160            0     244000\n 5    13830          212     189900\n 6     9978          360     195500\n 7     4920            0     213500\n 8     5005            0     191500\n 9     5389          237     236500\n10     7500          140     189000\n# ℹ 2,920 more rows\n\n\n{recipes} provides a step to perform logarithms, which out of the box uses \\(e\\) as the base with an offset of 0.\n\nlog_rec &lt;- recipe(Sale_Price ~ Lot_Area, data = ames) |&gt;\n  step_log(Lot_Area)\n\nlog_rec |&gt;\n  prep() |&gt;\n  bake(new_data = NULL)\n\n# A tibble: 2,930 × 2\n   Lot_Area Sale_Price\n      &lt;dbl&gt;      &lt;int&gt;\n 1    10.4      215000\n 2     9.36     105000\n 3     9.57     172000\n 4     9.32     244000\n 5     9.53     189900\n 6     9.21     195500\n 7     8.50     213500\n 8     8.52     191500\n 9     8.59     236500\n10     8.92     189000\n# ℹ 2,920 more rows\n\n\nThe base can be changed by setting the base argument.\n\nlog_rec &lt;- recipe(Sale_Price ~ Lot_Area, data = ames) |&gt;\n  step_log(Lot_Area, base = 2)\n\nlog_rec |&gt;\n  prep() |&gt;\n  bake(new_data = NULL)\n\n# A tibble: 2,930 × 2\n   Lot_Area Sale_Price\n      &lt;dbl&gt;      &lt;int&gt;\n 1     15.0     215000\n 2     13.5     105000\n 3     13.8     172000\n 4     13.4     244000\n 5     13.8     189900\n 6     13.3     195500\n 7     12.3     213500\n 8     12.3     191500\n 9     12.4     236500\n10     12.9     189000\n# ℹ 2,920 more rows\n\n\nIf we have non-positive values, which we do in the Wood_Deck_SF variable because it has quite a lot of zeroes, we get -Inf which isn’t going to work.\n\nlog_rec &lt;- recipe(Sale_Price ~ Wood_Deck_SF, data = ames) |&gt;\n  step_log(Wood_Deck_SF)\n\nlog_rec |&gt;\n  prep() |&gt;\n  bake(new_data = NULL)\n\n# A tibble: 2,930 × 2\n   Wood_Deck_SF Sale_Price\n          &lt;dbl&gt;      &lt;int&gt;\n 1         5.35     215000\n 2         4.94     105000\n 3         5.97     172000\n 4      -Inf        244000\n 5         5.36     189900\n 6         5.89     195500\n 7      -Inf        213500\n 8      -Inf        191500\n 9         5.47     236500\n10         4.94     189000\n# ℹ 2,920 more rows\n\n\nSetting the offset argument helps us to deal with that problem.\n\nlog_rec &lt;- recipe(Sale_Price ~ Wood_Deck_SF, data = ames) |&gt;\n  step_log(Wood_Deck_SF, offset = 0.5)\n\nlog_rec |&gt;\n  prep() |&gt;\n  bake(new_data = NULL)\n\n# A tibble: 2,930 × 2\n   Wood_Deck_SF Sale_Price\n          &lt;dbl&gt;      &lt;int&gt;\n 1        5.35      215000\n 2        4.95      105000\n 3        5.98      172000\n 4       -0.693     244000\n 5        5.36      189900\n 6        5.89      195500\n 7       -0.693     213500\n 8       -0.693     191500\n 9        5.47      236500\n10        4.95      189000\n# ℹ 2,920 more rows",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Logarithms</span>"
    ]
  },
  {
    "objectID": "numeric-logarithms.html#python-examples",
    "href": "numeric-logarithms.html#python-examples",
    "title": "2  Logarithms",
    "section": "2.4 Python Examples",
    "text": "2.4 Python Examples\nWe are using the ames data set for examples. {feature_engine} provided the LogCpTransformer() which is just what we need in this instance. This transformer lets us set an offset C that is calculated before taking the logarithm to avoid taking the log of a non-positive number. If we knew that there weren’t any non-positive numbers then we could use the LogTransformer instead.\n\nfrom feazdata import ames\nfrom sklearn.compose import ColumnTransformer\nfrom feature_engine.transformation import LogCpTransformer\n\nct = ColumnTransformer(\n    [('log', LogCpTransformer(C=1), ['Wood_Deck_SF'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('log', LogCpTransformer(C=1),\n                                 ['Wood_Deck_SF'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('log', LogCpTransformer(C=1),\n                                 ['Wood_Deck_SF'])]) log['Wood_Deck_SF'] LogCpTransformerLogCpTransformer(C=1) remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Lot_Area', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Mas_Vnr_Area', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Sale_Price', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames)\n\n      log__Wood_Deck_SF  ... remainder__Latitude\n0                 5.352  ...              42.054\n1                 4.949  ...              42.053\n2                 5.976  ...              42.053\n3                 0.000  ...              42.051\n4                 5.361  ...              42.061\n...                 ...  ...                 ...\n2925              4.796  ...              41.989\n2926              5.106  ...              41.988\n2927              4.394  ...              41.987\n2928              5.485  ...              41.991\n2929              5.252  ...              41.989\n\n[2930 rows x 74 columns]\n\n/Users/emilhvitfeldt/.virtualenvs/feaz-book/lib/python3.12/site-packages/feature_engine/transformation/log.py:388: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[5.35185813 4.94875989 5.97635091 ... 4.39444915 5.48479693 5.25227343]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n  X.loc[:, self.variables_] = np.log(X.loc[:, self.variables_] + self.C_)",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Logarithms</span>"
    ]
  },
  {
    "objectID": "numeric-sqrt.html",
    "href": "numeric-sqrt.html",
    "title": "3  Square Root",
    "section": "",
    "text": "3.1 Square Root",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Square Root</span>"
    ]
  },
  {
    "objectID": "numeric-sqrt.html#pros-and-cons",
    "href": "numeric-sqrt.html#pros-and-cons",
    "title": "3  Square Root",
    "section": "3.2 Pros and Cons",
    "text": "3.2 Pros and Cons\n\n3.2.1 Pros\n\nA non-trained operation, can easily be applied to training and testing data sets alike\nCan be applied to all numbers, not just non-negative values\n\n\n\n3.2.2 Cons\n\nIt will leave regression coefficients virtually uninterpretable\nIs not a universal fix. While it can make skewed distributions less skewed. It has the opposite effect on a distribution that isn’t skewed",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Square Root</span>"
    ]
  },
  {
    "objectID": "numeric-sqrt.html#r-examples",
    "href": "numeric-sqrt.html#r-examples",
    "title": "3  Square Root",
    "section": "3.3 R Examples",
    "text": "3.3 R Examples\nWe will be using the hotel_bookings data set for these examples.\n\nlibrary(recipes)\n\nhotel_bookings |&gt;\n  select(lead_time, adr)\n\n# A tibble: 119,390 × 2\n   lead_time   adr\n       &lt;dbl&gt; &lt;dbl&gt;\n 1       342    0 \n 2       737    0 \n 3         7   75 \n 4        13   75 \n 5        14   98 \n 6        14   98 \n 7         0  107 \n 8         9  103 \n 9        85   82 \n10        75  106.\n# ℹ 119,380 more rows\n\n\n{recipes} provides a step to perform logarithms, which out of the box uses \\(e\\) as the base with an offset of 0.\n\nsqrt_rec &lt;- recipe(lead_time ~ adr, data = hotel_bookings) |&gt;\n  step_sqrt(adr)\n\nsqrt_rec |&gt;\n  prep() |&gt;\n  bake(new_data = NULL)\n\nWarning in sqrt(new_data[[col_name]]): NaNs produced\n\n\n# A tibble: 119,390 × 2\n     adr lead_time\n   &lt;dbl&gt;     &lt;dbl&gt;\n 1  0          342\n 2  0          737\n 3  8.66         7\n 4  8.66        13\n 5  9.90        14\n 6  9.90        14\n 7 10.3          0\n 8 10.1          9\n 9  9.06        85\n10 10.3         75\n# ℹ 119,380 more rows\n\n\nif you want to do a signed square root instead, you can use step_mutate() which allows you to do any kind of transformations\n\nsigned_sqrt_rec &lt;- recipe(lead_time ~ adr, data = hotel_bookings) |&gt;\n  step_mutate(adr = sqrt(abs(adr)) * sign(adr))\n\nsigned_sqrt_rec |&gt;\n  prep() |&gt;\n  bake(new_data = NULL)\n\n# A tibble: 119,390 × 2\n     adr lead_time\n   &lt;dbl&gt;     &lt;dbl&gt;\n 1  0          342\n 2  0          737\n 3  8.66         7\n 4  8.66        13\n 5  9.90        14\n 6  9.90        14\n 7 10.3          0\n 8 10.1          9\n 9  9.06        85\n10 10.3         75\n# ℹ 119,380 more rows",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Square Root</span>"
    ]
  },
  {
    "objectID": "numeric-sqrt.html#python-examples",
    "href": "numeric-sqrt.html#python-examples",
    "title": "3  Square Root",
    "section": "3.4 Python Examples",
    "text": "3.4 Python Examples\nWe are using the ames data set for examples. Since there isn’t a built-in transformer for square root, we can create our own using FunctionTransformer() and numpy.sqrt().\n\nfrom feazdata import ames\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import FunctionTransformer\nimport numpy as np\n\nsqrt_transformer = FunctionTransformer(np.sqrt)\n\nct = ColumnTransformer(\n    [('sqrt', sqrt_transformer, ['Wood_Deck_SF'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('sqrt',\n                                 FunctionTransformer(func=&lt;ufunc 'sqrt'&gt;),\n                                 ['Wood_Deck_SF'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('sqrt',\n                                 FunctionTransformer(func=&lt;ufunc 'sqrt'&gt;),\n                                 ['Wood_Deck_SF'])]) sqrt['Wood_Deck_SF']  FunctionTransformer?Documentation for FunctionTransformerFunctionTransformer(func=&lt;ufunc 'sqrt'&gt;) remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Lot_Area', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Mas_Vnr_Area', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Sale_Price', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames)\n\n      sqrt__Wood_Deck_SF  ... remainder__Latitude\n0                 14.491  ...              42.054\n1                 11.832  ...              42.053\n2                 19.824  ...              42.053\n3                  0.000  ...              42.051\n4                 14.560  ...              42.061\n...                  ...  ...                 ...\n2925              10.954  ...              41.989\n2926              12.806  ...              41.988\n2927               8.944  ...              41.987\n2928              15.492  ...              41.991\n2929              13.784  ...              41.989\n\n[2930 rows x 74 columns]\n\n\nWe can also create and perform a signed square root transformation, by creating a function for signed_sqrt() and then using it in FunctionTransformer() as before\n\ndef signed_sqrt(x):\n  return np.sqrt(np.abs(x)) * np.sign(x)\n\nsigned_sqrt_transformer = FunctionTransformer(signed_sqrt)\n\nct = ColumnTransformer(\n    [('signed_sqrt', signed_sqrt_transformer, ['Wood_Deck_SF'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('signed_sqrt',\n                                 FunctionTransformer(func=&lt;function signed_sqrt at 0x2ad805a80&gt;),\n                                 ['Wood_Deck_SF'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('signed_sqrt',\n                                 FunctionTransformer(func=&lt;function signed_sqrt at 0x2ad805a80&gt;),\n                                 ['Wood_Deck_SF'])]) signed_sqrt['Wood_Deck_SF']  FunctionTransformer?Documentation for FunctionTransformerFunctionTransformer(func=&lt;function signed_sqrt at 0x2ad805a80&gt;) remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Lot_Area', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Mas_Vnr_Area', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Sale_Price', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames)\n\n      signed_sqrt__Wood_Deck_SF  ... remainder__Latitude\n0                        14.491  ...              42.054\n1                        11.832  ...              42.053\n2                        19.824  ...              42.053\n3                         0.000  ...              42.051\n4                        14.560  ...              42.061\n...                         ...  ...                 ...\n2925                     10.954  ...              41.989\n2926                     12.806  ...              41.988\n2927                      8.944  ...              41.987\n2928                     15.492  ...              41.991\n2929                     13.784  ...              41.989\n\n[2930 rows x 74 columns]",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Square Root</span>"
    ]
  },
  {
    "objectID": "numeric-boxcox.html",
    "href": "numeric-boxcox.html",
    "title": "4  Box-Cox",
    "section": "",
    "text": "4.1 Box-Cox",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Box-Cox</span>"
    ]
  },
  {
    "objectID": "numeric-boxcox.html#pros-and-cons",
    "href": "numeric-boxcox.html#pros-and-cons",
    "title": "4  Box-Cox",
    "section": "4.2 Pros and Cons",
    "text": "4.2 Pros and Cons\n\n4.2.1 Pros\n\nMore flexible than individually chosen power transformations such as logarithms and square roots\n\n\n\n4.2.2 Cons\n\nDoesn’t work with negative values\nIsn’t a universal fix",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Box-Cox</span>"
    ]
  },
  {
    "objectID": "numeric-boxcox.html#r-examples",
    "href": "numeric-boxcox.html#r-examples",
    "title": "4  Box-Cox",
    "section": "4.3 R Examples",
    "text": "4.3 R Examples\nWe will be using the ames data set for these examples.\n\nlibrary(recipes)\nlibrary(modeldata)\ndata(\"ames\")\n\names |&gt;\n  select(Lot_Area, Wood_Deck_SF, Sale_Price)\n\n# A tibble: 2,930 × 3\n   Lot_Area Wood_Deck_SF Sale_Price\n      &lt;int&gt;        &lt;int&gt;      &lt;int&gt;\n 1    31770          210     215000\n 2    11622          140     105000\n 3    14267          393     172000\n 4    11160            0     244000\n 5    13830          212     189900\n 6     9978          360     195500\n 7     4920            0     213500\n 8     5005            0     191500\n 9     5389          237     236500\n10     7500          140     189000\n# ℹ 2,920 more rows\n\n\n{recipes} provides a step to perform Box-Cox transformations.\n\nboxcox_rec &lt;- recipe(Sale_Price ~ Lot_Area, data = ames) |&gt;\n  step_BoxCox(Lot_Area) |&gt;\n  prep()\n\nboxcox_rec |&gt;\n  bake(new_data = NULL)\n\n# A tibble: 2,930 × 2\n   Lot_Area Sale_Price\n      &lt;dbl&gt;      &lt;int&gt;\n 1     21.8     215000\n 2     18.2     105000\n 3     18.9     172000\n 4     18.1     244000\n 5     18.8     189900\n 6     17.7     195500\n 7     15.5     213500\n 8     15.5     191500\n 9     15.8     236500\n10     16.8     189000\n# ℹ 2,920 more rows\n\n\nWe can also pull out the value of the estimated \\(\\lambda\\) by using the tidy() method on the recipe step.\n\nboxcox_rec |&gt;\n  tidy(1)\n\n# A tibble: 1 × 3\n  terms    value id          \n  &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;       \n1 Lot_Area 0.129 BoxCox_3gJXR",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Box-Cox</span>"
    ]
  },
  {
    "objectID": "numeric-boxcox.html#python-examples",
    "href": "numeric-boxcox.html#python-examples",
    "title": "4  Box-Cox",
    "section": "4.4 Python Examples",
    "text": "4.4 Python Examples\nWe are using the ames data set for examples. {feature_engine} provided the BoxCoxTransformer() which is just what we need in this instance. We note that this transformer does not work on non-positive data.\n\nfrom feazdata import ames\nfrom sklearn.compose import ColumnTransformer\nfrom feature_engine.transformation import BoxCoxTransformer\n\nct = ColumnTransformer(\n    [('boxcox', BoxCoxTransformer(), ['Lot_Area'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('boxcox', BoxCoxTransformer(), ['Lot_Area'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('boxcox', BoxCoxTransformer(), ['Lot_Area'])]) boxcox['Lot_Area'] BoxCoxTransformerBoxCoxTransformer() remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Mas_Vnr_Area', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Sale_Price', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames)\n\n      boxcox__Lot_Area  ... remainder__Latitude\n0               21.839  ...              42.054\n1               18.229  ...              42.053\n2               18.928  ...              42.053\n3               18.093  ...              42.051\n4               18.821  ...              42.061\n...                ...  ...                 ...\n2925            16.979  ...              41.989\n2926            17.343  ...              41.988\n2927            17.872  ...              41.987\n2928            17.733  ...              41.991\n2929            17.604  ...              41.989\n\n[2930 rows x 74 columns]",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Box-Cox</span>"
    ]
  },
  {
    "objectID": "numeric-yeojohnson.html",
    "href": "numeric-yeojohnson.html",
    "title": "5  Yeo-Johnson",
    "section": "",
    "text": "5.1 Yeo-Johnson",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Yeo-Johnson</span>"
    ]
  },
  {
    "objectID": "numeric-yeojohnson.html#pros-and-cons",
    "href": "numeric-yeojohnson.html#pros-and-cons",
    "title": "5  Yeo-Johnson",
    "section": "5.2 Pros and Cons",
    "text": "5.2 Pros and Cons\n\n5.2.1 Pros\n\nMore flexible than individually chosen power transformations such as logarithms and square roots\nCan handle negative values\n\n\n\n5.2.2 Cons\n\nIsn’t a universal fix",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Yeo-Johnson</span>"
    ]
  },
  {
    "objectID": "numeric-yeojohnson.html#r-examples",
    "href": "numeric-yeojohnson.html#r-examples",
    "title": "5  Yeo-Johnson",
    "section": "5.3 R Examples",
    "text": "5.3 R Examples\nWe will be using the ames data set for these examples.\n\nlibrary(recipes)\nlibrary(modeldata)\ndata(\"ames\")\n\names |&gt;\n  select(Lot_Area, Wood_Deck_SF, Sale_Price)\n\n# A tibble: 2,930 × 3\n   Lot_Area Wood_Deck_SF Sale_Price\n      &lt;int&gt;        &lt;int&gt;      &lt;int&gt;\n 1    31770          210     215000\n 2    11622          140     105000\n 3    14267          393     172000\n 4    11160            0     244000\n 5    13830          212     189900\n 6     9978          360     195500\n 7     4920            0     213500\n 8     5005            0     191500\n 9     5389          237     236500\n10     7500          140     189000\n# ℹ 2,920 more rows\n\n\n{recipes} provides a step to perform Yeo-Johnson transformations, which out of the box uses \\(e\\) as the base with an offset of 0.\n\nyeojohnson_rec &lt;- recipe(Sale_Price ~ Lot_Area, data = ames) |&gt;\n  step_YeoJohnson(Lot_Area) |&gt;\n  prep()\n\nyeojohnson_rec |&gt;\n  bake(new_data = NULL)\n\n# A tibble: 2,930 × 2\n   Lot_Area Sale_Price\n      &lt;dbl&gt;      &lt;int&gt;\n 1     21.8     215000\n 2     18.2     105000\n 3     18.9     172000\n 4     18.1     244000\n 5     18.8     189900\n 6     17.7     195500\n 7     15.5     213500\n 8     15.5     191500\n 9     15.8     236500\n10     16.8     189000\n# ℹ 2,920 more rows\n\n\nWe can also pull out the value of the estimated \\(\\lambda\\) by using the tidy() method on the recipe step.\n\nyeojohnson_rec |&gt;\n  tidy(1)\n\n# A tibble: 1 × 3\n  terms    value id              \n  &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;           \n1 Lot_Area 0.129 YeoJohnson_3gJXR",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Yeo-Johnson</span>"
    ]
  },
  {
    "objectID": "numeric-yeojohnson.html#python-examples",
    "href": "numeric-yeojohnson.html#python-examples",
    "title": "5  Yeo-Johnson",
    "section": "5.4 Python Examples",
    "text": "5.4 Python Examples\nWe are using the ames data set for examples. {feature_engine} provided the YeoJohnsonTransformer() that we can use.\n\nfrom feazdata import ames\nfrom sklearn.compose import ColumnTransformer\nfrom feature_engine.transformation import YeoJohnsonTransformer\n\nct = ColumnTransformer(\n    [('yeojohnson', YeoJohnsonTransformer(), ['Lot_Area'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('yeojohnson', YeoJohnsonTransformer(),\n                                 ['Lot_Area'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('yeojohnson', YeoJohnsonTransformer(),\n                                 ['Lot_Area'])]) yeojohnson['Lot_Area'] YeoJohnsonTransformerYeoJohnsonTransformer() remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Mas_Vnr_Area', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Sale_Price', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames)\n\n      yeojohnson__Lot_Area  ... remainder__Latitude\n0                   21.823  ...              42.054\n1                   18.218  ...              42.053\n2                   18.915  ...              42.053\n3                   18.082  ...              42.051\n4                   18.808  ...              42.061\n...                    ...  ...                 ...\n2925                16.969  ...              41.989\n2926                17.332  ...              41.988\n2927                17.861  ...              41.987\n2928                17.721  ...              41.991\n2929                17.593  ...              41.989\n\n[2930 rows x 74 columns]",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Yeo-Johnson</span>"
    ]
  },
  {
    "objectID": "numeric-percentile.html",
    "href": "numeric-percentile.html",
    "title": "6  Percentile Scaling",
    "section": "",
    "text": "6.1 Percentile Scaling",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Percentile Scaling</span>"
    ]
  },
  {
    "objectID": "numeric-percentile.html#pros-and-cons",
    "href": "numeric-percentile.html#pros-and-cons",
    "title": "6  Percentile Scaling",
    "section": "6.2 Pros and Cons",
    "text": "6.2 Pros and Cons\n\n6.2.1 Pros\n\nTransformation isn’t affected much by outliers\n\n\n\n6.2.2 Cons\n\nDoesn’t allow to exact reverse transformation\nIsn’t ideal if training data doesn’t have that many unique values",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Percentile Scaling</span>"
    ]
  },
  {
    "objectID": "numeric-percentile.html#r-examples",
    "href": "numeric-percentile.html#r-examples",
    "title": "6  Percentile Scaling",
    "section": "6.3 R Examples",
    "text": "6.3 R Examples\nWe will be using the ames data set for these examples.\n\nlibrary(recipes)\nlibrary(modeldata)\ndata(\"ames\")\n\names |&gt;\n  select(Lot_Area, Wood_Deck_SF, Sale_Price)\n\n# A tibble: 2,930 × 3\n   Lot_Area Wood_Deck_SF Sale_Price\n      &lt;int&gt;        &lt;int&gt;      &lt;int&gt;\n 1    31770          210     215000\n 2    11622          140     105000\n 3    14267          393     172000\n 4    11160            0     244000\n 5    13830          212     189900\n 6     9978          360     195500\n 7     4920            0     213500\n 8     5005            0     191500\n 9     5389          237     236500\n10     7500          140     189000\n# ℹ 2,920 more rows\n\n\nThe {recipes} step to do this transformation is step_percentile(). It defaults to the calculation of 100 percentiles and uses those to transform the data\n\npercentile_rec &lt;- recipe(Sale_Price ~ Lot_Area, data = ames) |&gt;\n  step_percentile(Lot_Area) |&gt;\n  prep()\n\npercentile_rec |&gt;\n  bake(new_data = NULL)\n\n# A tibble: 2,930 × 2\n   Lot_Area Sale_Price\n      &lt;dbl&gt;      &lt;int&gt;\n 1    0.989     215000\n 2    0.756     105000\n 3    0.898     172000\n 4    0.717     244000\n 5    0.883     189900\n 6    0.580     195500\n 7    0.104     213500\n 8    0.106     191500\n 9    0.120     236500\n10    0.259     189000\n# ℹ 2,920 more rows\n\n\nWe can use the tidy() method to pull out what the specific values are for each percentile\n\npercentile_rec |&gt;\n  tidy(1)\n\n# A tibble: 99 × 4\n   terms    value percentile id              \n   &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;           \n 1 Lot_Area 1300           0 percentile_Bp5vK\n 2 Lot_Area 1680           1 percentile_Bp5vK\n 3 Lot_Area 2040.          2 percentile_Bp5vK\n 4 Lot_Area 2362.          3 percentile_Bp5vK\n 5 Lot_Area 2779.          4 percentile_Bp5vK\n 6 Lot_Area 3188.          5 percentile_Bp5vK\n 7 Lot_Area 3674.          6 percentile_Bp5vK\n 8 Lot_Area 3901.          7 percentile_Bp5vK\n 9 Lot_Area 4122.          8 percentile_Bp5vK\n10 Lot_Area 4435           9 percentile_Bp5vK\n# ℹ 89 more rows\n\n\nYou can change the granularity by using the options argument. In this example, we are calculating 500 points evenly spaced between 0 and 1, both inclusive.\n\npercentile500_rec &lt;- recipe(Sale_Price ~ Lot_Area, data = ames) |&gt;\n  step_percentile(Lot_Area, options = list(probs = (0:500)/500)) |&gt;\n  prep()\n\npercentile500_rec |&gt;\n  bake(new_data = NULL)\n\n# A tibble: 2,930 × 2\n   Lot_Area Sale_Price\n      &lt;dbl&gt;      &lt;int&gt;\n 1    0.989     215000\n 2    0.755     105000\n 3    0.899     172000\n 4    0.717     244000\n 5    0.884     189900\n 6    0.580     195500\n 7    0.103     213500\n 8    0.106     191500\n 9    0.118     236500\n10    0.254     189000\n# ℹ 2,920 more rows\n\n\nAnd we can see the more precise numbers.\n\npercentile500_rec |&gt;\n  tidy(1)\n\n# A tibble: 457 × 4\n   terms    value percentile id              \n   &lt;chr&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;           \n 1 Lot_Area 1300         0   percentile_RUieL\n 2 Lot_Area 1487.        0.2 percentile_RUieL\n 3 Lot_Area 1531.        0.4 percentile_RUieL\n 4 Lot_Area 1605.        0.6 percentile_RUieL\n 5 Lot_Area 1680         0.8 percentile_RUieL\n 6 Lot_Area 1879.        1.4 percentile_RUieL\n 7 Lot_Area 1890         1.6 percentile_RUieL\n 8 Lot_Area 1946.        1.8 percentile_RUieL\n 9 Lot_Area 2040.        2   percentile_RUieL\n10 Lot_Area 2136.        2.2 percentile_RUieL\n# ℹ 447 more rows\n\n\nNotice how there are only 457 values in this output. This is happening because some percentile has been collapsed to save space since if the value for the 10.4 and 10.6 percentile is the same, we just store the 10.6 value.",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Percentile Scaling</span>"
    ]
  },
  {
    "objectID": "numeric-percentile.html#python-examples",
    "href": "numeric-percentile.html#python-examples",
    "title": "6  Percentile Scaling",
    "section": "6.4 Python Examples",
    "text": "6.4 Python Examples\nWe are using the ames data set for examples. {sklearn} provided the QuantileTransformer() method we can use. We can use the n_quantiles argument to change the number of quantiles to use.\n\nfrom feazdata import ames\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import QuantileTransformer\n\nct = ColumnTransformer(\n    [('Quantile', QuantileTransformer(n_quantiles = 500), ['Lot_Area'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('Quantile',\n                                 QuantileTransformer(n_quantiles=500),\n                                 ['Lot_Area'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('Quantile',\n                                 QuantileTransformer(n_quantiles=500),\n                                 ['Lot_Area'])]) Quantile['Lot_Area']  QuantileTransformer?Documentation for QuantileTransformerQuantileTransformer(n_quantiles=500) remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Mas_Vnr_Area', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Sale_Price', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames)\n\n      Quantile__Lot_Area  ... remainder__Latitude\n0                  0.989  ...              42.054\n1                  0.755  ...              42.053\n2                  0.899  ...              42.053\n3                  0.717  ...              42.051\n4                  0.884  ...              42.061\n...                  ...  ...                 ...\n2925               0.300  ...              41.989\n2926               0.427  ...              41.988\n2927               0.639  ...              41.987\n2928               0.586  ...              41.991\n2929               0.536  ...              41.989\n\n[2930 rows x 74 columns]",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Percentile Scaling</span>"
    ]
  },
  {
    "objectID": "numeric-normalization.html",
    "href": "numeric-normalization.html",
    "title": "7  Normalization",
    "section": "",
    "text": "7.1 Normalization",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Normalization</span>"
    ]
  },
  {
    "objectID": "numeric-normalization.html#pros-and-cons",
    "href": "numeric-normalization.html#pros-and-cons",
    "title": "7  Normalization",
    "section": "7.2 Pros and Cons",
    "text": "7.2 Pros and Cons\n\n7.2.1 Pros\n\nIf you don’t have any severe outliers then you will rarely see any downsides to applying normalization\nFast calculations\nTransformation can easily be reversed, making its interpretations easier on the original scale\n\n\n\n7.2.2 Cons\n\nNot all software solutions will be helpful when applying this transformation to a constant variable. You will often get a “division by 0” error\nCannot be used with sparse data as it isn’t preserved because of the centering that is happening. If you only scale the data you don’t have a problem\nThis transformation is highly affected by outliers, as they affect the mean and standard deviation quite a lot\n\nBelow is the figure Figure 7.2 is an illustration of the effect of having a single high value. In this case, a single observation with the value 10000 moved the transformed distribution much tighter around zero. And all but removed the variance of the non-outliers.\n\n\n\n\n\n\n\n\nFigure 7.2: Outliers can have a big effect on the resulting distribution when applying normalization.",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Normalization</span>"
    ]
  },
  {
    "objectID": "numeric-normalization.html#r-examples",
    "href": "numeric-normalization.html#r-examples",
    "title": "7  Normalization",
    "section": "7.3 R Examples",
    "text": "7.3 R Examples\nWe will be using the ames data set for these examples.\n\nlibrary(recipes)\nlibrary(modeldata)\ndata(\"ames\")\n\names |&gt;\n  select(Sale_Price, Lot_Area, Wood_Deck_SF, Mas_Vnr_Area)\n\n# A tibble: 2,930 × 4\n   Sale_Price Lot_Area Wood_Deck_SF Mas_Vnr_Area\n        &lt;int&gt;    &lt;int&gt;        &lt;int&gt;        &lt;dbl&gt;\n 1     215000    31770          210          112\n 2     105000    11622          140            0\n 3     172000    14267          393          108\n 4     244000    11160            0            0\n 5     189900    13830          212            0\n 6     195500     9978          360           20\n 7     213500     4920            0            0\n 8     191500     5005            0            0\n 9     236500     5389          237            0\n10     189000     7500          140            0\n# ℹ 2,920 more rows\n\n\n{recipes} provides a step to perform scaling, centering, and normalization. They are called step_scale(), step_center() and step_normalize() respectively.\nBelow is an example using step_scale()\n\nscale_rec &lt;- recipe(Sale_Price ~ ., data = ames) |&gt;\n  step_scale(all_numeric_predictors()) |&gt;\n  prep()\n\nscale_rec |&gt;\n  bake(new_data = NULL, Sale_Price, Lot_Area, Wood_Deck_SF, Mas_Vnr_Area)\n\n# A tibble: 2,930 × 4\n   Sale_Price Lot_Area Wood_Deck_SF Mas_Vnr_Area\n        &lt;int&gt;    &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n 1     215000    4.03          1.66        0.627\n 2     105000    1.47          1.11        0    \n 3     172000    1.81          3.11        0.605\n 4     244000    1.42          0           0    \n 5     189900    1.76          1.68        0    \n 6     195500    1.27          2.85        0.112\n 7     213500    0.624         0           0    \n 8     191500    0.635         0           0    \n 9     236500    0.684         1.88        0    \n10     189000    0.952         1.11        0    \n# ℹ 2,920 more rows\n\n\nWe can also pull out the value of the standard deviation for each variable that was affected using tidy()\n\nscale_rec |&gt;\n  tidy(1)\n\n# A tibble: 33 × 3\n   terms            value id         \n   &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;      \n 1 Lot_Frontage     33.5  scale_FGmgk\n 2 Lot_Area       7880.   scale_FGmgk\n 3 Year_Built       30.2  scale_FGmgk\n 4 Year_Remod_Add   20.9  scale_FGmgk\n 5 Mas_Vnr_Area    179.   scale_FGmgk\n 6 BsmtFin_SF_1      2.23 scale_FGmgk\n 7 BsmtFin_SF_2    169.   scale_FGmgk\n 8 Bsmt_Unf_SF     440.   scale_FGmgk\n 9 Total_Bsmt_SF   441.   scale_FGmgk\n10 First_Flr_SF    392.   scale_FGmgk\n# ℹ 23 more rows\n\n\nWe could also have used step_center() and step_scale() together in one recipe\n\ncenter_scale_rec &lt;- recipe(Sale_Price ~ ., data = ames) |&gt;\n  step_center(all_numeric_predictors()) |&gt;\n  step_scale(all_numeric_predictors()) |&gt;\n  prep()\n\ncenter_scale_rec |&gt;\n  bake(new_data = NULL, Sale_Price, Lot_Area, Wood_Deck_SF, Mas_Vnr_Area)\n\n# A tibble: 2,930 × 4\n   Sale_Price Lot_Area Wood_Deck_SF Mas_Vnr_Area\n        &lt;int&gt;    &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n 1     215000   2.74          0.920       0.0610\n 2     105000   0.187         0.366      -0.566 \n 3     172000   0.523         2.37        0.0386\n 4     244000   0.128        -0.742      -0.566 \n 5     189900   0.467         0.936      -0.566 \n 6     195500  -0.0216        2.11       -0.454 \n 7     213500  -0.663        -0.742      -0.566 \n 8     191500  -0.653        -0.742      -0.566 \n 9     236500  -0.604         1.13       -0.566 \n10     189000  -0.336         0.366      -0.566 \n# ℹ 2,920 more rows\n\n\nUsing tidy() we can see information about each step\n\ncenter_scale_rec |&gt;\n  tidy()\n\n# A tibble: 2 × 6\n  number operation type   trained skip  id          \n   &lt;int&gt; &lt;chr&gt;     &lt;chr&gt;  &lt;lgl&gt;   &lt;lgl&gt; &lt;chr&gt;       \n1      1 step      center TRUE    FALSE center_tSRk5\n2      2 step      scale  TRUE    FALSE scale_kjP2v \n\n\nAnd we can pull out the means using tidy(1)\n\ncenter_scale_rec |&gt;\n  tidy(1)\n\n# A tibble: 33 × 3\n   terms             value id          \n   &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;       \n 1 Lot_Frontage      57.6  center_tSRk5\n 2 Lot_Area       10148.   center_tSRk5\n 3 Year_Built      1971.   center_tSRk5\n 4 Year_Remod_Add  1984.   center_tSRk5\n 5 Mas_Vnr_Area     101.   center_tSRk5\n 6 BsmtFin_SF_1       4.18 center_tSRk5\n 7 BsmtFin_SF_2      49.7  center_tSRk5\n 8 Bsmt_Unf_SF      559.   center_tSRk5\n 9 Total_Bsmt_SF   1051.   center_tSRk5\n10 First_Flr_SF    1160.   center_tSRk5\n# ℹ 23 more rows\n\n\nand the standard deviation using tidy(2)\n\ncenter_scale_rec |&gt;\n  tidy(2)\n\n# A tibble: 33 × 3\n   terms            value id         \n   &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;      \n 1 Lot_Frontage     33.5  scale_kjP2v\n 2 Lot_Area       7880.   scale_kjP2v\n 3 Year_Built       30.2  scale_kjP2v\n 4 Year_Remod_Add   20.9  scale_kjP2v\n 5 Mas_Vnr_Area    179.   scale_kjP2v\n 6 BsmtFin_SF_1      2.23 scale_kjP2v\n 7 BsmtFin_SF_2    169.   scale_kjP2v\n 8 Bsmt_Unf_SF     440.   scale_kjP2v\n 9 Total_Bsmt_SF   441.   scale_kjP2v\n10 First_Flr_SF    392.   scale_kjP2v\n# ℹ 23 more rows\n\n\nSince these steps often follow each other, we often use the step_normalize() as a shortcut to do both operations in one step\n\nscale_rec &lt;- recipe(Sale_Price ~ ., data = ames) |&gt;\n  step_normalize(all_numeric_predictors()) |&gt;\n  prep()\n\nscale_rec |&gt;\n  bake(new_data = NULL, Sale_Price, Lot_Area, Wood_Deck_SF, Mas_Vnr_Area)\n\n# A tibble: 2,930 × 4\n   Sale_Price Lot_Area Wood_Deck_SF Mas_Vnr_Area\n        &lt;int&gt;    &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n 1     215000   2.74          0.920       0.0610\n 2     105000   0.187         0.366      -0.566 \n 3     172000   0.523         2.37        0.0386\n 4     244000   0.128        -0.742      -0.566 \n 5     189900   0.467         0.936      -0.566 \n 6     195500  -0.0216        2.11       -0.454 \n 7     213500  -0.663        -0.742      -0.566 \n 8     191500  -0.653        -0.742      -0.566 \n 9     236500  -0.604         1.13       -0.566 \n10     189000  -0.336         0.366      -0.566 \n# ℹ 2,920 more rows\n\n\nAnd we can still pull out the means and standard deviations using tidy()\n\nscale_rec |&gt;\n  tidy(1) |&gt;\n  filter(terms %in% c(\"Lot_Area\", \"Wood_Deck_SF\", \"Mas_Vnr_Area\"))\n\n# A tibble: 6 × 4\n  terms        statistic   value id             \n  &lt;chr&gt;        &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;          \n1 Lot_Area     mean      10148.  normalize_ucdPw\n2 Mas_Vnr_Area mean        101.  normalize_ucdPw\n3 Wood_Deck_SF mean         93.8 normalize_ucdPw\n4 Lot_Area     sd         7880.  normalize_ucdPw\n5 Mas_Vnr_Area sd          179.  normalize_ucdPw\n6 Wood_Deck_SF sd          126.  normalize_ucdPw",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Normalization</span>"
    ]
  },
  {
    "objectID": "numeric-normalization.html#python-examples",
    "href": "numeric-normalization.html#python-examples",
    "title": "7  Normalization",
    "section": "7.4 Python Examples",
    "text": "7.4 Python Examples\nWe are using the ames data set for examples. {sklearn} provided the StandardScaler() method we can use. By default we can use this method to perform both the centering and scaling.\n\nfrom feazdata import ames\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler\n\nct = ColumnTransformer(\n    [('normalize', StandardScaler(), ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',  'Mas_Vnr_Area'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('normalize', StandardScaler(),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('normalize', StandardScaler(),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])]) normalize['Sale_Price', 'Lot_Area', 'Wood_Deck_SF', 'Mas_Vnr_Area']  StandardScaler?Documentation for StandardScalerStandardScaler() remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames)\n\n      normalize__Sale_Price  ...  remainder__Latitude\n0                     0.428  ...               42.054\n1                    -0.949  ...               42.053\n2                    -0.110  ...               42.053\n3                     0.791  ...               42.051\n4                     0.114  ...               42.061\n...                     ...  ...                  ...\n2925                 -0.479  ...               41.989\n2926                 -0.623  ...               41.988\n2927                 -0.611  ...               41.987\n2928                 -0.135  ...               41.991\n2929                  0.090  ...               41.989\n\n[2930 rows x 74 columns]\n\n\nTo only perform scaling, you set with_mean=False.\n\nct = ColumnTransformer(\n    [('scaling', StandardScaler(with_mean=False, with_std=True), ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',  'Mas_Vnr_Area'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('scaling', StandardScaler(with_mean=False),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('scaling', StandardScaler(with_mean=False),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])]) scaling['Sale_Price', 'Lot_Area', 'Wood_Deck_SF', 'Mas_Vnr_Area']  StandardScaler?Documentation for StandardScalerStandardScaler(with_mean=False) remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames)\n\n      scaling__Sale_Price  ...  remainder__Latitude\n0                   2.692  ...               42.054\n1                   1.315  ...               42.053\n2                   2.153  ...               42.053\n3                   3.055  ...               42.051\n4                   2.378  ...               42.061\n...                   ...  ...                  ...\n2925                1.784  ...               41.989\n2926                1.640  ...               41.988\n2927                1.653  ...               41.987\n2928                2.128  ...               41.991\n2929                2.354  ...               41.989\n\n[2930 rows x 74 columns]\n\n\nAnd to only perform centering you set with_mean=True.\n\nct = ColumnTransformer(\n    [('centering', StandardScaler(with_mean=True, with_std=False), ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',  'Mas_Vnr_Area'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('centering', StandardScaler(with_std=False),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('centering', StandardScaler(with_std=False),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])]) centering['Sale_Price', 'Lot_Area', 'Wood_Deck_SF', 'Mas_Vnr_Area']  StandardScaler?Documentation for StandardScalerStandardScaler(with_std=False) remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames)\n\n      centering__Sale_Price  ...  remainder__Latitude\n0                  34203.94  ...               42.054\n1                 -75796.06  ...               42.053\n2                  -8796.06  ...               42.053\n3                  63203.94  ...               42.051\n4                   9103.94  ...               42.061\n...                     ...  ...                  ...\n2925              -38296.06  ...               41.989\n2926              -49796.06  ...               41.988\n2927              -48796.06  ...               41.987\n2928              -10796.06  ...               41.991\n2929                7203.94  ...               41.989\n\n[2930 rows x 74 columns]",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Normalization</span>"
    ]
  },
  {
    "objectID": "numeric-range.html",
    "href": "numeric-range.html",
    "title": "8  Range Scaling",
    "section": "",
    "text": "8.1 Range Scaling",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Range Scaling</span>"
    ]
  },
  {
    "objectID": "numeric-range.html#pros-and-cons",
    "href": "numeric-range.html#pros-and-cons",
    "title": "8  Range Scaling",
    "section": "8.2 Pros and Cons",
    "text": "8.2 Pros and Cons\n\n8.2.1 Pros\n\nFast calculations\nTransformation can easily be reversed, making its interpretations easier on the original scale, provided that clipping wasn’t turned on\n\n\n\n8.2.2 Cons\n\nTurning on clipping diminishes the effect of outliers by rounding them up/down\nDoesn’t work with zero variance data as max(x) - min(x) = 0, yielding a division by zero\nCannot be used with sparse data as it isn’t preserved",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Range Scaling</span>"
    ]
  },
  {
    "objectID": "numeric-range.html#r-examples",
    "href": "numeric-range.html#r-examples",
    "title": "8  Range Scaling",
    "section": "8.3 R Examples",
    "text": "8.3 R Examples\nstep_range() clips. Does allow the user to specify range step_minmax() doesn’t clip. Doesn’t allow users to specify a range. A PR is planned to allow users to turn off clipping in step_range()\nWe will be using the ames data set for these examples.\n\nlibrary(recipes)\nlibrary(modeldata)\ndata(\"ames\")\n\names |&gt;\n  select(Sale_Price, Lot_Area, Wood_Deck_SF, Mas_Vnr_Area)\n\n# A tibble: 2,930 × 4\n   Sale_Price Lot_Area Wood_Deck_SF Mas_Vnr_Area\n        &lt;int&gt;    &lt;int&gt;        &lt;int&gt;        &lt;dbl&gt;\n 1     215000    31770          210          112\n 2     105000    11622          140            0\n 3     172000    14267          393          108\n 4     244000    11160            0            0\n 5     189900    13830          212            0\n 6     195500     9978          360           20\n 7     213500     4920            0            0\n 8     191500     5005            0            0\n 9     236500     5389          237            0\n10     189000     7500          140            0\n# ℹ 2,920 more rows\n\n\nWe will be using the step_range() step for this\n\nrange_rec &lt;- recipe(Sale_Price ~ ., data = ames) |&gt;\n  step_range(all_numeric_predictors()) |&gt;\n  prep()\n\nrange_rec |&gt;\n  bake(new_data = NULL, Sale_Price, Lot_Area, Wood_Deck_SF, Mas_Vnr_Area)\n\n# A tibble: 2,930 × 4\n   Sale_Price Lot_Area Wood_Deck_SF Mas_Vnr_Area\n        &lt;int&gt;    &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n 1     215000   0.142        0.147        0.07  \n 2     105000   0.0482       0.0983       0     \n 3     172000   0.0606       0.276        0.0675\n 4     244000   0.0461       0            0     \n 5     189900   0.0586       0.149        0     \n 6     195500   0.0406       0.253        0.0125\n 7     213500   0.0169       0            0     \n 8     191500   0.0173       0            0     \n 9     236500   0.0191       0.166        0     \n10     189000   0.0290       0.0983       0     \n# ℹ 2,920 more rows\n\n\nWe can also pull out what the min and max values were for each variable using tidy()\n\nrange_rec |&gt;\n  tidy(1)\n\n# A tibble: 33 × 4\n   terms            min    max id         \n   &lt;chr&gt;          &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;      \n 1 Lot_Frontage       0    313 range_FGmgk\n 2 Lot_Area        1300 215245 range_FGmgk\n 3 Year_Built      1872   2010 range_FGmgk\n 4 Year_Remod_Add  1950   2010 range_FGmgk\n 5 Mas_Vnr_Area       0   1600 range_FGmgk\n 6 BsmtFin_SF_1       0      7 range_FGmgk\n 7 BsmtFin_SF_2       0   1526 range_FGmgk\n 8 Bsmt_Unf_SF        0   2336 range_FGmgk\n 9 Total_Bsmt_SF      0   6110 range_FGmgk\n10 First_Flr_SF     334   5095 range_FGmgk\n# ℹ 23 more rows\n\n\nusing the min and max arguments we can set different ranges\n\nrange_rec &lt;- recipe(Sale_Price ~ ., data = ames) |&gt;\n  step_range(all_numeric_predictors(), min = -2, max = 2) |&gt;\n  prep()\n\nrange_rec |&gt;\n  bake(new_data = NULL, Sale_Price, Lot_Area, Wood_Deck_SF, Mas_Vnr_Area)\n\n# A tibble: 2,930 × 4\n   Sale_Price Lot_Area Wood_Deck_SF Mas_Vnr_Area\n        &lt;int&gt;    &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n 1     215000    -1.43       -1.41         -1.72\n 2     105000    -1.81       -1.61         -2   \n 3     172000    -1.76       -0.896        -1.73\n 4     244000    -1.82       -2            -2   \n 5     189900    -1.77       -1.40         -2   \n 6     195500    -1.84       -0.989        -1.95\n 7     213500    -1.93       -2            -2   \n 8     191500    -1.93       -2            -2   \n 9     236500    -1.92       -1.33         -2   \n10     189000    -1.88       -1.61         -2   \n# ℹ 2,920 more rows",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Range Scaling</span>"
    ]
  },
  {
    "objectID": "numeric-range.html#python-examples",
    "href": "numeric-range.html#python-examples",
    "title": "8  Range Scaling",
    "section": "8.4 Python Examples",
    "text": "8.4 Python Examples\nWe are using the ames data set for examples. {sklearn} provided the MinMaxScaler() method we can use. By default we can use this method to perform both the centering and scaling.\n\nfrom feazdata import ames\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import MinMaxScaler\n\nct = ColumnTransformer(\n    [('minmax', MinMaxScaler(), ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',  'Mas_Vnr_Area'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('minmax', MinMaxScaler(),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('minmax', MinMaxScaler(),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])]) minmax['Sale_Price', 'Lot_Area', 'Wood_Deck_SF', 'Mas_Vnr_Area']  MinMaxScaler?Documentation for MinMaxScalerMinMaxScaler() remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames)\n\n      minmax__Sale_Price  ...  remainder__Latitude\n0                  0.272  ...               42.054\n1                  0.124  ...               42.053\n2                  0.215  ...               42.053\n3                  0.312  ...               42.051\n4                  0.239  ...               42.061\n...                  ...  ...                  ...\n2925               0.175  ...               41.989\n2926               0.159  ...               41.988\n2927               0.161  ...               41.987\n2928               0.212  ...               41.991\n2929               0.236  ...               41.989\n\n[2930 rows x 74 columns]\n\n\nMinMaxScaler() doesn’t clip by default, we can turn this back on by setting clip=True.\n\nct = ColumnTransformer(\n    [('minmax', MinMaxScaler(clip=True), ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',  'Mas_Vnr_Area'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('minmax', MinMaxScaler(clip=True),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('minmax', MinMaxScaler(clip=True),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])]) minmax['Sale_Price', 'Lot_Area', 'Wood_Deck_SF', 'Mas_Vnr_Area']  MinMaxScaler?Documentation for MinMaxScalerMinMaxScaler(clip=True) remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames)\n\n      minmax__Sale_Price  ...  remainder__Latitude\n0                  0.272  ...               42.054\n1                  0.124  ...               42.053\n2                  0.215  ...               42.053\n3                  0.312  ...               42.051\n4                  0.239  ...               42.061\n...                  ...  ...                  ...\n2925               0.175  ...               41.989\n2926               0.159  ...               41.988\n2927               0.161  ...               41.987\n2928               0.212  ...               41.991\n2929               0.236  ...               41.989\n\n[2930 rows x 74 columns]\n\n\nWe can also set a different range other than (0, 1) with the feature_range argument\n\nct = ColumnTransformer(\n    [('minmax', MinMaxScaler(feature_range=(-1,1)), ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',  'Mas_Vnr_Area'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('minmax', MinMaxScaler(feature_range=(-1, 1)),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('minmax', MinMaxScaler(feature_range=(-1, 1)),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])]) minmax['Sale_Price', 'Lot_Area', 'Wood_Deck_SF', 'Mas_Vnr_Area']  MinMaxScaler?Documentation for MinMaxScalerMinMaxScaler(feature_range=(-1, 1)) remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames)\n\n      minmax__Sale_Price  ...  remainder__Latitude\n0                 -0.455  ...               42.054\n1                 -0.752  ...               42.053\n2                 -0.571  ...               42.053\n3                 -0.377  ...               42.051\n4                 -0.523  ...               42.061\n...                  ...  ...                  ...\n2925              -0.650  ...               41.989\n2926              -0.681  ...               41.988\n2927              -0.679  ...               41.987\n2928              -0.576  ...               41.991\n2929              -0.528  ...               41.989\n\n[2930 rows x 74 columns]",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Range Scaling</span>"
    ]
  },
  {
    "objectID": "numeric-maxabs.html",
    "href": "numeric-maxabs.html",
    "title": "9  Max Abs Scaling",
    "section": "",
    "text": "9.1 Max Abs Scaling",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Max Abs Scaling</span>"
    ]
  },
  {
    "objectID": "numeric-maxabs.html#pros-and-cons",
    "href": "numeric-maxabs.html#pros-and-cons",
    "title": "9  Max Abs Scaling",
    "section": "9.2 Pros and Cons",
    "text": "9.2 Pros and Cons\n\n9.2.1 Pros\n\nFast calculations\nTransformation can easily be reversed, making its interpretations easier on the original scale\nDoesn’t affect sparsity\nCan be used on a zero variance variable. Doesn’t matter much since you likely should get rid of it\n\n\n\n9.2.2 Cons\n\nIs highly affected by outliers",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Max Abs Scaling</span>"
    ]
  },
  {
    "objectID": "numeric-maxabs.html#r-examples",
    "href": "numeric-maxabs.html#r-examples",
    "title": "9  Max Abs Scaling",
    "section": "9.3 R Examples",
    "text": "9.3 R Examples\nWe will be using the ames data set for these examples.\n\n# remotes::install_github(\"emilhvitfeldt/extrasteps\")\nlibrary(recipes)\nlibrary(extrasteps)\nlibrary(modeldata)\ndata(\"ames\")\n\names |&gt;\n  select(Sale_Price, Lot_Area, Wood_Deck_SF, Mas_Vnr_Area)\n\n# A tibble: 2,930 × 4\n   Sale_Price Lot_Area Wood_Deck_SF Mas_Vnr_Area\n        &lt;int&gt;    &lt;int&gt;        &lt;int&gt;        &lt;dbl&gt;\n 1     215000    31770          210          112\n 2     105000    11622          140            0\n 3     172000    14267          393          108\n 4     244000    11160            0            0\n 5     189900    13830          212            0\n 6     195500     9978          360           20\n 7     213500     4920            0            0\n 8     191500     5005            0            0\n 9     236500     5389          237            0\n10     189000     7500          140            0\n# ℹ 2,920 more rows\n\n\nWe will be using the step_maxabs() step for this, and it can be found in the extrasteps extension package.\n\nmaxabs_rec &lt;- recipe(Sale_Price ~ ., data = ames) |&gt;\n  step_maxabs(all_numeric_predictors()) |&gt;\n  prep()\n\nmaxabs_rec |&gt;\n  bake(new_data = NULL, Sale_Price, Lot_Area, Wood_Deck_SF, Mas_Vnr_Area)\n\n# A tibble: 2,930 × 4\n   Sale_Price Lot_Area Wood_Deck_SF Mas_Vnr_Area\n        &lt;int&gt;    &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n 1     215000   0.148        0.147        0.07  \n 2     105000   0.0540       0.0983       0     \n 3     172000   0.0663       0.276        0.0675\n 4     244000   0.0518       0            0     \n 5     189900   0.0643       0.149        0     \n 6     195500   0.0464       0.253        0.0125\n 7     213500   0.0229       0            0     \n 8     191500   0.0233       0            0     \n 9     236500   0.0250       0.166        0     \n10     189000   0.0348       0.0983       0     \n# ℹ 2,920 more rows\n\n\nWe can also pull out what the max values were for each variable using tidy()\n\nmaxabs_rec |&gt;\n  tidy(1)\n\n# A tibble: 33 × 4\n   terms          statistic  value id          \n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;       \n 1 Lot_Frontage   max          313 maxabs_Bp5vK\n 2 Lot_Area       max       215245 maxabs_Bp5vK\n 3 Year_Built     max         2010 maxabs_Bp5vK\n 4 Year_Remod_Add max         2010 maxabs_Bp5vK\n 5 Mas_Vnr_Area   max         1600 maxabs_Bp5vK\n 6 BsmtFin_SF_1   max            7 maxabs_Bp5vK\n 7 BsmtFin_SF_2   max         1526 maxabs_Bp5vK\n 8 Bsmt_Unf_SF    max         2336 maxabs_Bp5vK\n 9 Total_Bsmt_SF  max         6110 maxabs_Bp5vK\n10 First_Flr_SF   max         5095 maxabs_Bp5vK\n# ℹ 23 more rows",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Max Abs Scaling</span>"
    ]
  },
  {
    "objectID": "numeric-maxabs.html#python-examples",
    "href": "numeric-maxabs.html#python-examples",
    "title": "9  Max Abs Scaling",
    "section": "9.4 Python Examples",
    "text": "9.4 Python Examples\nWe are using the ames data set for examples. {sklearn} provided the MaxAbsScaler() method we can use.\n\nfrom feazdata import ames\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import MaxAbsScaler\n\nct = ColumnTransformer(\n    [('maxabs', MaxAbsScaler(), ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',  'Mas_Vnr_Area'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('maxabs', MaxAbsScaler(),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('maxabs', MaxAbsScaler(),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])]) maxabs['Sale_Price', 'Lot_Area', 'Wood_Deck_SF', 'Mas_Vnr_Area']  MaxAbsScaler?Documentation for MaxAbsScalerMaxAbsScaler() remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames)\n\n      maxabs__Sale_Price  ...  remainder__Latitude\n0                  0.285  ...               42.054\n1                  0.139  ...               42.053\n2                  0.228  ...               42.053\n3                  0.323  ...               42.051\n4                  0.252  ...               42.061\n...                  ...  ...                  ...\n2925               0.189  ...               41.989\n2926               0.174  ...               41.988\n2927               0.175  ...               41.987\n2928               0.225  ...               41.991\n2929               0.249  ...               41.989\n\n[2930 rows x 74 columns]",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Max Abs Scaling</span>"
    ]
  },
  {
    "objectID": "numeric-robust.html",
    "href": "numeric-robust.html",
    "title": "10  Robust Scaling",
    "section": "",
    "text": "10.1 Robust Scaling",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Robust Scaling</span>"
    ]
  },
  {
    "objectID": "numeric-robust.html#pros-and-cons",
    "href": "numeric-robust.html#pros-and-cons",
    "title": "10  Robust Scaling",
    "section": "10.2 Pros and Cons",
    "text": "10.2 Pros and Cons\n\n10.2.1 Pros\n\nIsn’t affected by outliers\nTransformation can easily be reversed, making its interpretations easier on the original scale\n\n\n\n10.2.2 Cons\n\nCompletely ignores part of the data outside the quantile ranges\nDoesn’t work with near zero variance data as Q1(x) - Q3(x) = 0, yielding a division by zero\nCannot be used with sparse data as it isn’t preserved",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Robust Scaling</span>"
    ]
  },
  {
    "objectID": "numeric-robust.html#r-examples",
    "href": "numeric-robust.html#r-examples",
    "title": "10  Robust Scaling",
    "section": "10.3 R Examples",
    "text": "10.3 R Examples\nWe will be using the ames data set for these examples.\n\n# remotes::install_github(\"emilhvitfeldt/extrasteps\")\nlibrary(recipes)\nlibrary(extrasteps)\nlibrary(modeldata)\ndata(\"ames\")\n\names |&gt;\n  select(Sale_Price, Lot_Area, Wood_Deck_SF, Mas_Vnr_Area)\n\n# A tibble: 2,930 × 4\n   Sale_Price Lot_Area Wood_Deck_SF Mas_Vnr_Area\n        &lt;int&gt;    &lt;int&gt;        &lt;int&gt;        &lt;dbl&gt;\n 1     215000    31770          210          112\n 2     105000    11622          140            0\n 3     172000    14267          393          108\n 4     244000    11160            0            0\n 5     189900    13830          212            0\n 6     195500     9978          360           20\n 7     213500     4920            0            0\n 8     191500     5005            0            0\n 9     236500     5389          237            0\n10     189000     7500          140            0\n# ℹ 2,920 more rows\n\n\nWe will be using the step_robust() step for this, and it can be found in the extrasteps extension package.\n\nmaxabs_rec &lt;- recipe(Sale_Price ~ ., data = ames) |&gt;\n  step_robust(all_numeric_predictors()) |&gt;\n  prep()\n\nmaxabs_rec |&gt;\n  bake(new_data = NULL, Sale_Price, Lot_Area, Wood_Deck_SF, Mas_Vnr_Area)\n\n# A tibble: 2,930 × 4\n   Sale_Price Lot_Area Wood_Deck_SF Mas_Vnr_Area\n        &lt;int&gt;    &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n 1     215000    5.43         1.25         0.688\n 2     105000    0.531        0.833        0    \n 3     172000    1.17         2.34         0.664\n 4     244000    0.419        0            0    \n 5     189900    1.07         1.26         0    \n 6     195500    0.132        2.14         0.123\n 7     213500   -1.10         0            0    \n 8     191500   -1.08         0            0    \n 9     236500   -0.984        1.41         0    \n10     189000   -0.471        0.833        0    \n# ℹ 2,920 more rows\n\n\nWe can also pull out what the max values were for each variable using tidy()\n\nmaxabs_rec |&gt;\n  tidy(1)\n\n# A tibble: 99 × 4\n   terms          statistic  value id          \n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;       \n 1 Lot_Frontage   lower        43  robust_Bp5vK\n 2 Lot_Frontage   median       63  robust_Bp5vK\n 3 Lot_Frontage   higher       78  robust_Bp5vK\n 4 Lot_Area       lower      7440. robust_Bp5vK\n 5 Lot_Area       median     9436. robust_Bp5vK\n 6 Lot_Area       higher    11555. robust_Bp5vK\n 7 Year_Built     lower      1954  robust_Bp5vK\n 8 Year_Built     median     1973  robust_Bp5vK\n 9 Year_Built     higher     2001  robust_Bp5vK\n10 Year_Remod_Add lower      1965  robust_Bp5vK\n# ℹ 89 more rows\n\n\nWe can also change the default range to allow more of the distribution to affect the calculations. This is done using the range argument.\n\nmaxabs_rec &lt;- recipe(Sale_Price ~ ., data = ames) |&gt;\n  step_robust(all_numeric_predictors(), range = c(0.1, 0.9)) |&gt;\n  prep()\n\nmaxabs_rec |&gt;\n  bake(new_data = NULL, Sale_Price, Lot_Area, Wood_Deck_SF, Mas_Vnr_Area)\n\n# A tibble: 2,930 × 4\n   Sale_Price Lot_Area Wood_Deck_SF Mas_Vnr_Area\n        &lt;int&gt;    &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n 1     215000   2.35          0.820       0.350 \n 2     105000   0.230         0.547       0     \n 3     172000   0.509         1.53        0.337 \n 4     244000   0.181         0           0     \n 5     189900   0.463         0.828       0     \n 6     195500   0.0570        1.41        0.0625\n 7     213500  -0.475         0           0     \n 8     191500  -0.467         0           0     \n 9     236500  -0.426         0.925       0     \n10     189000  -0.204         0.547       0     \n# ℹ 2,920 more rows\n\n\nwhen we pull out the ranges, we see that they are wider\n\nmaxabs_rec |&gt;\n  tidy(1)\n\n# A tibble: 99 × 4\n   terms          statistic  value id          \n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;       \n 1 Lot_Frontage   lower         0  robust_RUieL\n 2 Lot_Frontage   median       63  robust_RUieL\n 3 Lot_Frontage   higher       91  robust_RUieL\n 4 Lot_Area       lower      4800  robust_RUieL\n 5 Lot_Area       median     9436. robust_RUieL\n 6 Lot_Area       higher    14299. robust_RUieL\n 7 Year_Built     lower      1925. robust_RUieL\n 8 Year_Built     median     1973  robust_RUieL\n 9 Year_Built     higher     2006  robust_RUieL\n10 Year_Remod_Add lower      1950  robust_RUieL\n# ℹ 89 more rows",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Robust Scaling</span>"
    ]
  },
  {
    "objectID": "numeric-robust.html#python-examples",
    "href": "numeric-robust.html#python-examples",
    "title": "10  Robust Scaling",
    "section": "10.4 Python Examples",
    "text": "10.4 Python Examples\nWe are using the ames data set for examples. {sklearn} provided the RobustScaler() method we can use.\n\nfrom feazdata import ames\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import RobustScaler\n\nct = ColumnTransformer(\n    [('robust', RobustScaler(), ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',  'Mas_Vnr_Area'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('robust', RobustScaler(),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('robust', RobustScaler(),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])]) robust['Sale_Price', 'Lot_Area', 'Wood_Deck_SF', 'Mas_Vnr_Area']  RobustScaler?Documentation for RobustScalerRobustScaler() remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames)\n\n      robust__Sale_Price  ...  remainder__Latitude\n0                  0.655  ...               42.054\n1                 -0.655  ...               42.053\n2                  0.143  ...               42.053\n3                  1.000  ...               42.051\n4                  0.356  ...               42.061\n...                  ...  ...                  ...\n2925              -0.208  ...               41.989\n2926              -0.345  ...               41.988\n2927              -0.333  ...               41.987\n2928               0.119  ...               41.991\n2929               0.333  ...               41.989\n\n[2930 rows x 74 columns]\n\n\nWe can also change the default range (0.25, 0.75) to allow more of the distribution to affect the calculations. This is done using the quantile_range argument.\n\nct = ColumnTransformer(\n    [('robust', RobustScaler(quantile_range=(10.0, 90.0)), ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',  'Mas_Vnr_Area'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('robust',\n                                 RobustScaler(quantile_range=(10.0, 90.0)),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('robust',\n                                 RobustScaler(quantile_range=(10.0, 90.0)),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])]) robust['Sale_Price', 'Lot_Area', 'Wood_Deck_SF', 'Mas_Vnr_Area']  RobustScaler?Documentation for RobustScalerRobustScaler(quantile_range=(10.0, 90.0)) remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames)\n\n      robust__Sale_Price  ...  remainder__Latitude\n0                  0.313  ...               42.054\n1                 -0.313  ...               42.053\n2                  0.068  ...               42.053\n3                  0.478  ...               42.051\n4                  0.170  ...               42.061\n...                  ...  ...                  ...\n2925              -0.100  ...               41.989\n2926              -0.165  ...               41.988\n2927              -0.159  ...               41.987\n2928               0.057  ...               41.991\n2929               0.159  ...               41.989\n\n[2930 rows x 74 columns]",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Robust Scaling</span>"
    ]
  },
  {
    "objectID": "numeric-binning.html",
    "href": "numeric-binning.html",
    "title": "11  Binning",
    "section": "",
    "text": "11.1 Binning",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Binning</span>"
    ]
  },
  {
    "objectID": "numeric-binning.html#pros-and-cons",
    "href": "numeric-binning.html#pros-and-cons",
    "title": "11  Binning",
    "section": "11.2 Pros and Cons",
    "text": "11.2 Pros and Cons\n\n11.2.1 Pros\n\nWorks fast computationally\nBehaves predictably outside the range of the predictors\nIf cuts are placed well, it can handle sudden changes in distributions\nInterpretable\ndoesn’t create correlated features\n\n\n\n11.2.2 Cons\n\nThe inherent rounding that happens, can lead to loss of performance and interpretations\narguably less interpretable than binning\ncan produce a lot of variables",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Binning</span>"
    ]
  },
  {
    "objectID": "numeric-binning.html#r-examples",
    "href": "numeric-binning.html#r-examples",
    "title": "11  Binning",
    "section": "11.3 R Examples",
    "text": "11.3 R Examples\nWe will be using the ames data set for these examples.\n\nlibrary(recipes)\nlibrary(modeldata)\n\names |&gt;\n  select(Lot_Area, Year_Built)\n\n# A tibble: 2,930 × 2\n   Lot_Area Year_Built\n      &lt;int&gt;      &lt;int&gt;\n 1    31770       1960\n 2    11622       1961\n 3    14267       1958\n 4    11160       1968\n 5    13830       1997\n 6     9978       1998\n 7     4920       2001\n 8     5005       1992\n 9     5389       1995\n10     7500       1999\n# ℹ 2,920 more rows\n\n\n{recipes} has the function step_discretize() for just this occasion.\n\nbin_rec &lt;- recipe(~ Lot_Area + Year_Built, data = ames) |&gt;\n  step_discretize(Lot_Area, Year_Built)\n\nbin_rec |&gt;\n  prep() |&gt;\n  bake(new_data = NULL) |&gt;\n  glimpse()\n\nRows: 2,930\nColumns: 2\n$ Lot_Area   &lt;fct&gt; bin4, bin4, bin4, bin3, bin4, bin3, bin1, bin1, bin1, bin2,…\n$ Year_Built &lt;fct&gt; bin2, bin2, bin2, bin2, bin3, bin3, bin3, bin3, bin3, bin3,…\n\n\nIf you don’t like the default number of breaks created, you can use the num_breaks = 6 argument to change it.\n\nbin_rec &lt;- recipe(~ Lot_Area + Year_Built, data = ames) |&gt;\n  step_discretize(Lot_Area, Year_Built, num_breaks = 6)\n\nbin_rec |&gt;\n  prep() |&gt;\n  bake(new_data = NULL) |&gt;\n  glimpse()\n\nRows: 2,930\nColumns: 2\n$ Lot_Area   &lt;fct&gt; bin6, bin5, bin6, bin5, bin6, bin4, bin1, bin1, bin1, bin2,…\n$ Year_Built &lt;fct&gt; bin2, bin3, bin2, bin3, bin5, bin5, bin5, bin4, bin4, bin5,…\n\n\nThis step technically creates a factor variable, but we can turn it into a series of indicator functions with step_dummy()\n\nbin_rec &lt;- recipe(~ Lot_Area + Year_Built, data = ames) |&gt;\n  step_discretize(Lot_Area, Year_Built, num_breaks = 6) |&gt;\n  step_dummy(Lot_Area, Year_Built, one_hot = TRUE)\n\nbin_rec |&gt;\n  prep() |&gt;\n  bake(new_data = NULL) |&gt;\n  glimpse()\n\nRows: 2,930\nColumns: 12\n$ Lot_Area_bin1   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Lot_Area_bin2   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, …\n$ Lot_Area_bin3   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, …\n$ Lot_Area_bin4   &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, …\n$ Lot_Area_bin5   &lt;dbl&gt; 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, …\n$ Lot_Area_bin6   &lt;dbl&gt; 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ Year_Built_bin1 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Year_Built_bin2 &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Year_Built_bin3 &lt;dbl&gt; 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Year_Built_bin4 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, …\n$ Year_Built_bin5 &lt;dbl&gt; 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, …\n$ Year_Built_bin6 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, …",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Binning</span>"
    ]
  },
  {
    "objectID": "numeric-binning.html#python-examples",
    "href": "numeric-binning.html#python-examples",
    "title": "11  Binning",
    "section": "11.4 Python Examples",
    "text": "11.4 Python Examples",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Binning</span>"
    ]
  },
  {
    "objectID": "numeric-splines.html",
    "href": "numeric-splines.html",
    "title": "12  Splines",
    "section": "",
    "text": "12.1 Splines",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Splines</span>"
    ]
  },
  {
    "objectID": "numeric-splines.html#pros-and-cons",
    "href": "numeric-splines.html#pros-and-cons",
    "title": "12  Splines",
    "section": "12.2 Pros and Cons",
    "text": "12.2 Pros and Cons\n\n12.2.1 Pros\n\nWorks fast computationally\nGood performance compared to binning\nis good at handling continuous changes in predictors\n\n\n\n12.2.2 Cons\n\narguably less interpretable than binning\ncreates correlated features\ncan produce a lot of variables\nhave a hard time modeling sudden changes in distributions",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Splines</span>"
    ]
  },
  {
    "objectID": "numeric-splines.html#r-examples",
    "href": "numeric-splines.html#r-examples",
    "title": "12  Splines",
    "section": "12.3 R Examples",
    "text": "12.3 R Examples\nWe will be using the ames data set for these examples.\n\nlibrary(recipes)\nlibrary(modeldata)\n\names |&gt;\n  select(Lot_Area, Year_Built)\n\n# A tibble: 2,930 × 2\n   Lot_Area Year_Built\n      &lt;int&gt;      &lt;int&gt;\n 1    31770       1960\n 2    11622       1961\n 3    14267       1958\n 4    11160       1968\n 5    13830       1997\n 6     9978       1998\n 7     4920       2001\n 8     5005       1992\n 9     5389       1995\n10     7500       1999\n# ℹ 2,920 more rows\n\n\n{recipes} provides a number of steps to perform spline operations, each of them starting with step_spline_. Let us use a B-spline and a M-spline as examples here:\n\nlog_rec &lt;- recipe(~ Lot_Area + Year_Built, data = ames) |&gt;\n  step_spline_b(Lot_Area) |&gt;\n  step_spline_monotone(Year_Built)\n\nlog_rec |&gt;\n  prep() |&gt;\n  bake(new_data = NULL) |&gt;\n  glimpse()\n\nRows: 2,930\nColumns: 20\n$ Lot_Area_01   &lt;dbl&gt; 0.000000000, 0.000000000, 0.000000000, 0.000000000, 0.00…\n$ Lot_Area_02   &lt;dbl&gt; 0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00, …\n$ Lot_Area_03   &lt;dbl&gt; 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0…\n$ Lot_Area_04   &lt;dbl&gt; 0.0000000000, 0.0000000000, 0.0000000000, 0.0000000000, …\n$ Lot_Area_05   &lt;dbl&gt; 0.0000000000, 0.0000000000, 0.0000000000, 0.0078526499, …\n$ Lot_Area_06   &lt;dbl&gt; 0.000000000, 0.283603274, 0.000000000, 0.507327055, 0.00…\n$ Lot_Area_07   &lt;dbl&gt; 0.73399934, 0.71382012, 0.96474057, 0.48414256, 0.971047…\n$ Lot_Area_08   &lt;dbl&gt; 2.408258e-01, 2.576602e-03, 3.503161e-02, 6.777374e-04, …\n$ Lot_Area_09   &lt;dbl&gt; 2.444735e-02, 3.441535e-09, 2.277849e-04, 0.000000e+00, …\n$ Lot_Area_10   &lt;dbl&gt; 7.274651e-04, 0.000000e+00, 3.035128e-08, 0.000000e+00, …\n$ Year_Built_01 &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Year_Built_02 &lt;dbl&gt; 1.0000000, 1.0000000, 1.0000000, 1.0000000, 1.0000000, 1…\n$ Year_Built_03 &lt;dbl&gt; 0.9991483, 0.9995281, 0.9977527, 1.0000000, 1.0000000, 1…\n$ Year_Built_04 &lt;dbl&gt; 0.9041892, 0.9210803, 0.8649607, 0.9884577, 1.0000000, 1…\n$ Year_Built_05 &lt;dbl&gt; 0.20672563, 0.24041792, 0.14882796, 0.54043388, 0.999999…\n$ Year_Built_06 &lt;dbl&gt; 4.792231e-04, 1.169978e-03, 2.995144e-05, 3.881537e-02, …\n$ Year_Built_07 &lt;dbl&gt; 0.000000e+00, 0.000000e+00, 0.000000e+00, 4.491099e-07, …\n$ Year_Built_08 &lt;dbl&gt; 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.221125…\n$ Year_Built_09 &lt;dbl&gt; 0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00, …\n$ Year_Built_10 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,…\n\n\nWe can set the deg_free argument to specify how many spline features we want for each of the splines.\n\nlog_rec &lt;- recipe(~ Lot_Area + Year_Built, data = ames) |&gt;\n  step_spline_b(Lot_Area, deg_free = 3) |&gt;\n  step_spline_monotone(Year_Built, deg_free = 4)\n\nlog_rec |&gt;\n  prep() |&gt;\n  bake(new_data = NULL) |&gt;\n  glimpse()\n\nRows: 2,930\nColumns: 7\n$ Lot_Area_1   &lt;dbl&gt; 0.31422525, 0.13110895, 0.16045431, 0.12580964, 0.1557218…\n$ Lot_Area_2   &lt;dbl&gt; 0.0521839123, 0.0066461383, 0.0103524317, 0.0060782666, 0…\n$ Lot_Area_3   &lt;dbl&gt; 2.888757e-03, 1.123014e-04, 2.226446e-04, 9.788684e-05, 2…\n$ Year_Built_1 &lt;dbl&gt; 0.9827669, 0.9841047, 0.9798397, 0.9914201, 0.9999212, 0.…\n$ Year_Built_2 &lt;dbl&gt; 0.8614458, 0.8686207, 0.8464715, 0.9129756, 0.9968924, 0.…\n$ Year_Built_3 &lt;dbl&gt; 0.5411581, 0.5539857, 0.5156159, 0.6440229, 0.9532064, 0.…\n$ Year_Built_4 &lt;dbl&gt; 0.1653539, 0.1729990, 0.1508264, 0.2341901, 0.6731684, 0.…\n\n\nThese steps have more arguments, so we can change other things. The B-splines created by step_spline_b() default to cubic splines, but we can change that by specifying which polynomial degree with want with the degree argument.\n\nlog_rec &lt;- recipe(~ Lot_Area + Year_Built, data = ames) |&gt;\n  step_spline_b(Lot_Area, deg_free = 3, degree = 1) |&gt;\n  step_spline_monotone(Year_Built, deg_free = 4)\n\nlog_rec |&gt;\n  prep() |&gt;\n  bake(new_data = NULL) |&gt;\n  glimpse()\n\nRows: 2,930\nColumns: 7\n$ Lot_Area_1   &lt;dbl&gt; 0.00000000, 0.00000000, 0.00000000, 0.00000000, 0.0000000…\n$ Lot_Area_2   &lt;dbl&gt; 0.89690903, 0.99540159, 0.98247163, 0.99766006, 0.9846078…\n$ Lot_Area_3   &lt;dbl&gt; 0.103090969, 0.004598405, 0.017528365, 0.002339940, 0.015…\n$ Year_Built_1 &lt;dbl&gt; 0.9827669, 0.9841047, 0.9798397, 0.9914201, 0.9999212, 0.…\n$ Year_Built_2 &lt;dbl&gt; 0.8614458, 0.8686207, 0.8464715, 0.9129756, 0.9968924, 0.…\n$ Year_Built_3 &lt;dbl&gt; 0.5411581, 0.5539857, 0.5156159, 0.6440229, 0.9532064, 0.…\n$ Year_Built_4 &lt;dbl&gt; 0.1653539, 0.1729990, 0.1508264, 0.2341901, 0.6731684, 0.…",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Splines</span>"
    ]
  },
  {
    "objectID": "numeric-splines.html#python-examples",
    "href": "numeric-splines.html#python-examples",
    "title": "12  Splines",
    "section": "12.4 Python Examples",
    "text": "12.4 Python Examples\nWe are using the ames data set for examples. {sklearn} provided the SplineTransformer() method we can use.\n\nfrom feazdata import ames\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import SplineTransformer\n\nct = ColumnTransformer(\n    [('spline', SplineTransformer(), ['Lot_Area'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('spline', SplineTransformer(), ['Lot_Area'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('spline', SplineTransformer(), ['Lot_Area'])]) spline['Lot_Area']  SplineTransformer?Documentation for SplineTransformerSplineTransformer() remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Mas_Vnr_Area', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Sale_Price', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames)\n\n      spline__Lot_Area_sp_0  ...  remainder__Latitude\n0                     0.013  ...               42.054\n1                     0.088  ...               42.053\n2                     0.072  ...               42.053\n3                     0.090  ...               42.051\n4                     0.075  ...               42.061\n...                     ...  ...                  ...\n2925                  0.112  ...               41.989\n2926                  0.105  ...               41.988\n2927                  0.095  ...               41.987\n2928                  0.098  ...               41.991\n2929                  0.100  ...               41.989\n\n[2930 rows x 80 columns]",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Splines</span>"
    ]
  },
  {
    "objectID": "numeric-polynomial.html",
    "href": "numeric-polynomial.html",
    "title": "13  Polynomial Expansion",
    "section": "",
    "text": "13.1 Polynomial Expansion",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Polynomial Expansion</span>"
    ]
  },
  {
    "objectID": "numeric-polynomial.html#pros-and-cons",
    "href": "numeric-polynomial.html#pros-and-cons",
    "title": "13  Polynomial Expansion",
    "section": "13.2 Pros and Cons",
    "text": "13.2 Pros and Cons\n\n13.2.1 Pros\n\nWorks fast computationally\nGood performance compared to binning\nDoesn’t create correlated features\nis good at handling continuous changes in predictors\n\n\n\n13.2.2 Cons\n\narguably less interpretable than binning and splines\ncan produce a lot of variables\nhave a hard time modeling sudden changes in distributions",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Polynomial Expansion</span>"
    ]
  },
  {
    "objectID": "numeric-polynomial.html#r-examples",
    "href": "numeric-polynomial.html#r-examples",
    "title": "13  Polynomial Expansion",
    "section": "13.3 R Examples",
    "text": "13.3 R Examples\nWe will be using the ames data set for these examples.\n\nlibrary(recipes)\nlibrary(modeldata)\n\names |&gt;\n  select(Lot_Area, Year_Built)\n\n# A tibble: 2,930 × 2\n   Lot_Area Year_Built\n      &lt;int&gt;      &lt;int&gt;\n 1    31770       1960\n 2    11622       1961\n 3    14267       1958\n 4    11160       1968\n 5    13830       1997\n 6     9978       1998\n 7     4920       2001\n 8     5005       1992\n 9     5389       1995\n10     7500       1999\n# ℹ 2,920 more rows\n\n\n{recipes} has the function step_poly() for just this occasion.\n\npoly_rec &lt;- recipe(~ Lot_Area + Year_Built, data = ames) |&gt;\n  step_poly(Lot_Area, Year_Built)\n\npoly_rec |&gt;\n  prep() |&gt;\n  bake(new_data = NULL) |&gt;\n  glimpse()\n\nRows: 2,930\nColumns: 4\n$ Lot_Area_poly_1   &lt;dbl&gt; 5.070030e-02, 3.456477e-03, 9.658577e-03, 2.373161e-…\n$ Lot_Area_poly_2   &lt;dbl&gt; -0.052288355, -0.006139895, -0.013560043, -0.0048015…\n$ Year_Built_poly_1 &lt;dbl&gt; -0.0069377547, -0.0063268386, -0.0081595868, -0.0020…\n$ Year_Built_poly_2 &lt;dbl&gt; -0.0188536923, -0.0189190631, -0.0186090288, -0.0183…\n\n\nIf you don’t like the default number of features created, you can use the degree argument to change it.\n\npoly_rec &lt;- recipe(~ Lot_Area + Year_Built, data = ames) |&gt;\n  step_poly(Lot_Area, Year_Built, degree = 5)\n\npoly_rec |&gt;\n  prep() |&gt;\n  bake(new_data = NULL) |&gt;\n  glimpse()\n\nRows: 2,930\nColumns: 10\n$ Lot_Area_poly_1   &lt;dbl&gt; 5.070030e-02, 3.456477e-03, 9.658577e-03, 2.373161e-…\n$ Lot_Area_poly_2   &lt;dbl&gt; -0.052288355, -0.006139895, -0.013560043, -0.0048015…\n$ Lot_Area_poly_3   &lt;dbl&gt; 0.0024951091, 0.0067956902, 0.0110336270, 0.00588901…\n$ Lot_Area_poly_4   &lt;dbl&gt; 0.0390305341, -0.0078110499, -0.0092519823, -0.00723…\n$ Lot_Area_poly_5   &lt;dbl&gt; -0.0649379780, 0.0051370320, 0.0004088393, 0.0055404…\n$ Year_Built_poly_1 &lt;dbl&gt; -0.0069377547, -0.0063268386, -0.0081595868, -0.0020…\n$ Year_Built_poly_2 &lt;dbl&gt; -0.0188536923, -0.0189190631, -0.0186090288, -0.0183…\n$ Year_Built_poly_3 &lt;dbl&gt; -0.0031709327, -0.0044248985, -0.0006208212, -0.0124…\n$ Year_Built_poly_4 &lt;dbl&gt; 1.420211e-02, 1.311711e-02, 1.609112e-02, 3.358699e-…\n$ Year_Built_poly_5 &lt;dbl&gt; 0.009938840, 0.011096007, 0.007277173, 0.015173692, …\n\n\nwhile you properly shouldn’t, you can turn off the orthogonal polynomials by setting options = list(raw = TRUE).\n\npoly_rec &lt;- recipe(~ Lot_Area + Year_Built, data = ames) |&gt;\n  step_poly(Lot_Area, Year_Built, options = list(raw = TRUE))\n\npoly_rec |&gt;\n  prep() |&gt;\n  bake(new_data = NULL) |&gt;\n  glimpse()\n\nRows: 2,930\nColumns: 4\n$ Lot_Area_poly_1   &lt;dbl&gt; 31770, 11622, 14267, 11160, 13830, 9978, 4920, 5005,…\n$ Lot_Area_poly_2   &lt;dbl&gt; 1009332900, 135070884, 203547289, 124545600, 1912689…\n$ Year_Built_poly_1 &lt;dbl&gt; 1960, 1961, 1958, 1968, 1997, 1998, 2001, 1992, 1995…\n$ Year_Built_poly_2 &lt;dbl&gt; 3841600, 3845521, 3833764, 3873024, 3988009, 3992004…",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Polynomial Expansion</span>"
    ]
  },
  {
    "objectID": "numeric-polynomial.html#python-examples",
    "href": "numeric-polynomial.html#python-examples",
    "title": "13  Polynomial Expansion",
    "section": "13.4 Python Examples",
    "text": "13.4 Python Examples\nWe are using the ames data set for examples. {sklearn} provided the PolynomialFeatures(). We can use it out of the box.\n\nfrom feazdata import ames\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import PolynomialFeatures\n\nct = ColumnTransformer(\n    [('polynomial', PolynomialFeatures(), ['Lot_Area'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('polynomial', PolynomialFeatures(),\n                                 ['Lot_Area'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('polynomial', PolynomialFeatures(),\n                                 ['Lot_Area'])]) polynomial['Lot_Area']  PolynomialFeatures?Documentation for PolynomialFeaturesPolynomialFeatures() remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Mas_Vnr_Area', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Sale_Price', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames)\n\n      polynomial__1  ...  remainder__Latitude\n0               1.0  ...               42.054\n1               1.0  ...               42.053\n2               1.0  ...               42.053\n3               1.0  ...               42.051\n4               1.0  ...               42.061\n...             ...  ...                  ...\n2925            1.0  ...               41.989\n2926            1.0  ...               41.988\n2927            1.0  ...               41.987\n2928            1.0  ...               41.991\n2929            1.0  ...               41.989\n\n[2930 rows x 76 columns]\n\n\nOr we can change the degree using the degree argument\n\nct = ColumnTransformer(\n    [('polynomial', PolynomialFeatures(degree = 4), ['Lot_Area'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('polynomial', PolynomialFeatures(degree=4),\n                                 ['Lot_Area'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('polynomial', PolynomialFeatures(degree=4),\n                                 ['Lot_Area'])]) polynomial['Lot_Area']  PolynomialFeatures?Documentation for PolynomialFeaturesPolynomialFeatures(degree=4) remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Mas_Vnr_Area', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Sale_Price', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames)\n\n      polynomial__1  ...  remainder__Latitude\n0               1.0  ...               42.054\n1               1.0  ...               42.053\n2               1.0  ...               42.053\n3               1.0  ...               42.051\n4               1.0  ...               42.061\n...             ...  ...                  ...\n2925            1.0  ...               41.989\n2926            1.0  ...               41.988\n2927            1.0  ...               41.987\n2928            1.0  ...               41.991\n2929            1.0  ...               41.989\n\n[2930 rows x 78 columns]",
    "crumbs": [
      "Numeric Features",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Polynomial Expansion</span>"
    ]
  },
  {
    "objectID": "categorical.html",
    "href": "categorical.html",
    "title": "14  Categorical Overview",
    "section": "",
    "text": "14.1 Categorical Overview",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Categorical Overview</span>"
    ]
  },
  {
    "objectID": "categorical.html#categorical-to-categorical",
    "href": "categorical.html#categorical-to-categorical",
    "title": "14  Categorical Overview",
    "section": "14.2 Categorical to Categorical",
    "text": "14.2 Categorical to Categorical\nThese methods take a categorical variable and improve them. Whether it means cleaning levels, collapsing levels, or making sure it handles new levels correctly. These Tasks as not always needed depending on the method you are using but they are generally helpful to apply. One method that would have been located here if it wasn’t for the fact that it has a whole section by itself is dealing with missing values as seen in Chapter 41.",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Categorical Overview</span>"
    ]
  },
  {
    "objectID": "categorical.html#categorical-to-numerical",
    "href": "categorical.html#categorical-to-numerical",
    "title": "14  Categorical Overview",
    "section": "14.3 Categorical to Numerical",
    "text": "14.3 Categorical to Numerical\nThe vast majority of the chapters in these chapters concern methods that take a categorical variable and produce one or more numerical variables suitable for modeling. There are quite a lot of different methods, all have upsides and downsides and they will all be explored in the remaining chapters.",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Categorical Overview</span>"
    ]
  },
  {
    "objectID": "categorical-cleaning.html",
    "href": "categorical-cleaning.html",
    "title": "15  Cleaning",
    "section": "",
    "text": "15.1 Cleaning",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Cleaning</span>"
    ]
  },
  {
    "objectID": "categorical-cleaning.html#r-examples",
    "href": "categorical-cleaning.html#r-examples",
    "title": "15  Cleaning",
    "section": "15.2 R examples",
    "text": "15.2 R examples\n\n\n\n\n\n\nTODO\n\n\n\nfind a good data set for these examples\n\n\nUse janitor\ntextrecipes::step_clean_levels()",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Cleaning</span>"
    ]
  },
  {
    "objectID": "categorical-cleaning.html#python-examples",
    "href": "categorical-cleaning.html#python-examples",
    "title": "15  Cleaning",
    "section": "15.3 Python Examples",
    "text": "15.3 Python Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Cleaning</span>"
    ]
  },
  {
    "objectID": "categorical-unseen.html",
    "href": "categorical-unseen.html",
    "title": "16  Unseen Levels",
    "section": "",
    "text": "16.1 Unseen Levels",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Unseen Levels</span>"
    ]
  },
  {
    "objectID": "categorical-unseen.html#r-examples",
    "href": "categorical-unseen.html#r-examples",
    "title": "16  Unseen Levels",
    "section": "16.2 R Examples",
    "text": "16.2 R Examples\nWe will be using the nycflights13 data set. We are downsampling just a bit to only work on the first day and doing a test-train split.\n\nlibrary(recipes)\nlibrary(rsample)\nlibrary(nycflights13)\n\nflights &lt;- flights |&gt;\n  filter(year == 2013, month == 1, day == 1)\n\nset.seed(13630)\nflights_split &lt;- initial_split(flights)\nflights_train &lt;- training(flights_split)\nflights_test &lt;- testing(flights_split)\n\nNow we are doing the cardinal sin by looking at the testing data. But in this case, it is okay because we are doing it for educational purposes.\n\nflights_train |&gt; pull(carrier) |&gt; unique() |&gt; sort()\n\n [1] \"9E\" \"AA\" \"B6\" \"DL\" \"EV\" \"F9\" \"FL\" \"MQ\" \"UA\" \"US\" \"VX\" \"WN\"\n\nflights_test |&gt; pull(carrier) |&gt; unique() |&gt; sort()\n\n [1] \"9E\" \"AA\" \"AS\" \"B6\" \"DL\" \"EV\" \"FL\" \"HA\" \"MQ\" \"UA\" \"US\" \"VX\" \"WN\"\n\n\nNotice that the testing data includes the carrier \"AS\" and \"HA\" but the training data doesn’t know that. Let us see what would happen if we were to calculate dummy variables without doing any adjusting.\n\ndummy_spec &lt;- recipe(arr_delay ~ carrier, data = flights_train) |&gt;\n  step_dummy(carrier)\n\ndummy_spec_prepped &lt;- prep(dummy_spec)\n\nbake(dummy_spec_prepped, new_data = flights_test)\n\nWarning: ! There are new levels in a factor: `AS` and `HA`.\n\n\n# A tibble: 211 × 12\n   arr_delay carrier_AA carrier_B6 carrier_DL carrier_EV carrier_F9 carrier_FL\n       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1        12          0          0          0          0          0          0\n 2         8          1          0          0          0          0          0\n 3       -14          0          0          0          0          0          0\n 4        -6          0          1          0          0          0          0\n 5        -3          1          0          0          0          0          0\n 6       -33          0          0          1          0          0          0\n 7        -7          1          0          0          0          0          0\n 8         5          0          1          0          0          0          0\n 9        31          1          0          0          0          0          0\n10       -10         NA         NA         NA         NA         NA         NA\n# ℹ 201 more rows\n# ℹ 5 more variables: carrier_MQ &lt;dbl&gt;, carrier_UA &lt;dbl&gt;, carrier_US &lt;dbl&gt;,\n#   carrier_VX &lt;dbl&gt;, carrier_WN &lt;dbl&gt;\n\n\nWe get a warning, and if you look at the rows that were affected we see that it produces NAs. Let us now use the function step_novel() that implements the above-described method.\n\nnovel_spec &lt;- recipe(arr_delay ~ carrier, data = flights_train) |&gt;\n  step_novel(carrier) |&gt;\n  step_dummy(carrier) \n\nnovel_spec_prepped &lt;- prep(novel_spec)\n\nbake(novel_spec_prepped, new_data = flights_test)\n\n# A tibble: 211 × 13\n   arr_delay carrier_AA carrier_B6 carrier_DL carrier_EV carrier_F9 carrier_FL\n       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1        12          0          0          0          0          0          0\n 2         8          1          0          0          0          0          0\n 3       -14          0          0          0          0          0          0\n 4        -6          0          1          0          0          0          0\n 5        -3          1          0          0          0          0          0\n 6       -33          0          0          1          0          0          0\n 7        -7          1          0          0          0          0          0\n 8         5          0          1          0          0          0          0\n 9        31          1          0          0          0          0          0\n10       -10          0          0          0          0          0          0\n# ℹ 201 more rows\n# ℹ 6 more variables: carrier_MQ &lt;dbl&gt;, carrier_UA &lt;dbl&gt;, carrier_US &lt;dbl&gt;,\n#   carrier_VX &lt;dbl&gt;, carrier_WN &lt;dbl&gt;, carrier_new &lt;dbl&gt;\n\n\nAnd we see that we get no error or anything.",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Unseen Levels</span>"
    ]
  },
  {
    "objectID": "categorical-unseen.html#python-examples",
    "href": "categorical-unseen.html#python-examples",
    "title": "16  Unseen Levels",
    "section": "16.3 Python Examples",
    "text": "16.3 Python Examples\nI’m not aware of a good way to do this in a scikit-learn way. Please file an issue on github if you know of a good way.",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Unseen Levels</span>"
    ]
  },
  {
    "objectID": "categorical-dummy.html",
    "href": "categorical-dummy.html",
    "title": "17  Dummy Encoding",
    "section": "",
    "text": "17.1 Dummy Encoding",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Dummy Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-dummy.html#dummy-or-one-hot-encoding",
    "href": "categorical-dummy.html#dummy-or-one-hot-encoding",
    "title": "17  Dummy Encoding",
    "section": "17.2 Dummy or one-hot encoding",
    "text": "17.2 Dummy or one-hot encoding\n\n\n\n\n\n\nTODO\n\n\n\nadd diagram\n\n\nThe terms dummy encoding and one-hot encoding get thrown around interchangeably, but they do have different and distinct meanings. One-hot encoding is when you return k variables when you have k different levels. Like we have shown above\n\n\n     cat dog horse\n[1,]   0   1     0\n[2,]   1   0     0\n[3,]   0   0     1\n[4,]   0   1     0\n[5,]   1   0     0\n\n\nDummy encoding on the other hand returns k-1 variables, where the excluded one typically is the first one.\n\n\n     dog horse\n[1,]   1     0\n[2,]   0     0\n[3,]   0     1\n[4,]   1     0\n[5,]   0     0\n\n\nThese two encodings store the same information, even though the dummy encoding has 1 less column. Because we can deduce which observations are cat by finding the rows with all zeros. The main reason why one would use dummy variables is because of what some people call the dummy variable trap. When you use one-hot encoding, you are increasing the likelihood that you run into a collinearity problem. With the above example, if you included an intercept in your model you have that intercept = cat + dog + horse which gives perfect collinearity and would cause some models to error as they aren’t able to handle that.\n\n\n\n\n\n\nNote\n\n\n\nAn intercept is a variable that takes the value 1 for all entries.\n\n\nEven if you don’t include an intercept you could still run into collinearity. Imagine that in addition to the animal variable also creates a one-hot encoding of the home variable taking the two values \"house\" and \"apartment\", you would get the following indicator variables\n\n\n     cat dog horse house apartment\n[1,]   0   1     0     0         1\n[2,]   1   0     0     1         0\n[3,]   0   0     1     0         1\n[4,]   0   1     0     0         1\n[5,]   1   0     0     1         0\n\n\nAnd in this case, we have that house = cat + dog + horse - apartment which again is an example of perfect collinearity. Unless you have a reason to do otherwise I would suggest that you use dummy encoding in your models. Additionally, this leads to slightly smaller models as each categorical variable produces 1 less variable. It is worth noting that the choice between dummy encoding and one-hot encoding does matter for some models such as decision trees. Depending on what types of rules they can use. Being able to write animal == \"cat\" is easier then saying animal != \"dog\" & animal != \"horse\". This is unlikely to be an issue as many tree-based models can work with categorical variables directly without the need for encoding.",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Dummy Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-dummy.html#ordered-factors",
    "href": "categorical-dummy.html#ordered-factors",
    "title": "17  Dummy Encoding",
    "section": "17.3 Ordered factors",
    "text": "17.3 Ordered factors\n\n\n\n\n\n\nTODO\n\n\n\nfinish section",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Dummy Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-dummy.html#contrasts",
    "href": "categorical-dummy.html#contrasts",
    "title": "17  Dummy Encoding",
    "section": "17.4 Contrasts",
    "text": "17.4 Contrasts\n\n\n\n\n\n\nTODO\n\n\n\nfinish section",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Dummy Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-dummy.html#pros-and-cons",
    "href": "categorical-dummy.html#pros-and-cons",
    "title": "17  Dummy Encoding",
    "section": "17.5 Pros and Cons",
    "text": "17.5 Pros and Cons\n\n17.5.1 Pros\n\nVersatile and commonly used\nEasy interpretation\nWill rarely lead to a decrease in performance\n\n\n\n17.5.2 Cons\n\nDoes require fairly clean categorical levels\nCan be quite memory intensive if you have many levels in your categorical variables and you are unable to use sparse representation\nProvides a complete, but not necessarily compact set of variables",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Dummy Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-dummy.html#r-examples",
    "href": "categorical-dummy.html#r-examples",
    "title": "17  Dummy Encoding",
    "section": "17.6 R Examples",
    "text": "17.6 R Examples\nWe will be using the ames data set for these examples. The step_dummy() function allows us to perform dummy encoding and one-hot encoding.\n\nlibrary(recipes)\nlibrary(modeldata)\ndata(\"ames\")\n\names |&gt;\n  select(Sale_Price, MS_SubClass, MS_Zoning)\n\n# A tibble: 2,930 × 3\n   Sale_Price MS_SubClass                         MS_Zoning               \n        &lt;int&gt; &lt;fct&gt;                               &lt;fct&gt;                   \n 1     215000 One_Story_1946_and_Newer_All_Styles Residential_Low_Density \n 2     105000 One_Story_1946_and_Newer_All_Styles Residential_High_Density\n 3     172000 One_Story_1946_and_Newer_All_Styles Residential_Low_Density \n 4     244000 One_Story_1946_and_Newer_All_Styles Residential_Low_Density \n 5     189900 Two_Story_1946_and_Newer            Residential_Low_Density \n 6     195500 Two_Story_1946_and_Newer            Residential_Low_Density \n 7     213500 One_Story_PUD_1946_and_Newer        Residential_Low_Density \n 8     191500 One_Story_PUD_1946_and_Newer        Residential_Low_Density \n 9     236500 One_Story_PUD_1946_and_Newer        Residential_Low_Density \n10     189000 Two_Story_1946_and_Newer            Residential_Low_Density \n# ℹ 2,920 more rows\n\n\nWe can take a quick look at the possible values MS_SubClass takes\n\names |&gt;\n  count(MS_SubClass, sort = TRUE)\n\n# A tibble: 16 × 2\n   MS_SubClass                                   n\n   &lt;fct&gt;                                     &lt;int&gt;\n 1 One_Story_1946_and_Newer_All_Styles        1079\n 2 Two_Story_1946_and_Newer                    575\n 3 One_and_Half_Story_Finished_All_Ages        287\n 4 One_Story_PUD_1946_and_Newer                192\n 5 One_Story_1945_and_Older                    139\n 6 Two_Story_PUD_1946_and_Newer                129\n 7 Two_Story_1945_and_Older                    128\n 8 Split_or_Multilevel                         118\n 9 Duplex_All_Styles_and_Ages                  109\n10 Two_Family_conversion_All_Styles_and_Ages    61\n11 Split_Foyer                                  48\n12 Two_and_Half_Story_All_Ages                  23\n13 One_and_Half_Story_Unfinished_All_Ages       18\n14 PUD_Multilevel_Split_Level_Foyer             17\n15 One_Story_with_Finished_Attic_All_Ages        6\n16 One_and_Half_Story_PUD_All_Ages               1\n\n\nAnd since MS_SubClass is a factor, we can verify that they match and that all the levels are observed\n\names |&gt; pull(MS_SubClass) |&gt; levels()\n\n [1] \"One_Story_1946_and_Newer_All_Styles\"      \n [2] \"One_Story_1945_and_Older\"                 \n [3] \"One_Story_with_Finished_Attic_All_Ages\"   \n [4] \"One_and_Half_Story_Unfinished_All_Ages\"   \n [5] \"One_and_Half_Story_Finished_All_Ages\"     \n [6] \"Two_Story_1946_and_Newer\"                 \n [7] \"Two_Story_1945_and_Older\"                 \n [8] \"Two_and_Half_Story_All_Ages\"              \n [9] \"Split_or_Multilevel\"                      \n[10] \"Split_Foyer\"                              \n[11] \"Duplex_All_Styles_and_Ages\"               \n[12] \"One_Story_PUD_1946_and_Newer\"             \n[13] \"One_and_Half_Story_PUD_All_Ages\"          \n[14] \"Two_Story_PUD_1946_and_Newer\"             \n[15] \"PUD_Multilevel_Split_Level_Foyer\"         \n[16] \"Two_Family_conversion_All_Styles_and_Ages\"\n\n\nWe will be using the step_dummy() step for this, which defaults to creating dummy variables\n\ndummy_rec &lt;- recipe(Sale_Price ~ ., data = ames) |&gt;\n  step_dummy(all_nominal_predictors()) |&gt;\n  prep()\n\ndummy_rec |&gt;\n  bake(new_data = NULL, starts_with(\"MS_SubClass\"), starts_with(\"MS_Zoning\")) |&gt;\n  glimpse()\n\nRows: 2,930\nColumns: 21\n$ MS_SubClass_One_Story_1945_and_Older                  &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_One_Story_with_Finished_Attic_All_Ages    &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_One_and_Half_Story_Unfinished_All_Ages    &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_One_and_Half_Story_Finished_All_Ages      &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_Two_Story_1946_and_Newer                  &lt;dbl&gt; 0, 0, 0, 0, 1, 1…\n$ MS_SubClass_Two_Story_1945_and_Older                  &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_Two_and_Half_Story_All_Ages               &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_Split_or_Multilevel                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_Split_Foyer                               &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_Duplex_All_Styles_and_Ages                &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_One_Story_PUD_1946_and_Newer              &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_One_and_Half_Story_PUD_All_Ages           &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_Two_Story_PUD_1946_and_Newer              &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_PUD_Multilevel_Split_Level_Foyer          &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_Two_Family_conversion_All_Styles_and_Ages &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_Zoning_Residential_High_Density                    &lt;dbl&gt; 0, 1, 0, 0, 0, 0…\n$ MS_Zoning_Residential_Low_Density                     &lt;dbl&gt; 1, 0, 1, 1, 1, 1…\n$ MS_Zoning_Residential_Medium_Density                  &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_Zoning_A_agr                                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_Zoning_C_all                                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_Zoning_I_all                                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n\n\nWe can pull the factor levels for each variable by using tidy(). If a character vector was present in the data set, it would record the observed variables.\n\ndummy_rec |&gt;\n  tidy(1)\n\n# A tibble: 243 × 3\n   terms       columns                                id         \n   &lt;chr&gt;       &lt;chr&gt;                                  &lt;chr&gt;      \n 1 MS_SubClass One_Story_1945_and_Older               dummy_Bp5vK\n 2 MS_SubClass One_Story_with_Finished_Attic_All_Ages dummy_Bp5vK\n 3 MS_SubClass One_and_Half_Story_Unfinished_All_Ages dummy_Bp5vK\n 4 MS_SubClass One_and_Half_Story_Finished_All_Ages   dummy_Bp5vK\n 5 MS_SubClass Two_Story_1946_and_Newer               dummy_Bp5vK\n 6 MS_SubClass Two_Story_1945_and_Older               dummy_Bp5vK\n 7 MS_SubClass Two_and_Half_Story_All_Ages            dummy_Bp5vK\n 8 MS_SubClass Split_or_Multilevel                    dummy_Bp5vK\n 9 MS_SubClass Split_Foyer                            dummy_Bp5vK\n10 MS_SubClass Duplex_All_Styles_and_Ages             dummy_Bp5vK\n# ℹ 233 more rows\n\n\nsetting one_hot = TRUE gives us the complete one-hot encoding results.\n\nonehot_rec &lt;- recipe(Sale_Price ~ ., data = ames) |&gt;\n  step_dummy(all_nominal_predictors(), one_hot = TRUE) |&gt;\n  prep()\n\nonehot_rec |&gt;\n  bake(new_data = NULL, starts_with(\"MS_SubClass\"), starts_with(\"MS_Zoning\")) |&gt;\n  glimpse()\n\nRows: 2,930\nColumns: 23\n$ MS_SubClass_One_Story_1946_and_Newer_All_Styles       &lt;dbl&gt; 1, 1, 1, 1, 0, 0…\n$ MS_SubClass_One_Story_1945_and_Older                  &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_One_Story_with_Finished_Attic_All_Ages    &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_One_and_Half_Story_Unfinished_All_Ages    &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_One_and_Half_Story_Finished_All_Ages      &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_Two_Story_1946_and_Newer                  &lt;dbl&gt; 0, 0, 0, 0, 1, 1…\n$ MS_SubClass_Two_Story_1945_and_Older                  &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_Two_and_Half_Story_All_Ages               &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_Split_or_Multilevel                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_Split_Foyer                               &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_Duplex_All_Styles_and_Ages                &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_One_Story_PUD_1946_and_Newer              &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_One_and_Half_Story_PUD_All_Ages           &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_Two_Story_PUD_1946_and_Newer              &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_PUD_Multilevel_Split_Level_Foyer          &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_SubClass_Two_Family_conversion_All_Styles_and_Ages &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_Zoning_Floating_Village_Residential                &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_Zoning_Residential_High_Density                    &lt;dbl&gt; 0, 1, 0, 0, 0, 0…\n$ MS_Zoning_Residential_Low_Density                     &lt;dbl&gt; 1, 0, 1, 1, 1, 1…\n$ MS_Zoning_Residential_Medium_Density                  &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_Zoning_A_agr                                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_Zoning_C_all                                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0…\n$ MS_Zoning_I_all                                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0…",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Dummy Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-dummy.html#python-examples",
    "href": "categorical-dummy.html#python-examples",
    "title": "17  Dummy Encoding",
    "section": "17.7 Python Examples",
    "text": "17.7 Python Examples\nWe are using the ames data set for examples. {sklearn} provided the OneHotEncoder() method we can use. Below we see how it can be used with the MS_Zoning columns.\n\n\n\n\n\n\nNote\n\n\n\nWe are setting sparse_output=False in this example because we are having transform() return pandas data frames for better printing.\n\n\n\nfrom feazdata import ames\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\nct = ColumnTransformer(\n    [('onehot', OneHotEncoder(sparse_output=False), ['MS_Zoning'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('onehot', OneHotEncoder(sparse_output=False),\n                                 ['MS_Zoning'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('onehot', OneHotEncoder(sparse_output=False),\n                                 ['MS_Zoning'])]) onehot['MS_Zoning']  OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(sparse_output=False) remainder['MS_SubClass', 'Lot_Frontage', 'Lot_Area', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Mas_Vnr_Area', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Sale_Price', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames).filter(regex=(\"MS_Zoning.*\"))\n\n      onehot__MS_Zoning_A_agr  ...  onehot__MS_Zoning_Residential_Medium_Density\n0                         0.0  ...                                           0.0\n1                         0.0  ...                                           0.0\n2                         0.0  ...                                           0.0\n3                         0.0  ...                                           0.0\n4                         0.0  ...                                           0.0\n...                       ...  ...                                           ...\n2925                      0.0  ...                                           0.0\n2926                      0.0  ...                                           0.0\n2927                      0.0  ...                                           0.0\n2928                      0.0  ...                                           0.0\n2929                      0.0  ...                                           0.0\n\n[2930 rows x 7 columns]\n\n\nBy default OneHotEncoder() performs one-hot encoding, we can change this to dummy encoding by setting drop='first'.\n\nct = ColumnTransformer(\n    [('dummy', OneHotEncoder(sparse_output=False, drop='first'), ['MS_Zoning'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('dummy',\n                                 OneHotEncoder(drop='first',\n                                               sparse_output=False),\n                                 ['MS_Zoning'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('dummy',\n                                 OneHotEncoder(drop='first',\n                                               sparse_output=False),\n                                 ['MS_Zoning'])]) dummy['MS_Zoning']  OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(drop='first', sparse_output=False) remainder['MS_SubClass', 'Lot_Frontage', 'Lot_Area', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Mas_Vnr_Area', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Sale_Price', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames).filter(regex=(\"MS_Zoning.*\"))\n\n      dummy__MS_Zoning_C_all  ...  dummy__MS_Zoning_Residential_Medium_Density\n0                        0.0  ...                                          0.0\n1                        0.0  ...                                          0.0\n2                        0.0  ...                                          0.0\n3                        0.0  ...                                          0.0\n4                        0.0  ...                                          0.0\n...                      ...  ...                                          ...\n2925                     0.0  ...                                          0.0\n2926                     0.0  ...                                          0.0\n2927                     0.0  ...                                          0.0\n2928                     0.0  ...                                          0.0\n2929                     0.0  ...                                          0.0\n\n[2930 rows x 6 columns]",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Dummy Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-label.html",
    "href": "categorical-label.html",
    "title": "18  Label Encoding",
    "section": "",
    "text": "18.1 Label Encoding",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Label Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-label.html#pros-and-cons",
    "href": "categorical-label.html#pros-and-cons",
    "title": "18  Label Encoding",
    "section": "18.2 Pros and Cons",
    "text": "18.2 Pros and Cons\n\n18.2.1 Pros\n\nOnly produces a single numeric variable for each categorical variable\nHas a way to handle unseen levels, although poorly\n\n\n\n18.2.2 Cons\n\nOrdering of the levels matters a lot!\nWill very often give inferior performance compared to other methods.",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Label Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-label.html#r-examples",
    "href": "categorical-label.html#r-examples",
    "title": "18  Label Encoding",
    "section": "18.3 R Examples",
    "text": "18.3 R Examples\nWe will be using the ames data set for these examples. The step_dummy() function allows us to perform dummy encoding and one-hot encoding.\n\nlibrary(recipes)\nlibrary(modeldata)\ndata(\"ames\")\n\names |&gt;\n  select(Sale_Price, MS_SubClass, MS_Zoning)\n\n# A tibble: 2,930 × 3\n   Sale_Price MS_SubClass                         MS_Zoning               \n        &lt;int&gt; &lt;fct&gt;                               &lt;fct&gt;                   \n 1     215000 One_Story_1946_and_Newer_All_Styles Residential_Low_Density \n 2     105000 One_Story_1946_and_Newer_All_Styles Residential_High_Density\n 3     172000 One_Story_1946_and_Newer_All_Styles Residential_Low_Density \n 4     244000 One_Story_1946_and_Newer_All_Styles Residential_Low_Density \n 5     189900 Two_Story_1946_and_Newer            Residential_Low_Density \n 6     195500 Two_Story_1946_and_Newer            Residential_Low_Density \n 7     213500 One_Story_PUD_1946_and_Newer        Residential_Low_Density \n 8     191500 One_Story_PUD_1946_and_Newer        Residential_Low_Density \n 9     236500 One_Story_PUD_1946_and_Newer        Residential_Low_Density \n10     189000 Two_Story_1946_and_Newer            Residential_Low_Density \n# ℹ 2,920 more rows\n\n\nLooking at the levels of MS_SubClass we see that levels are set in a specific way. It isn’t alphabetical, but there isn’t one clear order. No clarification of the ordering can be done in the data documentation http://jse.amstat.org/v19n3/decock/DataDocumentation.txt.\n\names |&gt; pull(MS_SubClass) |&gt; levels()\n\n [1] \"One_Story_1946_and_Newer_All_Styles\"      \n [2] \"One_Story_1945_and_Older\"                 \n [3] \"One_Story_with_Finished_Attic_All_Ages\"   \n [4] \"One_and_Half_Story_Unfinished_All_Ages\"   \n [5] \"One_and_Half_Story_Finished_All_Ages\"     \n [6] \"Two_Story_1946_and_Newer\"                 \n [7] \"Two_Story_1945_and_Older\"                 \n [8] \"Two_and_Half_Story_All_Ages\"              \n [9] \"Split_or_Multilevel\"                      \n[10] \"Split_Foyer\"                              \n[11] \"Duplex_All_Styles_and_Ages\"               \n[12] \"One_Story_PUD_1946_and_Newer\"             \n[13] \"One_and_Half_Story_PUD_All_Ages\"          \n[14] \"Two_Story_PUD_1946_and_Newer\"             \n[15] \"PUD_Multilevel_Split_Level_Foyer\"         \n[16] \"Two_Family_conversion_All_Styles_and_Ages\"\n\n\nWe will be using the step_integer() step for this, which defaults to 1-based indexing\n\nlabel_rec &lt;- recipe(Sale_Price ~ ., data = ames) |&gt;\n  step_integer(all_nominal_predictors()) |&gt;\n  prep()\n\nlabel_rec |&gt;\n  bake(new_data = NULL, starts_with(\"MS_SubClass\"), starts_with(\"MS_Zoning\"))\n\n# A tibble: 2,930 × 2\n   MS_SubClass MS_Zoning\n         &lt;int&gt;     &lt;int&gt;\n 1           1         3\n 2           1         2\n 3           1         3\n 4           1         3\n 5           6         3\n 6           6         3\n 7          12         3\n 8          12         3\n 9          12         3\n10           6         3\n# ℹ 2,920 more rows",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Label Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-label.html#python-examples",
    "href": "categorical-label.html#python-examples",
    "title": "18  Label Encoding",
    "section": "18.4 Python Examples",
    "text": "18.4 Python Examples\nWe are using the ames data set for examples. {sklearn} provided the OrdinalEncoder() method we can use. Below we see how it can be used with the MS_Zoning columns. We call this method label encoding only when categories='auto' as it automatically labels 0 to n_categories - 1.\n\nfrom feazdata import ames\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OrdinalEncoder\n\nct = ColumnTransformer(\n    [('label', OrdinalEncoder(categories='auto'), ['MS_Zoning'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('label', OrdinalEncoder(), ['MS_Zoning'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('label', OrdinalEncoder(), ['MS_Zoning'])]) label['MS_Zoning']  OrdinalEncoder?Documentation for OrdinalEncoderOrdinalEncoder() remainder['MS_SubClass', 'Lot_Frontage', 'Lot_Area', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Mas_Vnr_Area', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Sale_Price', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames).filter(regex=\"label.*\")\n\n      label__MS_Zoning\n0                  5.0\n1                  4.0\n2                  5.0\n3                  5.0\n4                  5.0\n...                ...\n2925               5.0\n2926               5.0\n2927               5.0\n2928               5.0\n2929               5.0\n\n[2930 rows x 1 columns]",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Label Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-ordinal.html",
    "href": "categorical-ordinal.html",
    "title": "19  Ordinal Encoding",
    "section": "",
    "text": "19.1 Ordinal Encoding",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Ordinal Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-ordinal.html#pros-and-cons",
    "href": "categorical-ordinal.html#pros-and-cons",
    "title": "19  Ordinal Encoding",
    "section": "19.2 Pros and Cons",
    "text": "19.2 Pros and Cons\n\n19.2.1 Pros\n\nOnly produces a single numeric variable for each categorical variable\nPreserves the natural ordering of ordered values\n\n\n\n19.2.2 Cons\n\nWill very often give inferior performance compared to other methods\nUnseen levels need to be manually specified",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Ordinal Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-ordinal.html#r-examples",
    "href": "categorical-ordinal.html#r-examples",
    "title": "19  Ordinal Encoding",
    "section": "19.3 R Examples",
    "text": "19.3 R Examples\nWe will be using the ames data set for these examples. The step_dummy() function allows us to perform dummy encoding and one-hot encoding.\n\nlibrary(recipes)\nlibrary(modeldata)\ndata(\"ames\")\n\names |&gt;\n  select(Lot_Shape, Land_Slope)\n\n# A tibble: 2,930 × 2\n   Lot_Shape          Land_Slope\n   &lt;fct&gt;              &lt;fct&gt;     \n 1 Slightly_Irregular Gtl       \n 2 Regular            Gtl       \n 3 Slightly_Irregular Gtl       \n 4 Regular            Gtl       \n 5 Slightly_Irregular Gtl       \n 6 Slightly_Irregular Gtl       \n 7 Regular            Gtl       \n 8 Slightly_Irregular Gtl       \n 9 Slightly_Irregular Gtl       \n10 Regular            Gtl       \n# ℹ 2,920 more rows\n\n\nLooking at the levels of Lot_Shape and Land_Slope we see that they match the levels in the documentation http://jse.amstat.org/v19n3/decock/DataDocumentation.txt. Furthermore, these variables are listed as ordinal, they just aren’t denoted like this in this data set.\n\names |&gt; pull(Lot_Shape) |&gt; levels()\n\n[1] \"Regular\"              \"Slightly_Irregular\"   \"Moderately_Irregular\"\n[4] \"Irregular\"           \n\names |&gt; pull(Land_Slope) |&gt; levels()\n\n[1] \"Gtl\" \"Mod\" \"Sev\"\n\n\nWe will fix that by turning them into ordered factors.\n\names &lt;- ames |&gt;\n  mutate(across(.cols = c(Lot_Shape, Land_Slope), .fns = as.ordered))\n\nto perform ordinal encoding we will use the step_ordinalscore() step. This defaults to giving each level values between 1 and n, much like step_integer().\n\nordinal_rec &lt;- recipe(Sale_Price ~ ., data = ames) |&gt;\n  step_ordinalscore(Lot_Shape, Land_Slope) |&gt;\n  prep()\n\nordinal_rec |&gt;\n  bake(new_data = NULL, starts_with(\"Lot_Shape\"), starts_with(\"Land_Slope\"))\n\n# A tibble: 2,930 × 2\n   Lot_Shape Land_Slope\n       &lt;int&gt;      &lt;int&gt;\n 1         2          1\n 2         1          1\n 3         2          1\n 4         1          1\n 5         2          1\n 6         2          1\n 7         1          1\n 8         2          1\n 9         2          1\n10         1          1\n# ℹ 2,920 more rows\n\n\nWhat we can do is define a special transformation function for each of the steps. One way is to use the case_when() function\n\nLot_Shape_transformer &lt;- function(x) {\n  case_when(\n    x == \"Regular\" ~ 0, \n    x == \"Slightly_Irregular\" ~ -1,\n    x == \"Moderately_Irregular\" ~ -5,\n    x == \"Irregular\" ~ -10\n  )\n}\n\nIf you have the values for each of the levels as a vector or data, you can write the function to use that information as well.\n\nLand_Slope_values &lt;- c(Gtl = 0, Mod = 1, Sev = 5)\n\nLand_Slope_transformer &lt;- function(x) {\n  Land_Slope_values[x]\n}\n\nWith these functions, we can now apply them to the respective columns by using the convert argument.\n\nordinal_rec &lt;- recipe(Sale_Price ~ ., data = ames) |&gt;\n  step_ordinalscore(Lot_Shape, convert = Lot_Shape_transformer) |&gt;\n  step_ordinalscore(Land_Slope, convert = Land_Slope_transformer) |&gt;\n  prep()\n\nordinal_rec |&gt;\n  bake(new_data = NULL, starts_with(\"Lot_Shape\"), starts_with(\"Land_Slope\")) |&gt;\n  distinct()\n\n# A tibble: 11 × 2\n   Lot_Shape Land_Slope\n       &lt;int&gt;      &lt;int&gt;\n 1        -1          0\n 2         0          0\n 3        -5          1\n 4        -1          1\n 5         0          1\n 6        -5          0\n 7         0          5\n 8        -1          5\n 9       -10          0\n10        -5          5\n11       -10          5",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Ordinal Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-ordinal.html#python-examples",
    "href": "categorical-ordinal.html#python-examples",
    "title": "19  Ordinal Encoding",
    "section": "19.4 Python Examples",
    "text": "19.4 Python Examples\nI’m not aware of a good way to do this in a scikit-learn way. Please file an issue on github if you know of a good way.",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Ordinal Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-binary.html",
    "href": "categorical-binary.html",
    "title": "20  Binary Encoding",
    "section": "",
    "text": "20.1 Binary Encoding",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Binary Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-binary.html#pros-and-cons",
    "href": "categorical-binary.html#pros-and-cons",
    "title": "20  Binary Encoding",
    "section": "20.2 Pros and Cons",
    "text": "20.2 Pros and Cons\n\n20.2.1 Pros\n\nuses fewer variables to store the same information as dummy encoding\n\n\n\n20.2.2 Cons\n\nLess interpretability compared to dummy variables",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Binary Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-binary.html#r-examples",
    "href": "categorical-binary.html#r-examples",
    "title": "20  Binary Encoding",
    "section": "20.3 R Examples",
    "text": "20.3 R Examples\nWe will be using the ames data set for these examples. The step_encoding_binary() function from the extrasteps package allows us to perform binary encoding.\n\nlibrary(recipes)\nlibrary(extrasteps)\nlibrary(modeldata)\ndata(\"ames\")\n\names |&gt;\n  select(Sale_Price, MS_SubClass, MS_Zoning)\n\n# A tibble: 2,930 × 3\n   Sale_Price MS_SubClass                         MS_Zoning               \n        &lt;int&gt; &lt;fct&gt;                               &lt;fct&gt;                   \n 1     215000 One_Story_1946_and_Newer_All_Styles Residential_Low_Density \n 2     105000 One_Story_1946_and_Newer_All_Styles Residential_High_Density\n 3     172000 One_Story_1946_and_Newer_All_Styles Residential_Low_Density \n 4     244000 One_Story_1946_and_Newer_All_Styles Residential_Low_Density \n 5     189900 Two_Story_1946_and_Newer            Residential_Low_Density \n 6     195500 Two_Story_1946_and_Newer            Residential_Low_Density \n 7     213500 One_Story_PUD_1946_and_Newer        Residential_Low_Density \n 8     191500 One_Story_PUD_1946_and_Newer        Residential_Low_Density \n 9     236500 One_Story_PUD_1946_and_Newer        Residential_Low_Density \n10     189000 Two_Story_1946_and_Newer            Residential_Low_Density \n# ℹ 2,920 more rows\n\n\nWe can take a quick look at the possible values MS_SubClass takes\n\names |&gt;\n  count(MS_SubClass, sort = TRUE)\n\n# A tibble: 16 × 2\n   MS_SubClass                                   n\n   &lt;fct&gt;                                     &lt;int&gt;\n 1 One_Story_1946_and_Newer_All_Styles        1079\n 2 Two_Story_1946_and_Newer                    575\n 3 One_and_Half_Story_Finished_All_Ages        287\n 4 One_Story_PUD_1946_and_Newer                192\n 5 One_Story_1945_and_Older                    139\n 6 Two_Story_PUD_1946_and_Newer                129\n 7 Two_Story_1945_and_Older                    128\n 8 Split_or_Multilevel                         118\n 9 Duplex_All_Styles_and_Ages                  109\n10 Two_Family_conversion_All_Styles_and_Ages    61\n11 Split_Foyer                                  48\n12 Two_and_Half_Story_All_Ages                  23\n13 One_and_Half_Story_Unfinished_All_Ages       18\n14 PUD_Multilevel_Split_Level_Foyer             17\n15 One_Story_with_Finished_Attic_All_Ages        6\n16 One_and_Half_Story_PUD_All_Ages               1\n\n\nWe can then apply binary encoding using step_encoding_binary(). Notice how we only get 1 numeric variable for each categorical variable\n\ndummy_rec &lt;- recipe(Sale_Price ~ ., data = ames) |&gt;\n  step_encoding_binary(all_nominal_predictors()) |&gt;\n  prep()\n\ndummy_rec |&gt;\n  bake(new_data = NULL, starts_with(\"MS_SubClass\"), starts_with(\"MS_Zoning\")) |&gt;\n  glimpse()\n\nRows: 2,930\nColumns: 9\n$ MS_SubClass_1  &lt;int&gt; 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1…\n$ MS_SubClass_2  &lt;int&gt; 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0…\n$ MS_SubClass_4  &lt;int&gt; 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0…\n$ MS_SubClass_8  &lt;int&gt; 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0…\n$ MS_SubClass_16 &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ MS_Zoning_1    &lt;int&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ MS_Zoning_2    &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ MS_Zoning_4    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ MS_Zoning_8    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\nWe can pull the number of distinct levels of each variable by using tidy().\n\ndummy_rec |&gt;\n  tidy(1)\n\n# A tibble: 40 × 3\n   terms        value id                   \n   &lt;chr&gt;        &lt;int&gt; &lt;chr&gt;                \n 1 MS_SubClass     16 encoding_binary_Bp5vK\n 2 MS_Zoning        7 encoding_binary_Bp5vK\n 3 Street           2 encoding_binary_Bp5vK\n 4 Alley            3 encoding_binary_Bp5vK\n 5 Lot_Shape        4 encoding_binary_Bp5vK\n 6 Land_Contour     4 encoding_binary_Bp5vK\n 7 Utilities        3 encoding_binary_Bp5vK\n 8 Lot_Config       5 encoding_binary_Bp5vK\n 9 Land_Slope       3 encoding_binary_Bp5vK\n10 Neighborhood    29 encoding_binary_Bp5vK\n# ℹ 30 more rows",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Binary Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-binary.html#python-examples",
    "href": "categorical-binary.html#python-examples",
    "title": "20  Binary Encoding",
    "section": "20.4 Python Examples",
    "text": "20.4 Python Examples\nWe are using the ames data set for examples. {category_encoders} provided the BinaryEncoder() method we can use.\n\nfrom feazdata import ames\nfrom sklearn.compose import ColumnTransformer\nfrom category_encoders.binary import BinaryEncoder\n\nct = ColumnTransformer(\n    [('binary', BinaryEncoder(), ['MS_Zoning'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('binary', BinaryEncoder(), ['MS_Zoning'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('binary', BinaryEncoder(), ['MS_Zoning'])]) binary['MS_Zoning'] BinaryEncoderBinaryEncoder() remainder['MS_SubClass', 'Lot_Frontage', 'Lot_Area', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Mas_Vnr_Area', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Sale_Price', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames).filter(regex=\"binary.*\")\n\n      binary__MS_Zoning_0  binary__MS_Zoning_1  binary__MS_Zoning_2\n0                       0                    0                    1\n1                       0                    1                    0\n2                       0                    0                    1\n3                       0                    0                    1\n4                       0                    0                    1\n...                   ...                  ...                  ...\n2925                    0                    0                    1\n2926                    0                    0                    1\n2927                    0                    0                    1\n2928                    0                    0                    1\n2929                    0                    0                    1\n\n[2930 rows x 3 columns]",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Binary Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-frequency.html",
    "href": "categorical-frequency.html",
    "title": "21  Frequency Encoding",
    "section": "",
    "text": "21.1 Frequency Encoding",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Frequency Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-frequency.html#pros-and-cons",
    "href": "categorical-frequency.html#pros-and-cons",
    "title": "21  Frequency Encoding",
    "section": "21.2 Pros and Cons",
    "text": "21.2 Pros and Cons\n\n21.2.1 Pros\n\nPowerful and simple when used correctly\nHigh interpretability\n\n\n\n21.2.2 Cons\n\nIs not able to distinguish between two levels that have the same frequency\nMay not add predictive power",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Frequency Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-frequency.html#r-examples",
    "href": "categorical-frequency.html#r-examples",
    "title": "21  Frequency Encoding",
    "section": "21.3 R Examples",
    "text": "21.3 R Examples\nWe will be using the ames data set for these examples. The step_encoding_frequency() function from the extrasteps package allows us to perform frequency encoding.\n\nlibrary(recipes)\nlibrary(extrasteps)\nlibrary(modeldata)\ndata(\"ames\")\n\names |&gt;\n  select(Sale_Price, MS_SubClass, MS_Zoning)\n\n# A tibble: 2,930 × 3\n   Sale_Price MS_SubClass                         MS_Zoning               \n        &lt;int&gt; &lt;fct&gt;                               &lt;fct&gt;                   \n 1     215000 One_Story_1946_and_Newer_All_Styles Residential_Low_Density \n 2     105000 One_Story_1946_and_Newer_All_Styles Residential_High_Density\n 3     172000 One_Story_1946_and_Newer_All_Styles Residential_Low_Density \n 4     244000 One_Story_1946_and_Newer_All_Styles Residential_Low_Density \n 5     189900 Two_Story_1946_and_Newer            Residential_Low_Density \n 6     195500 Two_Story_1946_and_Newer            Residential_Low_Density \n 7     213500 One_Story_PUD_1946_and_Newer        Residential_Low_Density \n 8     191500 One_Story_PUD_1946_and_Newer        Residential_Low_Density \n 9     236500 One_Story_PUD_1946_and_Newer        Residential_Low_Density \n10     189000 Two_Story_1946_and_Newer            Residential_Low_Density \n# ℹ 2,920 more rows\n\n\nWe can take a quick look at the possible values MS_SubClass takes\n\names |&gt;\n  count(MS_SubClass, sort = TRUE)\n\n# A tibble: 16 × 2\n   MS_SubClass                                   n\n   &lt;fct&gt;                                     &lt;int&gt;\n 1 One_Story_1946_and_Newer_All_Styles        1079\n 2 Two_Story_1946_and_Newer                    575\n 3 One_and_Half_Story_Finished_All_Ages        287\n 4 One_Story_PUD_1946_and_Newer                192\n 5 One_Story_1945_and_Older                    139\n 6 Two_Story_PUD_1946_and_Newer                129\n 7 Two_Story_1945_and_Older                    128\n 8 Split_or_Multilevel                         118\n 9 Duplex_All_Styles_and_Ages                  109\n10 Two_Family_conversion_All_Styles_and_Ages    61\n11 Split_Foyer                                  48\n12 Two_and_Half_Story_All_Ages                  23\n13 One_and_Half_Story_Unfinished_All_Ages       18\n14 PUD_Multilevel_Split_Level_Foyer             17\n15 One_Story_with_Finished_Attic_All_Ages        6\n16 One_and_Half_Story_PUD_All_Ages               1\n\n\nWe can then apply frequency encoding using step_encoding_frequency(). Notice how we only get 1 numeric variable for each categorical variable\n\ndummy_rec &lt;- recipe(Sale_Price ~ ., data = ames) |&gt;\n  step_encoding_frequency(all_nominal_predictors()) |&gt;\n  prep()\n\ndummy_rec |&gt;\n  bake(new_data = NULL, starts_with(\"MS_SubClass\"), starts_with(\"MS_Zoning\")) |&gt;\n  glimpse()\n\nRows: 2,930\nColumns: 2\n$ MS_SubClass &lt;dbl&gt; 0.36825939, 0.36825939, 0.36825939, 0.36825939, 0.19624573…\n$ MS_Zoning   &lt;dbl&gt; 0.775767918, 0.009215017, 0.775767918, 0.775767918, 0.7757…\n\n\nWe can pull the frequencies for each level of each variable by using tidy().\n\ndummy_rec |&gt;\n  tidy(1)\n\n# A tibble: 283 × 4\n   terms       level                                  frequency id              \n   &lt;chr&gt;       &lt;chr&gt;                                      &lt;dbl&gt; &lt;chr&gt;           \n 1 MS_SubClass One_Story_1946_and_Newer_All_Styles      0.368   encoding_freque…\n 2 MS_SubClass One_Story_1945_and_Older                 0.0474  encoding_freque…\n 3 MS_SubClass One_Story_with_Finished_Attic_All_Ages   0.00205 encoding_freque…\n 4 MS_SubClass One_and_Half_Story_Unfinished_All_Ages   0.00614 encoding_freque…\n 5 MS_SubClass One_and_Half_Story_Finished_All_Ages     0.0980  encoding_freque…\n 6 MS_SubClass Two_Story_1946_and_Newer                 0.196   encoding_freque…\n 7 MS_SubClass Two_Story_1945_and_Older                 0.0437  encoding_freque…\n 8 MS_SubClass Two_and_Half_Story_All_Ages              0.00785 encoding_freque…\n 9 MS_SubClass Split_or_Multilevel                      0.0403  encoding_freque…\n10 MS_SubClass Split_Foyer                              0.0164  encoding_freque…\n# ℹ 273 more rows",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Frequency Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-frequency.html#python-examples",
    "href": "categorical-frequency.html#python-examples",
    "title": "21  Frequency Encoding",
    "section": "21.4 Python Examples",
    "text": "21.4 Python Examples\nWe are using the ames data set for examples. {category_encoders} provided the CountEncoder() method we can use. This performs count encoding, which we know is functionally equivalent to frequency encoding.\n\nfrom feazdata import ames\nfrom sklearn.compose import ColumnTransformer\nfrom category_encoders.count import CountEncoder\n\nct = ColumnTransformer(\n    [('count', CountEncoder(), ['MS_Zoning'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('count',\n                                 CountEncoder(combine_min_nan_groups=True),\n                                 ['MS_Zoning'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('count',\n                                 CountEncoder(combine_min_nan_groups=True),\n                                 ['MS_Zoning'])]) count['MS_Zoning'] CountEncoderCountEncoder(combine_min_nan_groups=True) remainder['MS_SubClass', 'Lot_Frontage', 'Lot_Area', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Mas_Vnr_Area', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Sale_Price', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames).filter(regex=\"count.*\")\n\n      count__MS_Zoning\n0                 2273\n1                   27\n2                 2273\n3                 2273\n4                 2273\n...                ...\n2925              2273\n2926              2273\n2927              2273\n2928              2273\n2929              2273\n\n[2930 rows x 1 columns]",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Frequency Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-target.html",
    "href": "categorical-target.html",
    "title": "22  Target Encoding",
    "section": "",
    "text": "22.1 Target Encoding",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Target Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-target.html#pros-and-cons",
    "href": "categorical-target.html#pros-and-cons",
    "title": "22  Target Encoding",
    "section": "22.2 Pros and Cons",
    "text": "22.2 Pros and Cons\n\n22.2.1 Pros\n\nCan deal with categorical variables with many levels\nCan deal with unseen levels in a sensible way\n\n\n\n22.2.2 Cons\n\nCan be prone to overfitting",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Target Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-target.html#r-examples",
    "href": "categorical-target.html#r-examples",
    "title": "22  Target Encoding",
    "section": "22.3 R Examples",
    "text": "22.3 R Examples\nThe embed package comes with a couple of functions to do target encoding. step_lencode_glm(), step_lencode_bayes() and step_lencode_mixed(). These functions are named such because they likelihood encode variables, and because the encodings can be calculated using no intercept models.\nstep_lencode_glm() implements the no-smoothing method, so we will look at that one first using the ames data set.\n\n\n\n\n\n\nTODO\n\n\n\nfind a better data set\n\n\n\nlibrary(recipes)\nlibrary(embed)\n\ndata(ames, package = \"modeldata\")\n\nrec_target &lt;- recipe(Sale_Price ~ Neighborhood, data = ames) |&gt;\n  step_lencode_glm(Neighborhood, outcome = vars(Sale_Price)) |&gt;\n  prep()\n\nrec_target |&gt;\n  bake(new_data = NULL)\n\n# A tibble: 2,930 × 2\n   Neighborhood Sale_Price\n          &lt;dbl&gt;      &lt;int&gt;\n 1      145097.     215000\n 2      145097.     105000\n 3      145097.     172000\n 4      145097.     244000\n 5      190647.     189900\n 6      190647.     195500\n 7      324229.     213500\n 8      324229.     191500\n 9      324229.     236500\n10      190647.     189000\n# ℹ 2,920 more rows\n\n\nAnd we see that it works as intended, we can pull out the exact levels using the tidy() method\n\nrec_target |&gt;\n  tidy(1)\n\n# A tibble: 29 × 4\n   level                value terms        id               \n   &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;            \n 1 North_Ames         145097. Neighborhood lencode_glm_Bp5vK\n 2 College_Creek      201803. Neighborhood lencode_glm_Bp5vK\n 3 Old_Town           123992. Neighborhood lencode_glm_Bp5vK\n 4 Edwards            130843. Neighborhood lencode_glm_Bp5vK\n 5 Somerset           229707. Neighborhood lencode_glm_Bp5vK\n 6 Northridge_Heights 322018. Neighborhood lencode_glm_Bp5vK\n 7 Gilbert            190647. Neighborhood lencode_glm_Bp5vK\n 8 Sawyer             136751. Neighborhood lencode_glm_Bp5vK\n 9 Northwest_Ames     188407. Neighborhood lencode_glm_Bp5vK\n10 Sawyer_West        184070. Neighborhood lencode_glm_Bp5vK\n# ℹ 19 more rows\n\n\nto apply smoothing we can use the step_lencode_mixed() step in the same way\n\nrec_target_smooth &lt;- recipe(Sale_Price ~ Neighborhood, data = ames) |&gt;\n  step_lencode_mixed(Neighborhood, outcome = vars(Sale_Price)) |&gt;\n  prep()\n\nrec_target_smooth |&gt;\n  bake(new_data = NULL)\n\n# A tibble: 2,930 × 2\n   Neighborhood Sale_Price\n          &lt;dbl&gt;      &lt;int&gt;\n 1      145156.     215000\n 2      145156.     105000\n 3      145156.     172000\n 4      145156.     244000\n 5      190633.     189900\n 6      190633.     195500\n 7      322591.     213500\n 8      322591.     191500\n 9      322591.     236500\n10      190633.     189000\n# ℹ 2,920 more rows\n\n\nWe see that these values are slightly different than the values we had earlier\n\nrec_target_smooth |&gt;\n  tidy(1)\n\n# A tibble: 29 × 4\n   level                value terms        id                 \n   &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;              \n 1 North_Ames         145156. Neighborhood lencode_mixed_RUieL\n 2 College_Creek      201769. Neighborhood lencode_mixed_RUieL\n 3 Old_Town           124154. Neighborhood lencode_mixed_RUieL\n 4 Edwards            131021. Neighborhood lencode_mixed_RUieL\n 5 Somerset           229563. Neighborhood lencode_mixed_RUieL\n 6 Northridge_Heights 321519. Neighborhood lencode_mixed_RUieL\n 7 Gilbert            190633. Neighborhood lencode_mixed_RUieL\n 8 Sawyer             136956. Neighborhood lencode_mixed_RUieL\n 9 Northwest_Ames     188401. Neighborhood lencode_mixed_RUieL\n10 Sawyer_West        184085. Neighborhood lencode_mixed_RUieL\n# ℹ 19 more rows",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Target Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-target.html#python-examples",
    "href": "categorical-target.html#python-examples",
    "title": "22  Target Encoding",
    "section": "22.4 Python Examples",
    "text": "22.4 Python Examples\nWe are using the ames data set for examples. {sklearn} provided the TargetEncoder() method we can use. For this to work, we need to remember to specify an outcome when we fit().\n\nfrom feazdata import ames\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import TargetEncoder\n\nct = ColumnTransformer(\n    [('target', TargetEncoder(target_type=\"continuous\"), ['Neighborhood'])], \n    remainder=\"passthrough\")\n\nct.fit(ames, y=ames[[\"Sale_Price\"]].values.flatten())\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('target',\n                                 TargetEncoder(target_type='continuous'),\n                                 ['Neighborhood'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('target',\n                                 TargetEncoder(target_type='continuous'),\n                                 ['Neighborhood'])]) target['Neighborhood']  TargetEncoder?Documentation for TargetEncoderTargetEncoder(target_type='continuous') remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Lot_Area', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Mas_Vnr_Area', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Sale_Price', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames).filter(regex=\"target.*\")\n\n      target__Neighborhood\n0               145110.156\n1               145110.156\n2               145110.156\n3               145110.156\n4               190636.427\n...                    ...\n2925            162269.818\n2926            162269.818\n2927            162269.818\n2928            162269.818\n2929            162269.818\n\n[2930 rows x 1 columns]\n\n\n\n\n\n\nMicci-Barreca, Daniele. 2001. “A Preprocessing Scheme for High-Cardinality Categorical Attributes in Classification and Prediction Problems.” SIGKDD Explor. Newsl. 3 (1): 27–32. https://doi.org/10.1145/507533.507538.",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Target Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-hashing.html",
    "href": "categorical-hashing.html",
    "title": "23  Hashing Encoding",
    "section": "",
    "text": "23.1 Hashing Encoding",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Hashing Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-hashing.html#pros-and-cons",
    "href": "categorical-hashing.html#pros-and-cons",
    "title": "23  Hashing Encoding",
    "section": "23.2 Pros and Cons",
    "text": "23.2 Pros and Cons\n\n23.2.1 Pros\n\nComputationally fast\nAllows for a fixed number of output columns\ngives less sparse output than dummy encoding\n\n\n\n23.2.2 Cons\n\nLoss of interpretability\nStill gives quite sparse output",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Hashing Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-hashing.html#r-examples",
    "href": "categorical-hashing.html#r-examples",
    "title": "23  Hashing Encoding",
    "section": "23.3 R Examples",
    "text": "23.3 R Examples\n\n\n\n\n\n\nTODO\n\n\n\nfind a higher cardinality data set for this\n\n\nWe will be using the ames data set for these examples. The step_dummy_hash() function from the textrecipes package allows us to perform hashing encoding.\n\nlibrary(recipes)\nlibrary(textrecipes)\nlibrary(modeldata)\ndata(\"ames\")\n\names |&gt;\n  select(Sale_Price, Exterior_1st)\n\n# A tibble: 2,930 × 2\n   Sale_Price Exterior_1st\n        &lt;int&gt; &lt;fct&gt;       \n 1     215000 BrkFace     \n 2     105000 VinylSd     \n 3     172000 Wd Sdng     \n 4     244000 BrkFace     \n 5     189900 VinylSd     \n 6     195500 VinylSd     \n 7     213500 CemntBd     \n 8     191500 HdBoard     \n 9     236500 CemntBd     \n10     189000 VinylSd     \n# ℹ 2,920 more rows\n\n\nWe will be using the step_dummy_hash() step for this. For illustrative purposes, we will be creating 8 columns, where in practice you would likely want this value higher.\n\ndummy_rec &lt;- recipe(Sale_Price ~ Exterior_1st, data = ames) |&gt;\n  step_dummy_hash(Exterior_1st, num_terms = 8) |&gt;\n  prep()\n\ndummy_rec |&gt;\n  bake(new_data = NULL) |&gt;\n  glimpse()\n\nRows: 2,930\nColumns: 9\n$ Sale_Price               &lt;int&gt; 215000, 105000, 172000, 244000, 189900, 19550…\n$ dummyhash_Exterior_1st_1 &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, -1, -1, 0, -1,…\n$ dummyhash_Exterior_1st_2 &lt;int&gt; 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ dummyhash_Exterior_1st_3 &lt;int&gt; 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ dummyhash_Exterior_1st_4 &lt;int&gt; -1, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ dummyhash_Exterior_1st_5 &lt;int&gt; 0, 0, 0, 0, 0, 0, -1, 0, -1, 0, 0, 0, 0, 0, 0…\n$ dummyhash_Exterior_1st_6 &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ dummyhash_Exterior_1st_7 &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ dummyhash_Exterior_1st_8 &lt;int&gt; 0, -1, 0, 0, -1, -1, 0, 0, 0, -1, 0, 0, -1, 0…",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Hashing Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-hashing.html#python-examples",
    "href": "categorical-hashing.html#python-examples",
    "title": "23  Hashing Encoding",
    "section": "23.4 Python Examples",
    "text": "23.4 Python Examples\nWe are using the ames data set for examples. {category_encoders} provided the HashingEncoder() method we can use. For illustrative purposes, we will be creating 8 columns, where in practice you would likely want this value higher.\n\nfrom feazdata import ames\nfrom sklearn.compose import ColumnTransformer\nfrom category_encoders.hashing import HashingEncoder\n\nct = ColumnTransformer(\n    [('hasher', HashingEncoder(n_components=8), ['MS_Zoning'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('hasher', HashingEncoder(max_process=5),\n                                 ['MS_Zoning'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('hasher', HashingEncoder(max_process=5),\n                                 ['MS_Zoning'])]) hasher['MS_Zoning'] HashingEncoderHashingEncoder(max_process=5) remainder['MS_SubClass', 'Lot_Frontage', 'Lot_Area', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Mas_Vnr_Area', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Wood_Deck_SF', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Sale_Price', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames).filter(regex=\"hasher.*\")\n\n      hasher__col_0  hasher__col_1  ...  hasher__col_6  hasher__col_7\n0                 0              0  ...              0              0\n1                 0              1  ...              0              0\n2                 0              0  ...              0              0\n3                 0              0  ...              0              0\n4                 0              0  ...              0              0\n...             ...            ...  ...            ...            ...\n2925              0              0  ...              0              0\n2926              0              0  ...              0              0\n2927              0              0  ...              0              0\n2928              0              0  ...              0              0\n2929              0              0  ...              0              0\n\n[2930 rows x 8 columns]",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Hashing Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-leaveoneout.html",
    "href": "categorical-leaveoneout.html",
    "title": "24  🏗️ Leave One Out Encoding",
    "section": "",
    "text": "24.1 Leave One Out Encoding",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>🏗️ Leave One Out Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-leaveoneout.html#pros-and-cons",
    "href": "categorical-leaveoneout.html#pros-and-cons",
    "title": "24  🏗️ Leave One Out Encoding",
    "section": "24.2 Pros and Cons",
    "text": "24.2 Pros and Cons\n\n24.2.1 Pros\n\n\n24.2.2 Cons",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>🏗️ Leave One Out Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-leaveoneout.html#r-examples",
    "href": "categorical-leaveoneout.html#r-examples",
    "title": "24  🏗️ Leave One Out Encoding",
    "section": "24.3 R Examples",
    "text": "24.3 R Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>🏗️ Leave One Out Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-leaveoneout.html#python-examples",
    "href": "categorical-leaveoneout.html#python-examples",
    "title": "24  🏗️ Leave One Out Encoding",
    "section": "24.4 Python Examples",
    "text": "24.4 Python Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>🏗️ Leave One Out Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-leaf.html",
    "href": "categorical-leaf.html",
    "title": "25  🏗️ Leaf Encoding",
    "section": "",
    "text": "25.1 Leaf Encoding",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>🏗️ Leaf Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-leaf.html#pros-and-cons",
    "href": "categorical-leaf.html#pros-and-cons",
    "title": "25  🏗️ Leaf Encoding",
    "section": "25.2 Pros and Cons",
    "text": "25.2 Pros and Cons\n\n25.2.1 Pros\n\n\n25.2.2 Cons",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>🏗️ Leaf Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-leaf.html#r-examples",
    "href": "categorical-leaf.html#r-examples",
    "title": "25  🏗️ Leaf Encoding",
    "section": "25.3 R Examples",
    "text": "25.3 R Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>🏗️ Leaf Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-leaf.html#python-examples",
    "href": "categorical-leaf.html#python-examples",
    "title": "25  🏗️ Leaf Encoding",
    "section": "25.4 Python Examples",
    "text": "25.4 Python Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>🏗️ Leaf Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-glmm.html",
    "href": "categorical-glmm.html",
    "title": "26  🏗️ GLMM Encoding",
    "section": "",
    "text": "26.1 GLMM Encoding",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>🏗️ GLMM Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-glmm.html#pros-and-cons",
    "href": "categorical-glmm.html#pros-and-cons",
    "title": "26  🏗️ GLMM Encoding",
    "section": "26.2 Pros and Cons",
    "text": "26.2 Pros and Cons\n\n26.2.1 Pros\n\n\n26.2.2 Cons",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>🏗️ GLMM Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-glmm.html#r-examples",
    "href": "categorical-glmm.html#r-examples",
    "title": "26  🏗️ GLMM Encoding",
    "section": "26.3 R Examples",
    "text": "26.3 R Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>🏗️ GLMM Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-glmm.html#python-examples",
    "href": "categorical-glmm.html#python-examples",
    "title": "26  🏗️ GLMM Encoding",
    "section": "26.4 Python Examples",
    "text": "26.4 Python Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>🏗️ GLMM Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-catboost.html",
    "href": "categorical-catboost.html",
    "title": "27  🏗️ Catboost Encoding",
    "section": "",
    "text": "27.1 Catboost Encoding",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>🏗️ Catboost Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-catboost.html#pros-and-cons",
    "href": "categorical-catboost.html#pros-and-cons",
    "title": "27  🏗️ Catboost Encoding",
    "section": "27.2 Pros and Cons",
    "text": "27.2 Pros and Cons\n\n27.2.1 Pros\n\n\n27.2.2 Cons",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>🏗️ Catboost Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-catboost.html#r-examples",
    "href": "categorical-catboost.html#r-examples",
    "title": "27  🏗️ Catboost Encoding",
    "section": "27.3 R Examples",
    "text": "27.3 R Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>🏗️ Catboost Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-catboost.html#python-examples",
    "href": "categorical-catboost.html#python-examples",
    "title": "27  🏗️ Catboost Encoding",
    "section": "27.4 Python Examples",
    "text": "27.4 Python Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>🏗️ Catboost Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-woe.html",
    "href": "categorical-woe.html",
    "title": "28  🏗️ Weight of Evidence Encoding",
    "section": "",
    "text": "28.1 Weight of Evidence Encoding",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>🏗️ Weight of Evidence Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-woe.html#pros-and-cons",
    "href": "categorical-woe.html#pros-and-cons",
    "title": "28  🏗️ Weight of Evidence Encoding",
    "section": "28.2 Pros and Cons",
    "text": "28.2 Pros and Cons\n\n28.2.1 Pros\n\n\n28.2.2 Cons",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>🏗️ Weight of Evidence Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-woe.html#r-examples",
    "href": "categorical-woe.html#r-examples",
    "title": "28  🏗️ Weight of Evidence Encoding",
    "section": "28.3 R Examples",
    "text": "28.3 R Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>🏗️ Weight of Evidence Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-woe.html#python-examples",
    "href": "categorical-woe.html#python-examples",
    "title": "28  🏗️ Weight of Evidence Encoding",
    "section": "28.4 Python Examples",
    "text": "28.4 Python Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>🏗️ Weight of Evidence Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-jamesstein.html",
    "href": "categorical-jamesstein.html",
    "title": "29  🏗️ James-Stein Encoding",
    "section": "",
    "text": "29.1 James-Stein Encoding",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>🏗️ James-Stein Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-jamesstein.html#pros-and-cons",
    "href": "categorical-jamesstein.html#pros-and-cons",
    "title": "29  🏗️ James-Stein Encoding",
    "section": "29.2 Pros and Cons",
    "text": "29.2 Pros and Cons\n\n29.2.1 Pros\n\n\n29.2.2 Cons",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>🏗️ James-Stein Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-jamesstein.html#r-examples",
    "href": "categorical-jamesstein.html#r-examples",
    "title": "29  🏗️ James-Stein Encoding",
    "section": "29.3 R Examples",
    "text": "29.3 R Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>🏗️ James-Stein Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-jamesstein.html#python-examples",
    "href": "categorical-jamesstein.html#python-examples",
    "title": "29  🏗️ James-Stein Encoding",
    "section": "29.4 Python Examples",
    "text": "29.4 Python Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>🏗️ James-Stein Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-mestimator.html",
    "href": "categorical-mestimator.html",
    "title": "30  🏗️ M-Estimator Encoding",
    "section": "",
    "text": "30.1 M-Estimator Encoding",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>🏗️ M-Estimator Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-mestimator.html#pros-and-cons",
    "href": "categorical-mestimator.html#pros-and-cons",
    "title": "30  🏗️ M-Estimator Encoding",
    "section": "30.2 Pros and Cons",
    "text": "30.2 Pros and Cons\n\n30.2.1 Pros\n\n\n30.2.2 Cons",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>🏗️ M-Estimator Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-mestimator.html#r-examples",
    "href": "categorical-mestimator.html#r-examples",
    "title": "30  🏗️ M-Estimator Encoding",
    "section": "30.3 R Examples",
    "text": "30.3 R Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>🏗️ M-Estimator Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-mestimator.html#python-examples",
    "href": "categorical-mestimator.html#python-examples",
    "title": "30  🏗️ M-Estimator Encoding",
    "section": "30.4 Python Examples",
    "text": "30.4 Python Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>🏗️ M-Estimator Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-thermometer.html",
    "href": "categorical-thermometer.html",
    "title": "31  🏗️ Thermometer Encoding",
    "section": "",
    "text": "31.1 Thermometer Encoding",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>🏗️ Thermometer Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-thermometer.html#pros-and-cons",
    "href": "categorical-thermometer.html#pros-and-cons",
    "title": "31  🏗️ Thermometer Encoding",
    "section": "31.2 Pros and Cons",
    "text": "31.2 Pros and Cons\n\n31.2.1 Pros\n\n\n31.2.2 Cons",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>🏗️ Thermometer Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-thermometer.html#r-examples",
    "href": "categorical-thermometer.html#r-examples",
    "title": "31  🏗️ Thermometer Encoding",
    "section": "31.3 R Examples",
    "text": "31.3 R Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>🏗️ Thermometer Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-thermometer.html#python-examples",
    "href": "categorical-thermometer.html#python-examples",
    "title": "31  🏗️ Thermometer Encoding",
    "section": "31.4 Python Examples",
    "text": "31.4 Python Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>🏗️ Thermometer Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-quantile.html",
    "href": "categorical-quantile.html",
    "title": "32  🏗️ Quantile Encoding",
    "section": "",
    "text": "32.1 Quantile Encoding",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>🏗️ Quantile Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-quantile.html#pros-and-cons",
    "href": "categorical-quantile.html#pros-and-cons",
    "title": "32  🏗️ Quantile Encoding",
    "section": "32.2 Pros and Cons",
    "text": "32.2 Pros and Cons\n\n32.2.1 Pros\n\n\n32.2.2 Cons",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>🏗️ Quantile Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-quantile.html#r-examples",
    "href": "categorical-quantile.html#r-examples",
    "title": "32  🏗️ Quantile Encoding",
    "section": "32.3 R Examples",
    "text": "32.3 R Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>🏗️ Quantile Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-quantile.html#python-examples",
    "href": "categorical-quantile.html#python-examples",
    "title": "32  🏗️ Quantile Encoding",
    "section": "32.4 Python Examples",
    "text": "32.4 Python Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>🏗️ Quantile Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-summary.html",
    "href": "categorical-summary.html",
    "title": "33  🏗️ Summary Encoding",
    "section": "",
    "text": "33.1 Summary Encoding",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>🏗️ Summary Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-summary.html#pros-and-cons",
    "href": "categorical-summary.html#pros-and-cons",
    "title": "33  🏗️ Summary Encoding",
    "section": "33.2 Pros and Cons",
    "text": "33.2 Pros and Cons\n\n33.2.1 Pros\n\n\n33.2.2 Cons",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>🏗️ Summary Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-summary.html#r-examples",
    "href": "categorical-summary.html#r-examples",
    "title": "33  🏗️ Summary Encoding",
    "section": "33.3 R Examples",
    "text": "33.3 R Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>🏗️ Summary Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-summary.html#python-examples",
    "href": "categorical-summary.html#python-examples",
    "title": "33  🏗️ Summary Encoding",
    "section": "33.4 Python Examples",
    "text": "33.4 Python Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>33</span>  <span class='chapter-title'>🏗️ Summary Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-collapse.html",
    "href": "categorical-collapse.html",
    "title": "34  Collapsing Categories",
    "section": "",
    "text": "34.1 Collapsing Categories",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Collapsing Categories</span>"
    ]
  },
  {
    "objectID": "categorical-collapse.html#pros-and-cons",
    "href": "categorical-collapse.html#pros-and-cons",
    "title": "34  Collapsing Categories",
    "section": "34.2 Pros and Cons",
    "text": "34.2 Pros and Cons\n\n34.2.1 Pros\n\nEasy to perform and verify\nComputationally fast\n\n\n\n34.2.2 Cons\n\nMust be tuned\nCan produce counterintuitive results",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Collapsing Categories</span>"
    ]
  },
  {
    "objectID": "categorical-collapse.html#r-examples",
    "href": "categorical-collapse.html#r-examples",
    "title": "34  Collapsing Categories",
    "section": "34.3 R Examples",
    "text": "34.3 R Examples\nMethods to collapse categorical levels can be found in the recipes package with step_other() and the embed package in step_collapse_cart() and step_collapse_stringdist().\n\n\n\n\n\n\nTODO\n\n\n\nfind a better data set for examples\n\n\nOthering can be done using the step_other() function, it uses the argument threshold to determine the cutoff used to turn levels into \"other\" or not.\n\nlibrary(recipes)\nlibrary(embed)\n\ndata(ames, package = \"modeldata\")\n\nrec_other &lt;- recipe(Sale_Price ~ Exterior_2nd, data = ames) |&gt;\n  step_other(Exterior_2nd, threshold = 0.1) |&gt;\n  prep()\n\nrec_other |&gt;\n  bake(new_data = NULL)\n\n# A tibble: 2,930 × 2\n   Exterior_2nd Sale_Price\n   &lt;fct&gt;             &lt;int&gt;\n 1 other            215000\n 2 VinylSd          105000\n 3 Wd Sdng          172000\n 4 other            244000\n 5 VinylSd          189900\n 6 VinylSd          195500\n 7 other            213500\n 8 HdBoard          191500\n 9 other            236500\n10 VinylSd          189000\n# ℹ 2,920 more rows\n\n\nselecting a higher threshold turns more levels into \"other\".\n\nrec_other &lt;- recipe(Sale_Price ~ Exterior_2nd, data = ames) |&gt;\n  step_other(Exterior_2nd, threshold = 0.5) |&gt;\n  prep()\n\nrec_other |&gt;\n  bake(new_data = NULL)\n\n# A tibble: 2,930 × 2\n   Exterior_2nd Sale_Price\n   &lt;fct&gt;             &lt;int&gt;\n 1 other            215000\n 2 VinylSd          105000\n 3 other            172000\n 4 other            244000\n 5 VinylSd          189900\n 6 VinylSd          195500\n 7 other            213500\n 8 other            191500\n 9 other            236500\n10 VinylSd          189000\n# ℹ 2,920 more rows\n\n\nfor the more advanced methods, we turn to the embed package. To collapse levels by their string distance, we use the step_collapse_stringdist(). By default, you control it with the distance argument.\n\nrec_stringdist &lt;- recipe(Sale_Price ~ Exterior_2nd, data = ames) |&gt;\n  step_collapse_stringdist(Exterior_2nd, distance = 5) |&gt;\n  prep()\n\nrec_stringdist |&gt;\n  bake(new_data = NULL)\n\n# A tibble: 2,930 × 2\n   Exterior_2nd Sale_Price\n   &lt;fct&gt;             &lt;int&gt;\n 1 Plywood          215000\n 2 MetalSd          105000\n 3 AsbShng          172000\n 4 Brk Cmn          244000\n 5 MetalSd          189900\n 6 MetalSd          195500\n 7 CmentBd          213500\n 8 HdBoard          191500\n 9 CmentBd          236500\n10 MetalSd          189000\n# ℹ 2,920 more rows\n\n\nUnsurprisingly, there are almost a dozen different ways to calculate the distance between two strings. Most are supported and can be changed using the method argument, and further controlled using the options argument.\n\nrec_stringdist &lt;- recipe(Sale_Price ~ Exterior_2nd, data = ames) |&gt;\n  step_collapse_stringdist(Exterior_2nd, \n                           distance = 0.75, \n                           method = \"cosine\", \n                           options = list(q = 2)) |&gt;\n  prep()\n\nrec_stringdist |&gt;\n  bake(new_data = NULL)\n\n# A tibble: 2,930 × 2\n   Exterior_2nd Sale_Price\n   &lt;fct&gt;             &lt;int&gt;\n 1 Plywood          215000\n 2 MetalSd          105000\n 3 AsbShng          172000\n 4 Brk Cmn          244000\n 5 MetalSd          189900\n 6 MetalSd          195500\n 7 CmentBd          213500\n 8 HdBoard          191500\n 9 CmentBd          236500\n10 MetalSd          189000\n# ℹ 2,920 more rows\n\n\nLastly, we have the tree-based method, this is done using the step_collapse_cart() function. For this to work, you need to select an outcome variable using the outcome argument. With cost_complexity and min_n as arguments to change the shape of the tree.\n\nrec_cart &lt;- recipe(Sale_Price ~ Exterior_2nd, data = ames) |&gt;\n  step_collapse_cart(Exterior_2nd, outcome = vars(Sale_Price)) |&gt;\n  prep()\n\nrec_cart |&gt;\n  bake(new_data = NULL)\n\n# A tibble: 2,930 × 2\n   Exterior_2nd   Sale_Price\n   &lt;fct&gt;               &lt;int&gt;\n 1 Exterior_2nd_5     215000\n 2 Exterior_2nd_7     105000\n 3 Exterior_2nd_3     172000\n 4 Exterior_2nd_6     244000\n 5 Exterior_2nd_7     189900\n 6 Exterior_2nd_7     195500\n 7 Exterior_2nd_8     213500\n 8 Exterior_2nd_5     191500\n 9 Exterior_2nd_8     236500\n10 Exterior_2nd_7     189000\n# ℹ 2,920 more rows",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Collapsing Categories</span>"
    ]
  },
  {
    "objectID": "categorical-collapse.html#python-examples",
    "href": "categorical-collapse.html#python-examples",
    "title": "34  Collapsing Categories",
    "section": "34.4 Python Examples",
    "text": "34.4 Python Examples\nhttps://github.com/skrub-data/skrub",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>34</span>  <span class='chapter-title'>Collapsing Categories</span>"
    ]
  },
  {
    "objectID": "categorical-combination.html",
    "href": "categorical-combination.html",
    "title": "35  🏗️ Combination",
    "section": "",
    "text": "35.1 Combination",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>🏗️ Combination</span>"
    ]
  },
  {
    "objectID": "categorical-combination.html#pros-and-cons",
    "href": "categorical-combination.html#pros-and-cons",
    "title": "35  🏗️ Combination",
    "section": "35.2 Pros and Cons",
    "text": "35.2 Pros and Cons\n\n35.2.1 Pros\n\n\n35.2.2 Cons",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>🏗️ Combination</span>"
    ]
  },
  {
    "objectID": "categorical-combination.html#r-examples",
    "href": "categorical-combination.html#r-examples",
    "title": "35  🏗️ Combination",
    "section": "35.3 R Examples",
    "text": "35.3 R Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>🏗️ Combination</span>"
    ]
  },
  {
    "objectID": "categorical-combination.html#python-examples",
    "href": "categorical-combination.html#python-examples",
    "title": "35  🏗️ Combination",
    "section": "35.4 Python Examples",
    "text": "35.4 Python Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>35</span>  <span class='chapter-title'>🏗️ Combination</span>"
    ]
  },
  {
    "objectID": "categorical-multi-dummy.html",
    "href": "categorical-multi-dummy.html",
    "title": "36  🏗️ Multi-Dummy Encoding",
    "section": "",
    "text": "36.1 Multi-Dummy Encoding",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>🏗️ Multi-Dummy Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-multi-dummy.html#pros-and-cons",
    "href": "categorical-multi-dummy.html#pros-and-cons",
    "title": "36  🏗️ Multi-Dummy Encoding",
    "section": "36.2 Pros and Cons",
    "text": "36.2 Pros and Cons\n\n36.2.1 Pros\n\n\n36.2.2 Cons",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>🏗️ Multi-Dummy Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-multi-dummy.html#r-examples",
    "href": "categorical-multi-dummy.html#r-examples",
    "title": "36  🏗️ Multi-Dummy Encoding",
    "section": "36.3 R Examples",
    "text": "36.3 R Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>🏗️ Multi-Dummy Encoding</span>"
    ]
  },
  {
    "objectID": "categorical-multi-dummy.html#python-examples",
    "href": "categorical-multi-dummy.html#python-examples",
    "title": "36  🏗️ Multi-Dummy Encoding",
    "section": "36.4 Python Examples",
    "text": "36.4 Python Examples",
    "crumbs": [
      "Categorical Features",
      "<span class='chapter-number'>36</span>  <span class='chapter-title'>🏗️ Multi-Dummy Encoding</span>"
    ]
  },
  {
    "objectID": "datetime.html",
    "href": "datetime.html",
    "title": "37  Datetime Overview",
    "section": "",
    "text": "37.1 Datetime Overview",
    "crumbs": [
      "Datetime Features",
      "<span class='chapter-number'>37</span>  <span class='chapter-title'>Datetime Overview</span>"
    ]
  },
  {
    "objectID": "datetime-extraction.html",
    "href": "datetime-extraction.html",
    "title": "38  Value Extraction",
    "section": "",
    "text": "38.1 Value Extraction",
    "crumbs": [
      "Datetime Features",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Value Extraction</span>"
    ]
  },
  {
    "objectID": "datetime-extraction.html#pros-and-cons",
    "href": "datetime-extraction.html#pros-and-cons",
    "title": "38  Value Extraction",
    "section": "38.2 Pros and Cons",
    "text": "38.2 Pros and Cons\n\n38.2.1 Pros\n\nFast and easy computations\nCan provide good results\n\n\n\n38.2.2 Cons\n\nThe numerical features generated are all increasing with time linearly\nThere are a lot of extractions, and they correlate quite a bit",
    "crumbs": [
      "Datetime Features",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Value Extraction</span>"
    ]
  },
  {
    "objectID": "datetime-extraction.html#r-examples",
    "href": "datetime-extraction.html#r-examples",
    "title": "38  Value Extraction",
    "section": "38.3 R Examples",
    "text": "38.3 R Examples\nWe will be using the hotel_bookings data set for these examples.\n\nlibrary(recipes)\n\nhotel_bookings |&gt;\n  select(reservation_status_date)\n\n# A tibble: 119,390 × 1\n   reservation_status_date\n   &lt;date&gt;                 \n 1 2015-07-01             \n 2 2015-07-01             \n 3 2015-07-02             \n 4 2015-07-02             \n 5 2015-07-03             \n 6 2015-07-03             \n 7 2015-07-03             \n 8 2015-07-03             \n 9 2015-05-06             \n10 2015-04-22             \n# ℹ 119,380 more rows\n\n\n{recipes} provide two steps for date time extraction. step_date() handles dates, and step_time() handles the sub-day time features. The steps work the same way, so we will only show how step_date() works here. A couple of features are selected by default,\n\ndate_rec &lt;- recipe(is_canceled ~ reservation_status_date, \n                   data = hotel_bookings) |&gt;\n  step_date(reservation_status_date)\n\ndate_rec |&gt;\n  prep() |&gt;\n  bake(new_data = NULL) |&gt;\n  glimpse()\n\nRows: 119,390\nColumns: 5\n$ reservation_status_date       &lt;date&gt; 2015-07-01, 2015-07-01, 2015-07-02, 201…\n$ is_canceled                   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0…\n$ reservation_status_date_dow   &lt;fct&gt; Wed, Wed, Thu, Thu, Fri, Fri, Fri, Fri, …\n$ reservation_status_date_month &lt;fct&gt; Jul, Jul, Jul, Jul, Jul, Jul, Jul, Jul, …\n$ reservation_status_date_year  &lt;int&gt; 2015, 2015, 2015, 2015, 2015, 2015, 2015…\n\n\nBut you can use the features argument to specify other types as well\n\ndate_rec &lt;- recipe(is_canceled ~ reservation_status_date, \n                   data = hotel_bookings) |&gt;\n  step_date(reservation_status_date, \n            features = c( \"year\", \"doy\", \"week\", \"decimal\", \"semester\", \n                          \"quarter\", \"dow\", \"month\"))\n\ndate_rec |&gt;\n  prep() |&gt;\n  bake(new_data = NULL) |&gt;\n  glimpse()\n\nRows: 119,390\nColumns: 10\n$ reservation_status_date          &lt;date&gt; 2015-07-01, 2015-07-01, 2015-07-02, …\n$ is_canceled                      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0…\n$ reservation_status_date_year     &lt;int&gt; 2015, 2015, 2015, 2015, 2015, 2015, 2…\n$ reservation_status_date_doy      &lt;int&gt; 182, 182, 183, 183, 184, 184, 184, 18…\n$ reservation_status_date_week     &lt;int&gt; 26, 26, 27, 27, 27, 27, 27, 27, 18, 1…\n$ reservation_status_date_decimal  &lt;dbl&gt; 2015.496, 2015.496, 2015.499, 2015.49…\n$ reservation_status_date_semester &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2…\n$ reservation_status_date_quarter  &lt;int&gt; 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 3, 3…\n$ reservation_status_date_dow      &lt;fct&gt; Wed, Wed, Thu, Thu, Fri, Fri, Fri, Fr…\n$ reservation_status_date_month    &lt;fct&gt; Jul, Jul, Jul, Jul, Jul, Jul, Jul, Ju…\n\n\nfeatures that can be categorical will be so by default, but can be turned off by setting label = FALSE.\n\ndate_rec &lt;- recipe(is_canceled ~ reservation_status_date, \n                   data = hotel_bookings) |&gt;\n  step_date(reservation_status_date, \n            features = c( \"year\", \"doy\", \"week\", \"decimal\", \"semester\", \n                          \"quarter\", \"dow\", \"month\"), label = FALSE)\n\ndate_rec |&gt;\n  prep() |&gt;\n  bake(new_data = NULL) |&gt;\n  glimpse()\n\nRows: 119,390\nColumns: 10\n$ reservation_status_date          &lt;date&gt; 2015-07-01, 2015-07-01, 2015-07-02, …\n$ is_canceled                      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0…\n$ reservation_status_date_year     &lt;int&gt; 2015, 2015, 2015, 2015, 2015, 2015, 2…\n$ reservation_status_date_doy      &lt;int&gt; 182, 182, 183, 183, 184, 184, 184, 18…\n$ reservation_status_date_week     &lt;int&gt; 26, 26, 27, 27, 27, 27, 27, 27, 18, 1…\n$ reservation_status_date_decimal  &lt;dbl&gt; 2015.496, 2015.496, 2015.499, 2015.49…\n$ reservation_status_date_semester &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2…\n$ reservation_status_date_quarter  &lt;int&gt; 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 3, 3…\n$ reservation_status_date_dow      &lt;int&gt; 4, 4, 5, 5, 6, 6, 6, 6, 4, 4, 3, 1, 1…\n$ reservation_status_date_month    &lt;int&gt; 7, 7, 7, 7, 7, 7, 7, 7, 5, 4, 6, 7, 7…\n\n\nIf we want to extract holiday features, we can use the step_holiday() function, which uses the {timeDate} library. With known holidays listed in timeDate::listHolidays().\n\ndate_rec &lt;- recipe(is_canceled ~ reservation_status_date, \n                   data = hotel_bookings) |&gt;\n  step_holiday(reservation_status_date, \n               holidays = c(\"BoxingDay\", \"CAFamilyDay\", \"JPConstitutionDay\"))\n\ndate_rec |&gt;\n  prep() |&gt;\n  bake(new_data = NULL) |&gt;\n  glimpse()\n\nRows: 119,390\nColumns: 5\n$ reservation_status_date                   &lt;date&gt; 2015-07-01, 2015-07-01, 201…\n$ is_canceled                               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 1…\n$ reservation_status_date_BoxingDay         &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reservation_status_date_CAFamilyDay       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reservation_status_date_JPConstitutionDay &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…",
    "crumbs": [
      "Datetime Features",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Value Extraction</span>"
    ]
  },
  {
    "objectID": "datetime-extraction.html#python-examples",
    "href": "datetime-extraction.html#python-examples",
    "title": "38  Value Extraction",
    "section": "38.4 Python Examples",
    "text": "38.4 Python Examples\nI’m not aware of a good way to do this in a scikit-learn way. Please file an issue on github if you know of a good way.",
    "crumbs": [
      "Datetime Features",
      "<span class='chapter-number'>38</span>  <span class='chapter-title'>Value Extraction</span>"
    ]
  },
  {
    "objectID": "datetime-advanced.html",
    "href": "datetime-advanced.html",
    "title": "39  Advanced Features",
    "section": "",
    "text": "39.1 Advanced Features",
    "crumbs": [
      "Datetime Features",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Advanced Features</span>"
    ]
  },
  {
    "objectID": "datetime-advanced.html#pros-and-cons",
    "href": "datetime-advanced.html#pros-and-cons",
    "title": "39  Advanced Features",
    "section": "39.2 Pros and Cons",
    "text": "39.2 Pros and Cons\n\n39.2.1 Pros\n\n\n39.2.2 Cons",
    "crumbs": [
      "Datetime Features",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Advanced Features</span>"
    ]
  },
  {
    "objectID": "datetime-advanced.html#r-examples",
    "href": "datetime-advanced.html#r-examples",
    "title": "39  Advanced Features",
    "section": "39.3 R Examples",
    "text": "39.3 R Examples",
    "crumbs": [
      "Datetime Features",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Advanced Features</span>"
    ]
  },
  {
    "objectID": "datetime-advanced.html#python-examples",
    "href": "datetime-advanced.html#python-examples",
    "title": "39  Advanced Features",
    "section": "39.4 Python Examples",
    "text": "39.4 Python Examples",
    "crumbs": [
      "Datetime Features",
      "<span class='chapter-number'>39</span>  <span class='chapter-title'>Advanced Features</span>"
    ]
  },
  {
    "objectID": "datetime-circular.html",
    "href": "datetime-circular.html",
    "title": "40  Circular Features",
    "section": "",
    "text": "40.1 Circular Features",
    "crumbs": [
      "Datetime Features",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Circular Features</span>"
    ]
  },
  {
    "objectID": "datetime-circular.html#pros-and-cons",
    "href": "datetime-circular.html#pros-and-cons",
    "title": "40  Circular Features",
    "section": "40.2 Pros and Cons",
    "text": "40.2 Pros and Cons\n\n40.2.1 Pros\n\nThe nature of datetime variables naturally leads to circular patterns\n\n\n\n40.2.2 Cons\n\nExtra care and work need to be done to find the right period",
    "crumbs": [
      "Datetime Features",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Circular Features</span>"
    ]
  },
  {
    "objectID": "datetime-circular.html#r-examples",
    "href": "datetime-circular.html#r-examples",
    "title": "40  Circular Features",
    "section": "40.3 R Examples",
    "text": "40.3 R Examples\n\n\n\n\n\n\nTODO\n\n\n\nAdd recipes steps",
    "crumbs": [
      "Datetime Features",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Circular Features</span>"
    ]
  },
  {
    "objectID": "datetime-circular.html#python-examples",
    "href": "datetime-circular.html#python-examples",
    "title": "40  Circular Features",
    "section": "40.4 Python Examples",
    "text": "40.4 Python Examples",
    "crumbs": [
      "Datetime Features",
      "<span class='chapter-number'>40</span>  <span class='chapter-title'>Circular Features</span>"
    ]
  },
  {
    "objectID": "missing.html",
    "href": "missing.html",
    "title": "41  Missing Overview",
    "section": "",
    "text": "41.1 Missing Overview",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Missing Overview</span>"
    ]
  },
  {
    "objectID": "missing.html#imputation",
    "href": "missing.html#imputation",
    "title": "41  Missing Overview",
    "section": "41.2 Imputation",
    "text": "41.2 Imputation\nOne of the most common ways of dealing with missing values is to fill them in with some values. The types of methods that do this can be split into two groups. Simple imputation in Chapter 42 is when you use the values in the variable to impute its missing values, which is where mean and mode imputation are found. Anything more complicated than this will be found in Chapter 43. This is where multiple columns are used to determine the type of imputation needed.",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Missing Overview</span>"
    ]
  },
  {
    "objectID": "missing.html#indication",
    "href": "missing.html#indication",
    "title": "41  Missing Overview",
    "section": "41.3 Indication",
    "text": "41.3 Indication\nIf you suspect that the data is not missing at random, it might be worthwhile to include the missingness as an indicator in your data. We will see how we can do that in Chapter 44.",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Missing Overview</span>"
    ]
  },
  {
    "objectID": "missing.html#removal",
    "href": "missing.html#removal",
    "title": "41  Missing Overview",
    "section": "41.4 Removal",
    "text": "41.4 Removal\nAs a last resort, you might want to remove variables or rows with missing data, we will see how that is done in Chapter 45. This chapter is put last in this section, as it is generally not the preferred action, and all other avenues should be considered before removal is done.\n\n\n\n\nRUBIN, DONALD B. 1976. “Inference and missing data.” Biometrika 63 (3): 581–92. https://doi.org/10.1093/biomet/63.3.581.",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Missing Overview</span>"
    ]
  },
  {
    "objectID": "missing.html#footnotes",
    "href": "missing.html#footnotes",
    "title": "41  Missing Overview",
    "section": "",
    "text": "Optical Character Recognition is used to extract text from images.↩︎",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>41</span>  <span class='chapter-title'>Missing Overview</span>"
    ]
  },
  {
    "objectID": "missing-simple.html",
    "href": "missing-simple.html",
    "title": "42  Simple Imputation",
    "section": "",
    "text": "42.1 Simple Imputation",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Simple Imputation</span>"
    ]
  },
  {
    "objectID": "missing-simple.html#pros-and-cons",
    "href": "missing-simple.html#pros-and-cons",
    "title": "42  Simple Imputation",
    "section": "42.2 Pros and Cons",
    "text": "42.2 Pros and Cons\n\n42.2.1 Pros\n\nFast computationally\nEasy to explain what was done\n\n\n\n42.2.2 Cons\n\nDoesn’t preserve relationship between predictors\nreducing the variance and standard deviation of the data\nunlikely to help performance",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Simple Imputation</span>"
    ]
  },
  {
    "objectID": "missing-simple.html#r-examples",
    "href": "missing-simple.html#r-examples",
    "title": "42  Simple Imputation",
    "section": "42.3 R Examples",
    "text": "42.3 R Examples\nThe recipes package contains several steps. It includes the steps step_impute_mean(), step_impute_median() and step_impute_mode() which imputes by the mean, median and mode respectively.\n\n\n\n\n\n\nTODO\n\n\n\nfind a good data set with missing values\n\n\n\nlibrary(recipes)\nlibrary(modeldata)\n\nimpute_rec &lt;- recipe(Sale_Price ~ ., data = ames) |&gt;\n  step_impute_mean(contains(\"Area\")) |&gt;\n  step_impute_median(contains(\"_SF\")) |&gt;\n  step_impute_mode(all_nominal_predictors()) |&gt;\n  prep()\n\nWe can use the tidy() function to find the estimated mean\n\nimpute_rec |&gt;\n  tidy(1)\n\n# A tibble: 5 × 3\n  terms         value id               \n  &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;            \n1 Lot_Area     10148  impute_mean_CnWw4\n2 Mas_Vnr_Area   101. impute_mean_CnWw4\n3 Gr_Liv_Area   1500  impute_mean_CnWw4\n4 Garage_Area    473. impute_mean_CnWw4\n5 Pool_Area        2  impute_mean_CnWw4\n\n\nestimated median\n\nimpute_rec |&gt;\n  tidy(2)\n\n# A tibble: 8 × 3\n  terms         value id                 \n  &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;              \n1 BsmtFin_SF_1     3  impute_median_UoO9a\n2 BsmtFin_SF_2     0  impute_median_UoO9a\n3 Bsmt_Unf_SF    466. impute_median_UoO9a\n4 Total_Bsmt_SF  990  impute_median_UoO9a\n5 First_Flr_SF  1084  impute_median_UoO9a\n6 Second_Flr_SF    0  impute_median_UoO9a\n7 Wood_Deck_SF     0  impute_median_UoO9a\n8 Open_Porch_SF   27  impute_median_UoO9a\n\n\nand estimated mode\n\nimpute_rec |&gt;\n  tidy(3)\n\n# A tibble: 40 × 3\n   terms        value                               id               \n   &lt;chr&gt;        &lt;chr&gt;                               &lt;chr&gt;            \n 1 MS_SubClass  One_Story_1946_and_Newer_All_Styles impute_mode_I3pVC\n 2 MS_Zoning    Residential_Low_Density             impute_mode_I3pVC\n 3 Street       Pave                                impute_mode_I3pVC\n 4 Alley        No_Alley_Access                     impute_mode_I3pVC\n 5 Lot_Shape    Regular                             impute_mode_I3pVC\n 6 Land_Contour Lvl                                 impute_mode_I3pVC\n 7 Utilities    AllPub                              impute_mode_I3pVC\n 8 Lot_Config   Inside                              impute_mode_I3pVC\n 9 Land_Slope   Gtl                                 impute_mode_I3pVC\n10 Neighborhood North_Ames                          impute_mode_I3pVC\n# ℹ 30 more rows\n\n\n\n\n\n\n\n\nTODO\n\n\n\nwait for the distribution step",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Simple Imputation</span>"
    ]
  },
  {
    "objectID": "missing-simple.html#python-examples",
    "href": "missing-simple.html#python-examples",
    "title": "42  Simple Imputation",
    "section": "42.4 Python Examples",
    "text": "42.4 Python Examples\nWe are using the ames data set for examples. {sklearn} provided the SimpleImputer() method we can use. The main argument we will use is strategy which we can set to determine the type of imputing.\n\nfrom feazdata import ames\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\n\nct = ColumnTransformer(\n    [('mean_impute', SimpleImputer(strategy='mean'), ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',  'Mas_Vnr_Area'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('mean_impute', SimpleImputer(),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('mean_impute', SimpleImputer(),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])]) mean_impute['Sale_Price', 'Lot_Area', 'Wood_Deck_SF', 'Mas_Vnr_Area']  SimpleImputer?Documentation for SimpleImputerSimpleImputer() remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames)\n\n      mean_impute__Sale_Price  ...  remainder__Latitude\n0                    215000.0  ...               42.054\n1                    105000.0  ...               42.053\n2                    172000.0  ...               42.053\n3                    244000.0  ...               42.051\n4                    189900.0  ...               42.061\n...                       ...  ...                  ...\n2925                 142500.0  ...               41.989\n2926                 131000.0  ...               41.988\n2927                 132000.0  ...               41.987\n2928                 170000.0  ...               41.991\n2929                 188000.0  ...               41.989\n\n[2930 rows x 74 columns]\n\n\nSetting strategy='median' switches the imputer to do median imputing.\n\nct = ColumnTransformer(\n    [('median_impute', SimpleImputer(strategy='median'), ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',  'Mas_Vnr_Area'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('median_impute',\n                                 SimpleImputer(strategy='median'),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('median_impute',\n                                 SimpleImputer(strategy='median'),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])]) median_impute['Sale_Price', 'Lot_Area', 'Wood_Deck_SF', 'Mas_Vnr_Area']  SimpleImputer?Documentation for SimpleImputerSimpleImputer(strategy='median') remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames)\n\n      median_impute__Sale_Price  ...  remainder__Latitude\n0                      215000.0  ...               42.054\n1                      105000.0  ...               42.053\n2                      172000.0  ...               42.053\n3                      244000.0  ...               42.051\n4                      189900.0  ...               42.061\n...                         ...  ...                  ...\n2925                   142500.0  ...               41.989\n2926                   131000.0  ...               41.988\n2927                   132000.0  ...               41.987\n2928                   170000.0  ...               41.991\n2929                   188000.0  ...               41.989\n\n[2930 rows x 74 columns]",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>42</span>  <span class='chapter-title'>Simple Imputation</span>"
    ]
  },
  {
    "objectID": "missing-model.html",
    "href": "missing-model.html",
    "title": "43  Model Based Imputation",
    "section": "",
    "text": "43.1 Model Based Imputation",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Model Based Imputation</span>"
    ]
  },
  {
    "objectID": "missing-model.html#pros-and-cons",
    "href": "missing-model.html#pros-and-cons",
    "title": "43  Model Based Imputation",
    "section": "43.2 Pros and Cons",
    "text": "43.2 Pros and Cons\n\n43.2.1 Pros\n\nLikely get better performance than simple imputation\n\n\n\n43.2.2 Cons\n\nMore complex model\nlower interpretability",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Model Based Imputation</span>"
    ]
  },
  {
    "objectID": "missing-model.html#r-examples",
    "href": "missing-model.html#r-examples",
    "title": "43  Model Based Imputation",
    "section": "43.3 R Examples",
    "text": "43.3 R Examples\nThere are a number of steps in the recipes package that fall under this category. Within that, we have step_impute_bag(), step_impute_knn(), and step_impute_linear().\n\n\n\n\n\n\nTODO\n\n\n\nfind a better data set\n\n\nBelow we are showing how we can impute using a K-nearest neighbor model using step_impute_knn(). We specify the variable to impute on first, and then with impute_with we specify which variables are used as predictors in the model.\n\nlibrary(recipes)\n\nimpute_knn_rec &lt;- recipe(mpg ~ ., data = mtcars) |&gt;\n  step_impute_knn(disp, neighbors = 1, impute_with = imp_vars(vs, am, hp, drat))\n\nimpute_knn_rec |&gt;\n  prep() |&gt;\n  juice()\n\n# A tibble: 32 × 11\n     cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb   mpg\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     6  160    110  3.9   2.62  16.5     0     1     4     4  21  \n 2     6  160    110  3.9   2.88  17.0     0     1     4     4  21  \n 3     4  108     93  3.85  2.32  18.6     1     1     4     1  22.8\n 4     6  258    110  3.08  3.22  19.4     1     0     3     1  21.4\n 5     8  360    175  3.15  3.44  17.0     0     0     3     2  18.7\n 6     6  225    105  2.76  3.46  20.2     1     0     3     1  18.1\n 7     8  360    245  3.21  3.57  15.8     0     0     3     4  14.3\n 8     4  147.    62  3.69  3.19  20       1     0     4     2  24.4\n 9     4  141.    95  3.92  3.15  22.9     1     0     4     2  22.8\n10     6  168.   123  3.92  3.44  18.3     1     0     4     4  19.2\n# ℹ 22 more rows",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Model Based Imputation</span>"
    ]
  },
  {
    "objectID": "missing-model.html#python-examples",
    "href": "missing-model.html#python-examples",
    "title": "43  Model Based Imputation",
    "section": "43.4 Python Examples",
    "text": "43.4 Python Examples\nI’m not aware of a good way to do this for models other than KNN in a scikit-learn way. Please file an issue on github if you know of a good way.\nWe are using the ames data set for examples. {sklearn} provided the KNNImputer() method we can use.\n\nfrom feazdata import ames\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import KNNImputer\n\nct = ColumnTransformer(\n    [('na_indicator', KNNImputer(), ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',  'Mas_Vnr_Area'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('na_indicator', KNNImputer(),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('na_indicator', KNNImputer(),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])]) na_indicator['Sale_Price', 'Lot_Area', 'Wood_Deck_SF', 'Mas_Vnr_Area']  KNNImputer?Documentation for KNNImputerKNNImputer() remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames)\n\n      na_indicator__Sale_Price  ...  remainder__Latitude\n0                     215000.0  ...               42.054\n1                     105000.0  ...               42.053\n2                     172000.0  ...               42.053\n3                     244000.0  ...               42.051\n4                     189900.0  ...               42.061\n...                        ...  ...                  ...\n2925                  142500.0  ...               41.989\n2926                  131000.0  ...               41.988\n2927                  132000.0  ...               41.987\n2928                  170000.0  ...               41.991\n2929                  188000.0  ...               41.989\n\n[2930 rows x 74 columns]\n\n\nThe argument n_neighbors is something you might have to tune to get good performance for this type of imputing method.\n\nct = ColumnTransformer(\n    [('na_indicator', KNNImputer(n_neighbors=15), ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',  'Mas_Vnr_Area'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('na_indicator', KNNImputer(n_neighbors=15),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('na_indicator', KNNImputer(n_neighbors=15),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])]) na_indicator['Sale_Price', 'Lot_Area', 'Wood_Deck_SF', 'Mas_Vnr_Area']  KNNImputer?Documentation for KNNImputerKNNImputer(n_neighbors=15) remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames)\n\n      na_indicator__Sale_Price  ...  remainder__Latitude\n0                     215000.0  ...               42.054\n1                     105000.0  ...               42.053\n2                     172000.0  ...               42.053\n3                     244000.0  ...               42.051\n4                     189900.0  ...               42.061\n...                        ...  ...                  ...\n2925                  142500.0  ...               41.989\n2926                  131000.0  ...               41.988\n2927                  132000.0  ...               41.987\n2928                  170000.0  ...               41.991\n2929                  188000.0  ...               41.989\n\n[2930 rows x 74 columns]\n\n\n\n\n\n\nBuuren, S. van. 2012. Flexible Imputation of Missing Data. Chapman & Hall/CRC Interdisciplinary Statistics. CRC Press. https://books.google.com/books?id=elDNBQAAQBAJ.",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>43</span>  <span class='chapter-title'>Model Based Imputation</span>"
    ]
  },
  {
    "objectID": "missing-indicator.html",
    "href": "missing-indicator.html",
    "title": "44  Missing Values Indicators",
    "section": "",
    "text": "44.1 Missing Values Indicators",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Missing Values Indicators</span>"
    ]
  },
  {
    "objectID": "missing-indicator.html#pros-and-cons",
    "href": "missing-indicator.html#pros-and-cons",
    "title": "44  Missing Values Indicators",
    "section": "44.2 Pros and Cons",
    "text": "44.2 Pros and Cons\n\n44.2.1 Pros\n\nNo performance harm when added to variables with no missing data\nSimple and interpretable\n\n\n\n44.2.2 Cons\n\nWill produce zero variance columns when used on data with no missing values\nCan create a sizable increase in data set size",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Missing Values Indicators</span>"
    ]
  },
  {
    "objectID": "missing-indicator.html#r-examples",
    "href": "missing-indicator.html#r-examples",
    "title": "44  Missing Values Indicators",
    "section": "44.3 R Examples",
    "text": "44.3 R Examples\n\n\n\n\n\n\nTODO\n\n\n\nfind a better data set\n\n\nFrom the recipes package, can we use the step_indicate_na() function to create indicator variables based on missing data\n\nlibrary(recipes)\n\nna_ind_rec &lt;- recipe(mpg ~ disp + vs + am, data = mtcars) |&gt;\n  step_indicate_na(all_predictors()) |&gt;\n  prep()\n\n\nna_ind_rec |&gt;\n  bake(new_data = mtcars)\n\n# A tibble: 32 × 7\n    disp    vs    am   mpg na_ind_disp na_ind_vs na_ind_am\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;       &lt;int&gt;     &lt;int&gt;     &lt;int&gt;\n 1  160      0     1  21             0         0         0\n 2  160      0     1  21             0         0         0\n 3  108      1     1  22.8           0         0         0\n 4  258      1     0  21.4           0         0         0\n 5  360      0     0  18.7           0         0         0\n 6  225      1     0  18.1           0         0         0\n 7  360      0     0  14.3           0         0         0\n 8  147.     1     0  24.4           0         0         0\n 9  141.     1     0  22.8           0         0         0\n10  168.     1     0  19.2           0         0         0\n# ℹ 22 more rows",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Missing Values Indicators</span>"
    ]
  },
  {
    "objectID": "missing-indicator.html#python-examples",
    "href": "missing-indicator.html#python-examples",
    "title": "44  Missing Values Indicators",
    "section": "44.4 Python Examples",
    "text": "44.4 Python Examples\nWe are using the ames data set for examples. {sklearn} provided the MissingIndicator() method we can use.\n\nfrom feazdata import ames\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import MissingIndicator\n\nct = ColumnTransformer(\n    [('na_indicator', MissingIndicator(), ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',  'Mas_Vnr_Area'])], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('na_indicator', MissingIndicator(),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('na_indicator', MissingIndicator(),\n                                 ['Sale_Price', 'Lot_Area', 'Wood_Deck_SF',\n                                  'Mas_Vnr_Area'])]) na_indicator['Sale_Price', 'Lot_Area', 'Wood_Deck_SF', 'Mas_Vnr_Area']  MissingIndicator?Documentation for MissingIndicatorMissingIndicator() remainder['MS_SubClass', 'MS_Zoning', 'Lot_Frontage', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Year_Built', 'Year_Remod_Add', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_SF_1', 'BsmtFin_Type_2', 'BsmtFin_SF_2', 'Bsmt_Unf_SF', 'Total_Bsmt_SF', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'First_Flr_SF', 'Second_Flr_SF', 'Gr_Liv_Area', 'Bsmt_Full_Bath', 'Bsmt_Half_Bath', 'Full_Bath', 'Half_Bath', 'Bedroom_AbvGr', 'Kitchen_AbvGr', 'TotRms_AbvGrd', 'Functional', 'Fireplaces', 'Garage_Type', 'Garage_Finish', 'Garage_Cars', 'Garage_Area', 'Garage_Cond', 'Paved_Drive', 'Open_Porch_SF', 'Enclosed_Porch', 'Three_season_porch', 'Screen_Porch', 'Pool_Area', 'Pool_QC', 'Fence', 'Misc_Feature', 'Misc_Val', 'Mo_Sold', 'Year_Sold', 'Sale_Type', 'Sale_Condition', 'Longitude', 'Latitude'] passthroughpassthrough \n\nct.transform(ames)\n\n                   remainder__MS_SubClass  ... remainder__Latitude\n0     One_Story_1946_and_Newer_All_Styles  ...              42.054\n1     One_Story_1946_and_Newer_All_Styles  ...              42.053\n2     One_Story_1946_and_Newer_All_Styles  ...              42.053\n3     One_Story_1946_and_Newer_All_Styles  ...              42.051\n4                Two_Story_1946_and_Newer  ...              42.061\n...                                   ...  ...                 ...\n2925                  Split_or_Multilevel  ...              41.989\n2926  One_Story_1946_and_Newer_All_Styles  ...              41.988\n2927                          Split_Foyer  ...              41.987\n2928  One_Story_1946_and_Newer_All_Styles  ...              41.991\n2929             Two_Story_1946_and_Newer  ...              41.989\n\n[2930 rows x 70 columns]",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>44</span>  <span class='chapter-title'>Missing Values Indicators</span>"
    ]
  },
  {
    "objectID": "missing-remove.html",
    "href": "missing-remove.html",
    "title": "45  Remove Missing Values",
    "section": "",
    "text": "45.1 Remove Missing Values",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Remove Missing Values</span>"
    ]
  },
  {
    "objectID": "missing-remove.html#pros-and-cons",
    "href": "missing-remove.html#pros-and-cons",
    "title": "45  Remove Missing Values",
    "section": "45.2 Pros and Cons",
    "text": "45.2 Pros and Cons\n\n45.2.1 Pros\n\nWill sometimes be necessary\n\n\n\n45.2.2 Cons\n\nExtreme care has to be taken\nLoss of data",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Remove Missing Values</span>"
    ]
  },
  {
    "objectID": "missing-remove.html#r-examples",
    "href": "missing-remove.html#r-examples",
    "title": "45  Remove Missing Values",
    "section": "45.3 R Examples",
    "text": "45.3 R Examples\n\n\n\n\n\n\nTODO\n\n\n\nfind data set\n\n\nWe can use the step_naomit() function from the recipes package to remove any observation that contains missing values.\n\nlibrary(recipes)\n\nnaomit_rec &lt;- recipe(~., data = mtcars) |&gt;\n  step_naomit(all_predictors()) |&gt;\n  prep()\n\nbake(naomit_rec, new_data = NULL)\n\n# A tibble: 32 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ℹ 22 more rows\n\n\n\n\n\n\n\n\nTODO\n\n\n\nwait for thresholded observation removal\n\n\nThere is the step_filter_missing() function from the recipes package that removes predictors with more missing values than the specified threshold\n\nlibrary(recipes)\n\nfilter_missing_rec &lt;- recipe(~., data = mtcars) |&gt;\n  step_filter_missing(all_predictors()) |&gt;\n  prep()\n\nbake(filter_missing_rec, new_data = NULL)\n\n# A tibble: 32 × 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ℹ 22 more rows",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Remove Missing Values</span>"
    ]
  },
  {
    "objectID": "missing-remove.html#python-examples",
    "href": "missing-remove.html#python-examples",
    "title": "45  Remove Missing Values",
    "section": "45.4 Python Examples",
    "text": "45.4 Python Examples\nI’m not aware of a good way to do this in a scikit-learn way. Please file an issue on github if you know of a good way.",
    "crumbs": [
      "Missing Data",
      "<span class='chapter-number'>45</span>  <span class='chapter-title'>Remove Missing Values</span>"
    ]
  },
  {
    "objectID": "text.html",
    "href": "text.html",
    "title": "46  Text Overview",
    "section": "",
    "text": "46.1 Text Overview",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Text Overview</span>"
    ]
  },
  {
    "objectID": "text.html#text-cleaning",
    "href": "text.html#text-cleaning",
    "title": "46  Text Overview",
    "section": "46.2 Text cleaning",
    "text": "46.2 Text cleaning\nIn Chapter 48, we will look over the ways we take raw text and get it ready for later tasks. This work deals with encoding issues, standardization, and cases and sometimes you need to get rid of a lot of unwanted chunks.",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Text Overview</span>"
    ]
  },
  {
    "objectID": "text.html#tokenization",
    "href": "text.html#tokenization",
    "title": "46  Text Overview",
    "section": "46.3 Tokenization",
    "text": "46.3 Tokenization\nOnce the text is cleaned, we need to split it into a smaller unit of information such that we can count it, this is called tokenization and we will visit that in Chapter 49.",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Text Overview</span>"
    ]
  },
  {
    "objectID": "text.html#modifying-tokens",
    "href": "text.html#modifying-tokens",
    "title": "46  Text Overview",
    "section": "46.4 Modifying tokens",
    "text": "46.4 Modifying tokens\nOnce you have the data as tokens, one of the things you might want to do is modify them in various ways. This could be things like changing the endings to words or changing the words entirely. We see examples of this in Chapter 50 and Chapter 51.",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Text Overview</span>"
    ]
  },
  {
    "objectID": "text.html#filtering-tokens",
    "href": "text.html#filtering-tokens",
    "title": "46  Text Overview",
    "section": "46.5 Filtering tokens",
    "text": "46.5 Filtering tokens\nThe tokens you create might not all be of the same quality. Depending on your choice of tokenizer, there will be reasons for you to remove some of the tokens you have created. We see examples of this in Chapter 52 and Chapter 53.",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Text Overview</span>"
    ]
  },
  {
    "objectID": "text.html#counting-tokens",
    "href": "text.html#counting-tokens",
    "title": "46  Text Overview",
    "section": "46.6 Counting tokens",
    "text": "46.6 Counting tokens\nWe have gotten to the end of the line and we are ready to turn the tokens into numeric variables we can use. There are many different ways we look at them in Chapter 54, Chapter 55, Chapter 56, Chapter 57, and Chapter 58.",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Text Overview</span>"
    ]
  },
  {
    "objectID": "text.html#embeddings",
    "href": "text.html#embeddings",
    "title": "46  Text Overview",
    "section": "46.7 Embeddings",
    "text": "46.7 Embeddings\nAnother way to use text is to work with embeddings, this is another powerful tool that can give you good performance. We look at some of them in Chapter 59 and Chapter 60.",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Text Overview</span>"
    ]
  },
  {
    "objectID": "text.html#footnotes",
    "href": "text.html#footnotes",
    "title": "46  Text Overview",
    "section": "",
    "text": "https://thegradient.pub/the-benderrule-on-naming-the-languages-we-study-and-why-it-matters/↩︎",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>46</span>  <span class='chapter-title'>Text Overview</span>"
    ]
  },
  {
    "objectID": "text-manual.html",
    "href": "text-manual.html",
    "title": "47  Manual Text Features",
    "section": "",
    "text": "47.1 Manual Text Features",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Manual Text Features</span>"
    ]
  },
  {
    "objectID": "text-manual.html#pros-and-cons",
    "href": "text-manual.html#pros-and-cons",
    "title": "47  Manual Text Features",
    "section": "47.2 Pros and Cons",
    "text": "47.2 Pros and Cons\n\n47.2.1 Pros\n\nClear and actionable features\nHigh interpretability\n\n\n\n47.2.2 Cons\n\nCan be time-consuming to create\nComputational speed depends on the feature\nWill likely need to",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Manual Text Features</span>"
    ]
  },
  {
    "objectID": "text-manual.html#r-examples",
    "href": "text-manual.html#r-examples",
    "title": "47  Manual Text Features",
    "section": "47.3 R Examples",
    "text": "47.3 R Examples\n\n\n\n\n\n\nTODO\n\n\n\nfind a better data set\n\n\nThe textfeatures package is one package in R that contains a bunch of general features that may or may not be useful.\n\nlibrary(textfeatures)\nlibrary(modeldata)\n\ntextfeatures(modeldata::tate_text$medium, word_dims = 0, \n             verbose = FALSE) |&gt;\n  dplyr::glimpse()\n\nRows: 4,284\nColumns: 34\n$ n_urls           &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ n_uq_urls        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ n_hashtags       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ n_uq_hashtags    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ n_mentions       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ n_uq_mentions    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ n_chars          &lt;dbl&gt; 1.39951429, -0.91391731, -0.91391731, -0.91391731, -0…\n$ n_uq_chars       &lt;dbl&gt; 1.3463720, -0.2656168, -0.2656168, -0.2656168, -0.585…\n$ n_commas         &lt;dbl&gt; 1.2867430, -0.6470182, -0.6470182, -0.6470182, -0.647…\n$ n_digits         &lt;dbl&gt; -0.2800874, -0.2800874, -0.2800874, -0.2800874, -0.28…\n$ n_exclaims       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ n_extraspaces    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ n_lowers         &lt;dbl&gt; 1.348546506, -0.912127069, -0.912127069, -0.912127069…\n$ n_lowersp        &lt;dbl&gt; -1.0518721, 0.1014681, 0.1014681, 0.1014681, 0.352584…\n$ n_periods        &lt;dbl&gt; -0.04324894, -0.04324894, -0.04324894, -0.04324894, -…\n$ n_words          &lt;dbl&gt; 1.3593949, -0.7937823, -0.7937823, -0.7937823, -0.162…\n$ n_uq_words       &lt;dbl&gt; 1.4230658, -0.7920930, -0.7920930, -0.7920930, -0.142…\n$ n_caps           &lt;dbl&gt; -0.04050572, -0.04050572, -0.04050572, -0.04050572, -…\n$ n_nonasciis      &lt;dbl&gt; -0.02646899, -0.02646899, -0.02646899, -0.02646899, -…\n$ n_puncts         &lt;dbl&gt; 5.6233563, -0.2031327, -0.2031327, -0.2031327, -0.203…\n$ n_capsp          &lt;dbl&gt; -1.2508524, 0.8890397, 0.8890397, 0.8890397, 0.538919…\n$ n_charsperword   &lt;dbl&gt; 1.09976675, -0.87544061, -0.87544061, -0.87544061, -1…\n$ sent_afinn       &lt;dbl&gt; 0.01511448, 0.01511448, 0.01511448, 0.01511448, 0.015…\n$ sent_bing        &lt;dbl&gt; -0.07864915, -0.07864915, -0.07864915, -0.07864915, -…\n$ sent_syuzhet     &lt;dbl&gt; -0.1334035, -0.1334035, -0.1334035, -0.1334035, -0.13…\n$ sent_vader       &lt;dbl&gt; -0.06711618, -0.06711618, -0.06711618, -0.06711618, -…\n$ n_polite         &lt;dbl&gt; 0.05597655, 0.05597655, 0.05597655, 0.05597655, 0.055…\n$ n_first_person   &lt;dbl&gt; -0.01527831, -0.01527831, -0.01527831, -0.01527831, -…\n$ n_first_personp  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ n_second_person  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ n_second_personp &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ n_third_person   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ n_tobe           &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ n_prepositions   &lt;dbl&gt; -2.3324219, 0.3482094, 0.3482094, 0.3482094, 0.348209…\n\n\n\n\n\n\n\n\nTODO\n\n\n\nCome up with domain-specific examples",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Manual Text Features</span>"
    ]
  },
  {
    "objectID": "text-manual.html#python-examples",
    "href": "text-manual.html#python-examples",
    "title": "47  Manual Text Features",
    "section": "47.4 Python Examples",
    "text": "47.4 Python Examples",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>47</span>  <span class='chapter-title'>Manual Text Features</span>"
    ]
  },
  {
    "objectID": "text-cleaning.html",
    "href": "text-cleaning.html",
    "title": "48  Text Cleaning",
    "section": "",
    "text": "48.1 Text Cleaning",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Text Cleaning</span>"
    ]
  },
  {
    "objectID": "text-cleaning.html#pros-and-cons",
    "href": "text-cleaning.html#pros-and-cons",
    "title": "48  Text Cleaning",
    "section": "48.2 Pros and Cons",
    "text": "48.2 Pros and Cons\n\n48.2.1 Pros\n\nWhen applied correctly, can lead to boosts in insights into the data\n\n\n\n48.2.2 Cons\n\nCan be a quite manual process which will likely be domain specific",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Text Cleaning</span>"
    ]
  },
  {
    "objectID": "text-cleaning.html#r-examples",
    "href": "text-cleaning.html#r-examples",
    "title": "48  Text Cleaning",
    "section": "48.3 R Examples",
    "text": "48.3 R Examples\n\n\n\n\n\n\nTODO\n\n\n\nFind a data set that isn’t clean\n\n\nWe will use the step_text_normalization() function from the {textrecipes} package to perform unicode normalization, which defaults to the NFC normalization form.\n\nlibrary(textrecipes)\n\nLoading required package: recipes\n\n\nLoading required package: dplyr\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\nAttaching package: 'recipes'\n\n\nThe following object is masked from 'package:stats':\n\n    step\n\nsample_data &lt;- tibble(text = c(\"sch\\U00f6n\", \"scho\\U0308n\"))\n\nsample_data |&gt;\n  count(text)\n\n# A tibble: 2 × 2\n  text      n\n  &lt;chr&gt; &lt;int&gt;\n1 schön     1\n2 schön     1\n\nrec &lt;- recipe(~., data = sample_data) |&gt;\n  step_text_normalization(text) |&gt;\n  prep()\n\nrec |&gt;\n  bake(new_data = NULL) |&gt;\n  count(text)\n\n# A tibble: 1 × 2\n  text      n\n  &lt;fct&gt; &lt;int&gt;\n1 schön     2",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Text Cleaning</span>"
    ]
  },
  {
    "objectID": "text-cleaning.html#python-examples",
    "href": "text-cleaning.html#python-examples",
    "title": "48  Text Cleaning",
    "section": "48.4 Python Examples",
    "text": "48.4 Python Examples",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>48</span>  <span class='chapter-title'>Text Cleaning</span>"
    ]
  },
  {
    "objectID": "text-tokenization.html",
    "href": "text-tokenization.html",
    "title": "49  Tokenization",
    "section": "",
    "text": "49.1 Tokenization",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Tokenization</span>"
    ]
  },
  {
    "objectID": "text-tokenization.html#pros-and-cons",
    "href": "text-tokenization.html#pros-and-cons",
    "title": "49  Tokenization",
    "section": "49.2 Pros and Cons",
    "text": "49.2 Pros and Cons\n\n49.2.1 Pros\n\nMany established methods are implemented\nYou rarely have to think about performance in terms of speed\n\n\n\n49.2.2 Cons\n\nThere is often not a best answer, and experimentation will be needed\nsomething a handcrafted tokenizer will go better than an off-the-shelf version",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Tokenization</span>"
    ]
  },
  {
    "objectID": "text-tokenization.html#r-examples",
    "href": "text-tokenization.html#r-examples",
    "title": "49  Tokenization",
    "section": "49.3 R Examples",
    "text": "49.3 R Examples\n\n\n\n\n\n\nTODO\n\n\n\nfind text data set to use",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Tokenization</span>"
    ]
  },
  {
    "objectID": "text-tokenization.html#python-examples",
    "href": "text-tokenization.html#python-examples",
    "title": "49  Tokenization",
    "section": "49.4 Python Examples",
    "text": "49.4 Python Examples\n\n\n\n\n\n\nTODO\n\n\n\nfigure out the best approach to teach in Python. Should we stay in scikit-learn? move somewhere else? how should this be taught since it is likely not separate as it is in {textrecipes}",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>49</span>  <span class='chapter-title'>Tokenization</span>"
    ]
  },
  {
    "objectID": "text-stemming.html",
    "href": "text-stemming.html",
    "title": "50  Stemming",
    "section": "",
    "text": "50.1 Stemming",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Stemming</span>"
    ]
  },
  {
    "objectID": "text-stemming.html#pros-and-cons",
    "href": "text-stemming.html#pros-and-cons",
    "title": "50  Stemming",
    "section": "50.2 Pros and Cons",
    "text": "50.2 Pros and Cons\n\n50.2.1 Pros\n\nCan be a fast and easy way to reduce the number of tokens\n\n\n\n50.2.2 Cons\n\nDoes require thorough inspection to avoid wrongful collapse",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Stemming</span>"
    ]
  },
  {
    "objectID": "text-stemming.html#r-examples",
    "href": "text-stemming.html#r-examples",
    "title": "50  Stemming",
    "section": "50.3 R Examples",
    "text": "50.3 R Examples",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Stemming</span>"
    ]
  },
  {
    "objectID": "text-stemming.html#python-examples",
    "href": "text-stemming.html#python-examples",
    "title": "50  Stemming",
    "section": "50.4 Python Examples",
    "text": "50.4 Python Examples\n\n\n\n\nHonnibal, Matthew, Ines Montani, Sofie Van Landeghem, and Adriane Boyd. 2020. “spaCy: Industrial-strength Natural Language Processing in Python.” https://doi.org/10.5281/zenodo.1212303.\n\n\nPorter, Martin F. 1980. “An Algorithm for Suffix Stripping.” Program 14 (3): 130–37. https://doi.org/10.1108/eb046814.",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>50</span>  <span class='chapter-title'>Stemming</span>"
    ]
  },
  {
    "objectID": "text-ngrams.html",
    "href": "text-ngrams.html",
    "title": "51  N-grams",
    "section": "",
    "text": "51.1 N-grams",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>N-grams</span>"
    ]
  },
  {
    "objectID": "text-ngrams.html#pros-and-cons",
    "href": "text-ngrams.html#pros-and-cons",
    "title": "51  N-grams",
    "section": "51.2 Pros and Cons",
    "text": "51.2 Pros and Cons\n\n51.2.1 Pros\n\nCan uncover patterns in the data not otherwise seen\n\n\n\n51.2.2 Cons\n\nCan lead to longer computation times",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>N-grams</span>"
    ]
  },
  {
    "objectID": "text-ngrams.html#r-examples",
    "href": "text-ngrams.html#r-examples",
    "title": "51  N-grams",
    "section": "51.3 R Examples",
    "text": "51.3 R Examples",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>N-grams</span>"
    ]
  },
  {
    "objectID": "text-ngrams.html#python-examples",
    "href": "text-ngrams.html#python-examples",
    "title": "51  N-grams",
    "section": "51.4 Python Examples",
    "text": "51.4 Python Examples",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>51</span>  <span class='chapter-title'>N-grams</span>"
    ]
  },
  {
    "objectID": "text-stopwords.html",
    "href": "text-stopwords.html",
    "title": "52  Stop words",
    "section": "",
    "text": "52.1 Stop words",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Stop words</span>"
    ]
  },
  {
    "objectID": "text-stopwords.html#pros-and-cons",
    "href": "text-stopwords.html#pros-and-cons",
    "title": "52  Stop words",
    "section": "52.2 Pros and Cons",
    "text": "52.2 Pros and Cons\n\n52.2.1 Pros\n\n\n52.2.2 Cons",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Stop words</span>"
    ]
  },
  {
    "objectID": "text-stopwords.html#r-examples",
    "href": "text-stopwords.html#r-examples",
    "title": "52  Stop words",
    "section": "52.3 R Examples",
    "text": "52.3 R Examples",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Stop words</span>"
    ]
  },
  {
    "objectID": "text-stopwords.html#python-examples",
    "href": "text-stopwords.html#python-examples",
    "title": "52  Stop words",
    "section": "52.4 Python Examples",
    "text": "52.4 Python Examples\n\n\n\n\nLewis, David D., Yiming Yang, Tony G. Rose, and Fan Li. 2004. “RCV1: A New Benchmark Collection for Text Categorization Research.” Journal of Machine Learning Research 5: 361–97. https://www.jmlr.org/papers/volume5/lewis04a/lewis04a.pdf.\n\n\nLuhn, H. P. 1960. “Key Word-in-Context Index for Technical Literature (Kwic Index).” American Documentation 11 (4): 288–95. https://doi.org/https://doi.org/10.1002/asi.5090110403.\n\n\nPorter, Martin F. 2001. “Snowball: A Language for Stemming Algorithms.” https://snowballstem.org.",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>52</span>  <span class='chapter-title'>Stop words</span>"
    ]
  },
  {
    "objectID": "text-filter.html",
    "href": "text-filter.html",
    "title": "53  🏗️ Token Filter",
    "section": "",
    "text": "53.1 Token Filter",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>🏗️ Token Filter</span>"
    ]
  },
  {
    "objectID": "text-filter.html#pros-and-cons",
    "href": "text-filter.html#pros-and-cons",
    "title": "53  🏗️ Token Filter",
    "section": "53.2 Pros and Cons",
    "text": "53.2 Pros and Cons\n\n53.2.1 Pros\n\n\n53.2.2 Cons",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>🏗️ Token Filter</span>"
    ]
  },
  {
    "objectID": "text-filter.html#r-examples",
    "href": "text-filter.html#r-examples",
    "title": "53  🏗️ Token Filter",
    "section": "53.3 R Examples",
    "text": "53.3 R Examples",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>🏗️ Token Filter</span>"
    ]
  },
  {
    "objectID": "text-filter.html#python-examples",
    "href": "text-filter.html#python-examples",
    "title": "53  🏗️ Token Filter",
    "section": "53.4 Python Examples",
    "text": "53.4 Python Examples",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>53</span>  <span class='chapter-title'>🏗️ Token Filter</span>"
    ]
  },
  {
    "objectID": "text-tf.html",
    "href": "text-tf.html",
    "title": "54  🏗️ Term Frequency",
    "section": "",
    "text": "54.1 Term Frequency",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>🏗️ Term Frequency</span>"
    ]
  },
  {
    "objectID": "text-tf.html#pros-and-cons",
    "href": "text-tf.html#pros-and-cons",
    "title": "54  🏗️ Term Frequency",
    "section": "54.2 Pros and Cons",
    "text": "54.2 Pros and Cons\n\n54.2.1 Pros\n\n\n54.2.2 Cons",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>🏗️ Term Frequency</span>"
    ]
  },
  {
    "objectID": "text-tf.html#r-examples",
    "href": "text-tf.html#r-examples",
    "title": "54  🏗️ Term Frequency",
    "section": "54.3 R Examples",
    "text": "54.3 R Examples",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>🏗️ Term Frequency</span>"
    ]
  },
  {
    "objectID": "text-tf.html#python-examples",
    "href": "text-tf.html#python-examples",
    "title": "54  🏗️ Term Frequency",
    "section": "54.4 Python Examples",
    "text": "54.4 Python Examples",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>54</span>  <span class='chapter-title'>🏗️ Term Frequency</span>"
    ]
  },
  {
    "objectID": "text-tfidf.html",
    "href": "text-tfidf.html",
    "title": "55  🏗️ TF-IDF",
    "section": "",
    "text": "55.1 TF-IDF",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>🏗️ TF-IDF</span>"
    ]
  },
  {
    "objectID": "text-tfidf.html#pros-and-cons",
    "href": "text-tfidf.html#pros-and-cons",
    "title": "55  🏗️ TF-IDF",
    "section": "55.2 Pros and Cons",
    "text": "55.2 Pros and Cons\n\n55.2.1 Pros\n\n\n55.2.2 Cons",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>🏗️ TF-IDF</span>"
    ]
  },
  {
    "objectID": "text-tfidf.html#r-examples",
    "href": "text-tfidf.html#r-examples",
    "title": "55  🏗️ TF-IDF",
    "section": "55.3 R Examples",
    "text": "55.3 R Examples",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>🏗️ TF-IDF</span>"
    ]
  },
  {
    "objectID": "text-tfidf.html#python-examples",
    "href": "text-tfidf.html#python-examples",
    "title": "55  🏗️ TF-IDF",
    "section": "55.4 Python Examples",
    "text": "55.4 Python Examples",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>55</span>  <span class='chapter-title'>🏗️ TF-IDF</span>"
    ]
  },
  {
    "objectID": "text-hashing.html",
    "href": "text-hashing.html",
    "title": "56  🏗️ Token Hashing",
    "section": "",
    "text": "56.1 Token Hashing",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>🏗️ Token Hashing</span>"
    ]
  },
  {
    "objectID": "text-hashing.html#pros-and-cons",
    "href": "text-hashing.html#pros-and-cons",
    "title": "56  🏗️ Token Hashing",
    "section": "56.2 Pros and Cons",
    "text": "56.2 Pros and Cons\n\n56.2.1 Pros\n\n\n56.2.2 Cons",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>🏗️ Token Hashing</span>"
    ]
  },
  {
    "objectID": "text-hashing.html#r-examples",
    "href": "text-hashing.html#r-examples",
    "title": "56  🏗️ Token Hashing",
    "section": "56.3 R Examples",
    "text": "56.3 R Examples",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>🏗️ Token Hashing</span>"
    ]
  },
  {
    "objectID": "text-hashing.html#python-examples",
    "href": "text-hashing.html#python-examples",
    "title": "56  🏗️ Token Hashing",
    "section": "56.4 Python Examples",
    "text": "56.4 Python Examples",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>56</span>  <span class='chapter-title'>🏗️ Token Hashing</span>"
    ]
  },
  {
    "objectID": "text-onehot.html",
    "href": "text-onehot.html",
    "title": "57  🏗️ Sequence Encoding",
    "section": "",
    "text": "57.1 Sequence Encoding",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>🏗️ Sequence Encoding</span>"
    ]
  },
  {
    "objectID": "text-onehot.html#pros-and-cons",
    "href": "text-onehot.html#pros-and-cons",
    "title": "57  🏗️ Sequence Encoding",
    "section": "57.2 Pros and Cons",
    "text": "57.2 Pros and Cons\n\n57.2.1 Pros\n\n\n57.2.2 Cons",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>🏗️ Sequence Encoding</span>"
    ]
  },
  {
    "objectID": "text-onehot.html#r-examples",
    "href": "text-onehot.html#r-examples",
    "title": "57  🏗️ Sequence Encoding",
    "section": "57.3 R Examples",
    "text": "57.3 R Examples",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>🏗️ Sequence Encoding</span>"
    ]
  },
  {
    "objectID": "text-onehot.html#python-examples",
    "href": "text-onehot.html#python-examples",
    "title": "57  🏗️ Sequence Encoding",
    "section": "57.4 Python Examples",
    "text": "57.4 Python Examples",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>57</span>  <span class='chapter-title'>🏗️ Sequence Encoding</span>"
    ]
  },
  {
    "objectID": "text-lda.html",
    "href": "text-lda.html",
    "title": "58  🏗️ LDA",
    "section": "",
    "text": "58.1 LDA",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>🏗️ LDA</span>"
    ]
  },
  {
    "objectID": "text-lda.html#pros-and-cons",
    "href": "text-lda.html#pros-and-cons",
    "title": "58  🏗️ LDA",
    "section": "58.2 Pros and Cons",
    "text": "58.2 Pros and Cons\n\n58.2.1 Pros\n\n\n58.2.2 Cons",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>🏗️ LDA</span>"
    ]
  },
  {
    "objectID": "text-lda.html#r-examples",
    "href": "text-lda.html#r-examples",
    "title": "58  🏗️ LDA",
    "section": "58.3 R Examples",
    "text": "58.3 R Examples",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>🏗️ LDA</span>"
    ]
  },
  {
    "objectID": "text-lda.html#python-examples",
    "href": "text-lda.html#python-examples",
    "title": "58  🏗️ LDA",
    "section": "58.4 Python Examples",
    "text": "58.4 Python Examples",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>58</span>  <span class='chapter-title'>🏗️ LDA</span>"
    ]
  },
  {
    "objectID": "text-word2vec.html",
    "href": "text-word2vec.html",
    "title": "59  🏗️ word2vec",
    "section": "",
    "text": "59.1 word2vec",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>🏗️ word2vec</span>"
    ]
  },
  {
    "objectID": "text-word2vec.html#pros-and-cons",
    "href": "text-word2vec.html#pros-and-cons",
    "title": "59  🏗️ word2vec",
    "section": "59.2 Pros and Cons",
    "text": "59.2 Pros and Cons\n\n59.2.1 Pros\n\n\n59.2.2 Cons",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>🏗️ word2vec</span>"
    ]
  },
  {
    "objectID": "text-word2vec.html#r-examples",
    "href": "text-word2vec.html#r-examples",
    "title": "59  🏗️ word2vec",
    "section": "59.3 R Examples",
    "text": "59.3 R Examples",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>🏗️ word2vec</span>"
    ]
  },
  {
    "objectID": "text-word2vec.html#python-examples",
    "href": "text-word2vec.html#python-examples",
    "title": "59  🏗️ word2vec",
    "section": "59.4 Python Examples",
    "text": "59.4 Python Examples",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>59</span>  <span class='chapter-title'>🏗️ word2vec</span>"
    ]
  },
  {
    "objectID": "text-bert.html",
    "href": "text-bert.html",
    "title": "60  🏗️ BERT",
    "section": "",
    "text": "60.1 BERT",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>🏗️ BERT</span>"
    ]
  },
  {
    "objectID": "text-bert.html#pros-and-cons",
    "href": "text-bert.html#pros-and-cons",
    "title": "60  🏗️ BERT",
    "section": "60.2 Pros and Cons",
    "text": "60.2 Pros and Cons\n\n60.2.1 Pros\n\n\n60.2.2 Cons",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>🏗️ BERT</span>"
    ]
  },
  {
    "objectID": "text-bert.html#r-examples",
    "href": "text-bert.html#r-examples",
    "title": "60  🏗️ BERT",
    "section": "60.3 R Examples",
    "text": "60.3 R Examples",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>🏗️ BERT</span>"
    ]
  },
  {
    "objectID": "text-bert.html#python-examples",
    "href": "text-bert.html#python-examples",
    "title": "60  🏗️ BERT",
    "section": "60.4 Python Examples",
    "text": "60.4 Python Examples",
    "crumbs": [
      "Text Features",
      "<span class='chapter-number'>60</span>  <span class='chapter-title'>🏗️ BERT</span>"
    ]
  },
  {
    "objectID": "circular.html",
    "href": "circular.html",
    "title": "61  Circular Overview",
    "section": "",
    "text": "61.1 Circular Overview",
    "crumbs": [
      "Circular Features",
      "<span class='chapter-number'>61</span>  <span class='chapter-title'>Circular Overview</span>"
    ]
  },
  {
    "objectID": "circular-trig.html",
    "href": "circular-trig.html",
    "title": "62  🏗️ Trigonometric",
    "section": "",
    "text": "62.1 Trigonometric",
    "crumbs": [
      "Circular Features",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>🏗️ Trigonometric</span>"
    ]
  },
  {
    "objectID": "circular-trig.html#pros-and-cons",
    "href": "circular-trig.html#pros-and-cons",
    "title": "62  🏗️ Trigonometric",
    "section": "62.2 Pros and Cons",
    "text": "62.2 Pros and Cons\n\n62.2.1 Pros\n\n\n62.2.2 Cons",
    "crumbs": [
      "Circular Features",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>🏗️ Trigonometric</span>"
    ]
  },
  {
    "objectID": "circular-trig.html#r-examples",
    "href": "circular-trig.html#r-examples",
    "title": "62  🏗️ Trigonometric",
    "section": "62.3 R Examples",
    "text": "62.3 R Examples",
    "crumbs": [
      "Circular Features",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>🏗️ Trigonometric</span>"
    ]
  },
  {
    "objectID": "circular-trig.html#python-examples",
    "href": "circular-trig.html#python-examples",
    "title": "62  🏗️ Trigonometric",
    "section": "62.4 Python Examples",
    "text": "62.4 Python Examples",
    "crumbs": [
      "Circular Features",
      "<span class='chapter-number'>62</span>  <span class='chapter-title'>🏗️ Trigonometric</span>"
    ]
  },
  {
    "objectID": "circular-splines.html",
    "href": "circular-splines.html",
    "title": "63  🏗️ Periodic Splines",
    "section": "",
    "text": "63.1 Periodic Splines",
    "crumbs": [
      "Circular Features",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>🏗️ Periodic Splines</span>"
    ]
  },
  {
    "objectID": "circular-splines.html#pros-and-cons",
    "href": "circular-splines.html#pros-and-cons",
    "title": "63  🏗️ Periodic Splines",
    "section": "63.2 Pros and Cons",
    "text": "63.2 Pros and Cons\n\n63.2.1 Pros\n\n\n63.2.2 Cons",
    "crumbs": [
      "Circular Features",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>🏗️ Periodic Splines</span>"
    ]
  },
  {
    "objectID": "circular-splines.html#r-examples",
    "href": "circular-splines.html#r-examples",
    "title": "63  🏗️ Periodic Splines",
    "section": "63.3 R Examples",
    "text": "63.3 R Examples",
    "crumbs": [
      "Circular Features",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>🏗️ Periodic Splines</span>"
    ]
  },
  {
    "objectID": "circular-splines.html#python-examples",
    "href": "circular-splines.html#python-examples",
    "title": "63  🏗️ Periodic Splines",
    "section": "63.4 Python Examples",
    "text": "63.4 Python Examples",
    "crumbs": [
      "Circular Features",
      "<span class='chapter-number'>63</span>  <span class='chapter-title'>🏗️ Periodic Splines</span>"
    ]
  },
  {
    "objectID": "circular-indicators.html",
    "href": "circular-indicators.html",
    "title": "64  🏗️ Periodic Indicators",
    "section": "",
    "text": "64.1 Periodic Indicators",
    "crumbs": [
      "Circular Features",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>🏗️ Periodic Indicators</span>"
    ]
  },
  {
    "objectID": "circular-indicators.html#pros-and-cons",
    "href": "circular-indicators.html#pros-and-cons",
    "title": "64  🏗️ Periodic Indicators",
    "section": "64.2 Pros and Cons",
    "text": "64.2 Pros and Cons\n\n64.2.1 Pros\n\n\n64.2.2 Cons",
    "crumbs": [
      "Circular Features",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>🏗️ Periodic Indicators</span>"
    ]
  },
  {
    "objectID": "circular-indicators.html#r-examples",
    "href": "circular-indicators.html#r-examples",
    "title": "64  🏗️ Periodic Indicators",
    "section": "64.3 R Examples",
    "text": "64.3 R Examples",
    "crumbs": [
      "Circular Features",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>🏗️ Periodic Indicators</span>"
    ]
  },
  {
    "objectID": "circular-indicators.html#python-examples",
    "href": "circular-indicators.html#python-examples",
    "title": "64  🏗️ Periodic Indicators",
    "section": "64.4 Python Examples",
    "text": "64.4 Python Examples",
    "crumbs": [
      "Circular Features",
      "<span class='chapter-number'>64</span>  <span class='chapter-title'>🏗️ Periodic Indicators</span>"
    ]
  },
  {
    "objectID": "too-many.html",
    "href": "too-many.html",
    "title": "65  Too Many Overview",
    "section": "",
    "text": "65.1 Too Many Overview",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Too Many Overview</span>"
    ]
  },
  {
    "objectID": "too-many.html#non-zero-variance-filtering",
    "href": "too-many.html#non-zero-variance-filtering",
    "title": "65  Too Many Overview",
    "section": "65.2 Non-zero Variance filtering",
    "text": "65.2 Non-zero Variance filtering\nThese types of methods are quite simple, we remove variables that take a few number of values. If the value is always 1 then it doesn’t have any information in it and we should remove it. If the variables are almost always the same we might want to remove them. We look at these methods in Chapter 66.",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Too Many Overview</span>"
    ]
  },
  {
    "objectID": "too-many.html#dimensionality-reduction",
    "href": "too-many.html#dimensionality-reduction",
    "title": "65  Too Many Overview",
    "section": "65.3 Dimensionality reduction",
    "text": "65.3 Dimensionality reduction\nThe bulk of the chapter will be in this category. This book categorizes dimensionality reduction methods as methods where a calculation is done on several features, with the same or fewer features being returned. Remember that we only look at methods that can be used in predictive settings, hence we won’t be talking about t-distributed stochastic neighbor embedding t-SNE.\n\nPrincipal Component Analysis (PCA) Chapter 67\nPCA variants Chapter 68\nIndependent Component Analysis (ICA) Chapter 69\nNon-negative matrix factorization (NMF) Chapter 70\nLinear discriminant analysis (LDA) Chapter 71\nGeneralized discriminant analysis (GDA) Chapter 72\nAutoencoders Chapter 73\nUniform Manifold Approximation and Projection (UMAP) Chapter 74\nISOMAP Chapter 75",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Too Many Overview</span>"
    ]
  },
  {
    "objectID": "too-many.html#feature-selection",
    "href": "too-many.html#feature-selection",
    "title": "65  Too Many Overview",
    "section": "65.4 Feature selection",
    "text": "65.4 Feature selection\nFeature selection on the other hand finds which variables to keep or remove. And then you act on that. This can be done in a couple of different ways. Filter-based approaches are covered in Chapter 76, these methods give each feature a score or rank, and then you use this information to select variables. There are many different ways to get these rankings and many will be covered in the chapter. Wrapper-based approaches are covered in Chapter 77. These methods iteratively look at subsets of data to try to find the best set. Their main downside is they tend to add a lot of computational overhead as you need to fit your model many times. Lastly, we have embedded methods which will be covered in Chapter 78. These methods use more advanced methods, sometimes other models, to do the feature selection.",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>65</span>  <span class='chapter-title'>Too Many Overview</span>"
    ]
  },
  {
    "objectID": "too-many-zv.html",
    "href": "too-many-zv.html",
    "title": "66  Zero Variance Filter",
    "section": "",
    "text": "66.1 Zero Variance Filter",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Zero Variance Filter</span>"
    ]
  },
  {
    "objectID": "too-many-zv.html#pros-and-cons",
    "href": "too-many-zv.html#pros-and-cons",
    "title": "66  Zero Variance Filter",
    "section": "66.2 Pros and Cons",
    "text": "66.2 Pros and Cons\n\n66.2.1 Pros\n\nRemoving zero variance predictors should provide no downside\nFaster and smaller models\nEasy to explain and execute\n\n\n\n66.2.2 Cons\n\nRemoval of near-zero predictors requires care to avoid removing useful predictors",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Zero Variance Filter</span>"
    ]
  },
  {
    "objectID": "too-many-zv.html#r-examples",
    "href": "too-many-zv.html#r-examples",
    "title": "66  Zero Variance Filter",
    "section": "66.3 R Examples",
    "text": "66.3 R Examples\nWe will use the step_zv() and step_nzv() steps which are used to remove zero variance and near-zero variance preditors respectively.\n\n\n\n\n\n\nTODO\n\n\n\nfind a good data set\n\n\nBelow we are using the step_zv() function to remove\n\nlibrary(recipes)\n\ndata(\"ames\", package = \"modeldata\")\n\nzv_rec &lt;- recipe(Sale_Price ~ ., data = ames) |&gt;\n  step_zv(all_predictors()) |&gt;\n  prep()\n\nWe can use the tidy() method to find out which variables were removed\n\nzv_rec |&gt;\n  tidy(1)\n\n# A tibble: 0 × 2\n# ℹ 2 variables: terms &lt;chr&gt;, id &lt;chr&gt;\n\n\nWe can remove non-zero variance predictors in the same manner using step_nzv()\n\nnzv_rec &lt;- recipe(Sale_Price ~ ., data = ames) |&gt;\n  step_nzv(all_predictors()) |&gt;\n  prep()\n\nnzv_rec |&gt;\n  tidy(1)\n\n# A tibble: 21 × 2\n   terms          id       \n   &lt;chr&gt;          &lt;chr&gt;    \n 1 Street         nzv_RUieL\n 2 Alley          nzv_RUieL\n 3 Land_Contour   nzv_RUieL\n 4 Utilities      nzv_RUieL\n 5 Land_Slope     nzv_RUieL\n 6 Condition_2    nzv_RUieL\n 7 Roof_Matl      nzv_RUieL\n 8 Bsmt_Cond      nzv_RUieL\n 9 BsmtFin_Type_2 nzv_RUieL\n10 BsmtFin_SF_2   nzv_RUieL\n# ℹ 11 more rows",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Zero Variance Filter</span>"
    ]
  },
  {
    "objectID": "too-many-zv.html#python-examples",
    "href": "too-many-zv.html#python-examples",
    "title": "66  Zero Variance Filter",
    "section": "66.4 Python Examples",
    "text": "66.4 Python Examples\nWe are using the ames data set for examples. {sklearn} provided the VarianceThreshold() method we can use. With this, we can set the threshold argument to specify the threshold of when to remove. The default 0 will remove zero-variance columns.\n\nfrom feazdata import ames\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.compose import make_column_selector\nimport numpy as np\n\nct = ColumnTransformer(\n    [('onehot', VarianceThreshold(threshold=0), make_column_selector(dtype_include=np.number))], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('onehot', VarianceThreshold(threshold=0),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x29764fe60&gt;)])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('onehot', VarianceThreshold(threshold=0),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x29764fe60&gt;)]) onehot&lt;sklearn.compose._column_transformer.make_column_selector object at 0x29764fe60&gt;  VarianceThreshold?Documentation for VarianceThresholdVarianceThreshold(threshold=0) remainder['MS_SubClass', 'MS_Zoning', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_Type_2', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'Functional', 'Garage_Type', 'Garage_Finish', 'Garage_Cond', 'Paved_Drive', 'Pool_QC', 'Fence', 'Misc_Feature', 'Sale_Type', 'Sale_Condition'] passthroughpassthrough \n\nct.transform(ames)\n\n      onehot__Lot_Frontage  ...  remainder__Sale_Condition\n0                      141  ...                     Normal\n1                       80  ...                     Normal\n2                       81  ...                     Normal\n3                       93  ...                     Normal\n4                       74  ...                     Normal\n...                    ...  ...                        ...\n2925                    37  ...                     Normal\n2926                     0  ...                     Normal\n2927                    62  ...                     Normal\n2928                    77  ...                     Normal\n2929                    74  ...                     Normal\n\n[2930 rows x 74 columns]\n\n\nbut we can change that threshold to remove near-zero variance columns.\n\nct = ColumnTransformer(\n    [('onehot', VarianceThreshold(threshold=0.2), make_column_selector(dtype_include=np.number))], \n    remainder=\"passthrough\")\n\nct.fit(ames)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('onehot', VarianceThreshold(threshold=0.2),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x297c17fe0&gt;)])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('onehot', VarianceThreshold(threshold=0.2),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x297c17fe0&gt;)]) onehot&lt;sklearn.compose._column_transformer.make_column_selector object at 0x297c17fe0&gt;  VarianceThreshold?Documentation for VarianceThresholdVarianceThreshold(threshold=0.2) remainder['MS_SubClass', 'MS_Zoning', 'Street', 'Alley', 'Lot_Shape', 'Land_Contour', 'Utilities', 'Lot_Config', 'Land_Slope', 'Neighborhood', 'Condition_1', 'Condition_2', 'Bldg_Type', 'House_Style', 'Overall_Cond', 'Roof_Style', 'Roof_Matl', 'Exterior_1st', 'Exterior_2nd', 'Mas_Vnr_Type', 'Exter_Cond', 'Foundation', 'Bsmt_Cond', 'Bsmt_Exposure', 'BsmtFin_Type_1', 'BsmtFin_Type_2', 'Heating', 'Heating_QC', 'Central_Air', 'Electrical', 'Functional', 'Garage_Type', 'Garage_Finish', 'Garage_Cond', 'Paved_Drive', 'Pool_QC', 'Fence', 'Misc_Feature', 'Sale_Type', 'Sale_Condition'] passthroughpassthrough \n\nct.transform(ames)\n\n      onehot__Lot_Frontage  ...  remainder__Sale_Condition\n0                      141  ...                     Normal\n1                       80  ...                     Normal\n2                       81  ...                     Normal\n3                       93  ...                     Normal\n4                       74  ...                     Normal\n...                    ...  ...                        ...\n2925                    37  ...                     Normal\n2926                     0  ...                     Normal\n2927                    62  ...                     Normal\n2928                    77  ...                     Normal\n2929                    74  ...                     Normal\n\n[2930 rows x 70 columns]",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>66</span>  <span class='chapter-title'>Zero Variance Filter</span>"
    ]
  },
  {
    "objectID": "too-many-pca.html",
    "href": "too-many-pca.html",
    "title": "67  🏗️ Principal Component Analysis",
    "section": "",
    "text": "67.1 Principal Component Analysis",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>🏗️ Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "too-many-pca.html#pros-and-cons",
    "href": "too-many-pca.html#pros-and-cons",
    "title": "67  🏗️ Principal Component Analysis",
    "section": "67.2 Pros and Cons",
    "text": "67.2 Pros and Cons\n\n67.2.1 Pros\n\n\n67.2.2 Cons",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>🏗️ Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "too-many-pca.html#r-examples",
    "href": "too-many-pca.html#r-examples",
    "title": "67  🏗️ Principal Component Analysis",
    "section": "67.3 R Examples",
    "text": "67.3 R Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>🏗️ Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "too-many-pca.html#python-examples",
    "href": "too-many-pca.html#python-examples",
    "title": "67  🏗️ Principal Component Analysis",
    "section": "67.4 Python Examples",
    "text": "67.4 Python Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>67</span>  <span class='chapter-title'>🏗️ Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "too-many-pca-variants.html",
    "href": "too-many-pca-variants.html",
    "title": "68  🏗️ Principal Component Analysis Variants",
    "section": "",
    "text": "68.1 Principal Component Analysis Variants",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>🏗️ Principal Component Analysis Variants</span>"
    ]
  },
  {
    "objectID": "too-many-pca-variants.html#pros-and-cons",
    "href": "too-many-pca-variants.html#pros-and-cons",
    "title": "68  🏗️ Principal Component Analysis Variants",
    "section": "68.2 Pros and Cons",
    "text": "68.2 Pros and Cons\n\n68.2.1 Pros\n\n\n68.2.2 Cons",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>🏗️ Principal Component Analysis Variants</span>"
    ]
  },
  {
    "objectID": "too-many-pca-variants.html#r-examples",
    "href": "too-many-pca-variants.html#r-examples",
    "title": "68  🏗️ Principal Component Analysis Variants",
    "section": "68.3 R Examples",
    "text": "68.3 R Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>🏗️ Principal Component Analysis Variants</span>"
    ]
  },
  {
    "objectID": "too-many-pca-variants.html#python-examples",
    "href": "too-many-pca-variants.html#python-examples",
    "title": "68  🏗️ Principal Component Analysis Variants",
    "section": "68.4 Python Examples",
    "text": "68.4 Python Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>68</span>  <span class='chapter-title'>🏗️ Principal Component Analysis Variants</span>"
    ]
  },
  {
    "objectID": "too-many-ica.html",
    "href": "too-many-ica.html",
    "title": "69  🏗️ Independent Component Analysis",
    "section": "",
    "text": "69.1 Independent Component Analysis",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>🏗️ Independent Component Analysis</span>"
    ]
  },
  {
    "objectID": "too-many-ica.html#pros-and-cons",
    "href": "too-many-ica.html#pros-and-cons",
    "title": "69  🏗️ Independent Component Analysis",
    "section": "69.2 Pros and Cons",
    "text": "69.2 Pros and Cons\n\n69.2.1 Pros\n\n\n69.2.2 Cons",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>🏗️ Independent Component Analysis</span>"
    ]
  },
  {
    "objectID": "too-many-ica.html#r-examples",
    "href": "too-many-ica.html#r-examples",
    "title": "69  🏗️ Independent Component Analysis",
    "section": "69.3 R Examples",
    "text": "69.3 R Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>🏗️ Independent Component Analysis</span>"
    ]
  },
  {
    "objectID": "too-many-ica.html#python-examples",
    "href": "too-many-ica.html#python-examples",
    "title": "69  🏗️ Independent Component Analysis",
    "section": "69.4 Python Examples",
    "text": "69.4 Python Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>69</span>  <span class='chapter-title'>🏗️ Independent Component Analysis</span>"
    ]
  },
  {
    "objectID": "too-many-nmf.html",
    "href": "too-many-nmf.html",
    "title": "70  🏗️ Non-Negative Matrix Factorization",
    "section": "",
    "text": "70.1 Non-Negative Matrix Factorization",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>🏗️ Non-Negative Matrix Factorization</span>"
    ]
  },
  {
    "objectID": "too-many-nmf.html#pros-and-cons",
    "href": "too-many-nmf.html#pros-and-cons",
    "title": "70  🏗️ Non-Negative Matrix Factorization",
    "section": "70.2 Pros and Cons",
    "text": "70.2 Pros and Cons\n\n70.2.1 Pros\n\n\n70.2.2 Cons",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>🏗️ Non-Negative Matrix Factorization</span>"
    ]
  },
  {
    "objectID": "too-many-nmf.html#r-examples",
    "href": "too-many-nmf.html#r-examples",
    "title": "70  🏗️ Non-Negative Matrix Factorization",
    "section": "70.3 R Examples",
    "text": "70.3 R Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>🏗️ Non-Negative Matrix Factorization</span>"
    ]
  },
  {
    "objectID": "too-many-nmf.html#python-examples",
    "href": "too-many-nmf.html#python-examples",
    "title": "70  🏗️ Non-Negative Matrix Factorization",
    "section": "70.4 Python Examples",
    "text": "70.4 Python Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>70</span>  <span class='chapter-title'>🏗️ Non-Negative Matrix Factorization</span>"
    ]
  },
  {
    "objectID": "too-many-lda.html",
    "href": "too-many-lda.html",
    "title": "71  🏗️ Linear Discriminant Analysis",
    "section": "",
    "text": "71.1 Linear Discriminant Analysis",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>🏗️ Linear Discriminant Analysis</span>"
    ]
  },
  {
    "objectID": "too-many-lda.html#pros-and-cons",
    "href": "too-many-lda.html#pros-and-cons",
    "title": "71  🏗️ Linear Discriminant Analysis",
    "section": "71.2 Pros and Cons",
    "text": "71.2 Pros and Cons\n\n71.2.1 Pros\n\n\n71.2.2 Cons",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>🏗️ Linear Discriminant Analysis</span>"
    ]
  },
  {
    "objectID": "too-many-lda.html#r-examples",
    "href": "too-many-lda.html#r-examples",
    "title": "71  🏗️ Linear Discriminant Analysis",
    "section": "71.3 R Examples",
    "text": "71.3 R Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>🏗️ Linear Discriminant Analysis</span>"
    ]
  },
  {
    "objectID": "too-many-lda.html#python-examples",
    "href": "too-many-lda.html#python-examples",
    "title": "71  🏗️ Linear Discriminant Analysis",
    "section": "71.4 Python Examples",
    "text": "71.4 Python Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>71</span>  <span class='chapter-title'>🏗️ Linear Discriminant Analysis</span>"
    ]
  },
  {
    "objectID": "too-many-gda.html",
    "href": "too-many-gda.html",
    "title": "72  🏗️ Generalized Discriminant Analysis",
    "section": "",
    "text": "72.1 Generalized Discriminant Analysis",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>🏗️ Generalized Discriminant Analysis</span>"
    ]
  },
  {
    "objectID": "too-many-gda.html#pros-and-cons",
    "href": "too-many-gda.html#pros-and-cons",
    "title": "72  🏗️ Generalized Discriminant Analysis",
    "section": "72.2 Pros and Cons",
    "text": "72.2 Pros and Cons\n\n72.2.1 Pros\n\n\n72.2.2 Cons",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>🏗️ Generalized Discriminant Analysis</span>"
    ]
  },
  {
    "objectID": "too-many-gda.html#r-examples",
    "href": "too-many-gda.html#r-examples",
    "title": "72  🏗️ Generalized Discriminant Analysis",
    "section": "72.3 R Examples",
    "text": "72.3 R Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>🏗️ Generalized Discriminant Analysis</span>"
    ]
  },
  {
    "objectID": "too-many-gda.html#python-examples",
    "href": "too-many-gda.html#python-examples",
    "title": "72  🏗️ Generalized Discriminant Analysis",
    "section": "72.4 Python Examples",
    "text": "72.4 Python Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>72</span>  <span class='chapter-title'>🏗️ Generalized Discriminant Analysis</span>"
    ]
  },
  {
    "objectID": "too-many-autoencoder.html",
    "href": "too-many-autoencoder.html",
    "title": "73  🏗️ Autoencoders",
    "section": "",
    "text": "73.1 Autoencoders",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>🏗️ Autoencoders</span>"
    ]
  },
  {
    "objectID": "too-many-autoencoder.html#pros-and-cons",
    "href": "too-many-autoencoder.html#pros-and-cons",
    "title": "73  🏗️ Autoencoders",
    "section": "73.2 Pros and Cons",
    "text": "73.2 Pros and Cons\n\n73.2.1 Pros\n\n\n73.2.2 Cons",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>🏗️ Autoencoders</span>"
    ]
  },
  {
    "objectID": "too-many-autoencoder.html#r-examples",
    "href": "too-many-autoencoder.html#r-examples",
    "title": "73  🏗️ Autoencoders",
    "section": "73.3 R Examples",
    "text": "73.3 R Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>🏗️ Autoencoders</span>"
    ]
  },
  {
    "objectID": "too-many-autoencoder.html#python-examples",
    "href": "too-many-autoencoder.html#python-examples",
    "title": "73  🏗️ Autoencoders",
    "section": "73.4 Python Examples",
    "text": "73.4 Python Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>73</span>  <span class='chapter-title'>🏗️ Autoencoders</span>"
    ]
  },
  {
    "objectID": "too-many-umap.html",
    "href": "too-many-umap.html",
    "title": "74  🏗️ Uniform Manifold Approximation and Projection",
    "section": "",
    "text": "74.1 UMAP",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>🏗️ Uniform Manifold Approximation and Projection</span>"
    ]
  },
  {
    "objectID": "too-many-umap.html#pros-and-cons",
    "href": "too-many-umap.html#pros-and-cons",
    "title": "74  🏗️ Uniform Manifold Approximation and Projection",
    "section": "74.2 Pros and Cons",
    "text": "74.2 Pros and Cons\n\n74.2.1 Pros\n\n\n74.2.2 Cons",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>🏗️ Uniform Manifold Approximation and Projection</span>"
    ]
  },
  {
    "objectID": "too-many-umap.html#r-examples",
    "href": "too-many-umap.html#r-examples",
    "title": "74  🏗️ Uniform Manifold Approximation and Projection",
    "section": "74.3 R Examples",
    "text": "74.3 R Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>🏗️ Uniform Manifold Approximation and Projection</span>"
    ]
  },
  {
    "objectID": "too-many-umap.html#python-examples",
    "href": "too-many-umap.html#python-examples",
    "title": "74  🏗️ Uniform Manifold Approximation and Projection",
    "section": "74.4 Python Examples",
    "text": "74.4 Python Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>74</span>  <span class='chapter-title'>🏗️ Uniform Manifold Approximation and Projection</span>"
    ]
  },
  {
    "objectID": "too-many-isomap.html",
    "href": "too-many-isomap.html",
    "title": "75  🏗️ ISOMAP",
    "section": "",
    "text": "75.1 ISOMAP",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>🏗️ ISOMAP</span>"
    ]
  },
  {
    "objectID": "too-many-isomap.html#pros-and-cons",
    "href": "too-many-isomap.html#pros-and-cons",
    "title": "75  🏗️ ISOMAP",
    "section": "75.2 Pros and Cons",
    "text": "75.2 Pros and Cons\n\n75.2.1 Pros\n\n\n75.2.2 Cons",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>🏗️ ISOMAP</span>"
    ]
  },
  {
    "objectID": "too-many-isomap.html#r-examples",
    "href": "too-many-isomap.html#r-examples",
    "title": "75  🏗️ ISOMAP",
    "section": "75.3 R Examples",
    "text": "75.3 R Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>🏗️ ISOMAP</span>"
    ]
  },
  {
    "objectID": "too-many-isomap.html#python-examples",
    "href": "too-many-isomap.html#python-examples",
    "title": "75  🏗️ ISOMAP",
    "section": "75.4 Python Examples",
    "text": "75.4 Python Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>75</span>  <span class='chapter-title'>🏗️ ISOMAP</span>"
    ]
  },
  {
    "objectID": "too-many-filter.html",
    "href": "too-many-filter.html",
    "title": "76  🏗️ Filter based feature selection",
    "section": "",
    "text": "76.1 Filter based feature selection",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>🏗️ Filter based feature selection</span>"
    ]
  },
  {
    "objectID": "too-many-filter.html#pros-and-cons",
    "href": "too-many-filter.html#pros-and-cons",
    "title": "76  🏗️ Filter based feature selection",
    "section": "76.2 Pros and Cons",
    "text": "76.2 Pros and Cons\n\n76.2.1 Pros\n\n\n76.2.2 Cons",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>🏗️ Filter based feature selection</span>"
    ]
  },
  {
    "objectID": "too-many-filter.html#r-examples",
    "href": "too-many-filter.html#r-examples",
    "title": "76  🏗️ Filter based feature selection",
    "section": "76.3 R Examples",
    "text": "76.3 R Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>🏗️ Filter based feature selection</span>"
    ]
  },
  {
    "objectID": "too-many-filter.html#python-examples",
    "href": "too-many-filter.html#python-examples",
    "title": "76  🏗️ Filter based feature selection",
    "section": "76.4 Python Examples",
    "text": "76.4 Python Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>76</span>  <span class='chapter-title'>🏗️ Filter based feature selection</span>"
    ]
  },
  {
    "objectID": "too-many-wrapper.html",
    "href": "too-many-wrapper.html",
    "title": "77  🏗️ Wrapper based feature selection",
    "section": "",
    "text": "77.1 Wrapper Based feature selection",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>🏗️ Wrapper based feature selection</span>"
    ]
  },
  {
    "objectID": "too-many-wrapper.html#pros-and-cons",
    "href": "too-many-wrapper.html#pros-and-cons",
    "title": "77  🏗️ Wrapper based feature selection",
    "section": "77.2 Pros and Cons",
    "text": "77.2 Pros and Cons\n\n77.2.1 Pros\n\n\n77.2.2 Cons",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>🏗️ Wrapper based feature selection</span>"
    ]
  },
  {
    "objectID": "too-many-wrapper.html#r-examples",
    "href": "too-many-wrapper.html#r-examples",
    "title": "77  🏗️ Wrapper based feature selection",
    "section": "77.3 R Examples",
    "text": "77.3 R Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>🏗️ Wrapper based feature selection</span>"
    ]
  },
  {
    "objectID": "too-many-wrapper.html#python-examples",
    "href": "too-many-wrapper.html#python-examples",
    "title": "77  🏗️ Wrapper based feature selection",
    "section": "77.4 Python Examples",
    "text": "77.4 Python Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>77</span>  <span class='chapter-title'>🏗️ Wrapper based feature selection</span>"
    ]
  },
  {
    "objectID": "too-many-embedded.html",
    "href": "too-many-embedded.html",
    "title": "78  🏗️ Embedded based feature selection",
    "section": "",
    "text": "78.1 Embedded based feature selection",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>🏗️ Embedded based feature selection</span>"
    ]
  },
  {
    "objectID": "too-many-embedded.html#pros-and-cons",
    "href": "too-many-embedded.html#pros-and-cons",
    "title": "78  🏗️ Embedded based feature selection",
    "section": "78.2 Pros and Cons",
    "text": "78.2 Pros and Cons\n\n78.2.1 Pros\n\n\n78.2.2 Cons",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>🏗️ Embedded based feature selection</span>"
    ]
  },
  {
    "objectID": "too-many-embedded.html#r-examples",
    "href": "too-many-embedded.html#r-examples",
    "title": "78  🏗️ Embedded based feature selection",
    "section": "78.3 R Examples",
    "text": "78.3 R Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>🏗️ Embedded based feature selection</span>"
    ]
  },
  {
    "objectID": "too-many-embedded.html#python-examples",
    "href": "too-many-embedded.html#python-examples",
    "title": "78  🏗️ Embedded based feature selection",
    "section": "78.4 Python Examples",
    "text": "78.4 Python Examples",
    "crumbs": [
      "Too Many Variables",
      "<span class='chapter-number'>78</span>  <span class='chapter-title'>🏗️ Embedded based feature selection</span>"
    ]
  },
  {
    "objectID": "correlated.html",
    "href": "correlated.html",
    "title": "79  Correlated Overview",
    "section": "",
    "text": "79.1 Correlated Overview",
    "crumbs": [
      "Correlated Data",
      "<span class='chapter-number'>79</span>  <span class='chapter-title'>Correlated Overview</span>"
    ]
  },
  {
    "objectID": "correlated-filter.html",
    "href": "correlated-filter.html",
    "title": "80  High Correlation Filter",
    "section": "",
    "text": "80.1 High Correlation Filter",
    "crumbs": [
      "Correlated Data",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>High Correlation Filter</span>"
    ]
  },
  {
    "objectID": "correlated-filter.html#pros-and-cons",
    "href": "correlated-filter.html#pros-and-cons",
    "title": "80  High Correlation Filter",
    "section": "80.2 Pros and Cons",
    "text": "80.2 Pros and Cons\n\n80.2.1 Pros\n\nComputationally simple and fast\nEasily explainable. “Predictors were removed”\nWill lead to a faster and simpler model\n\n\n\n80.2.2 Cons\n\nCan be hard to justify. “Why was this predictor kept instead of this one?”\nWill lead to loss of signal and performance, with the hope that this loss is kept minimal",
    "crumbs": [
      "Correlated Data",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>High Correlation Filter</span>"
    ]
  },
  {
    "objectID": "correlated-filter.html#r-examples",
    "href": "correlated-filter.html#r-examples",
    "title": "80  High Correlation Filter",
    "section": "80.3 R Examples",
    "text": "80.3 R Examples\nWe will use the ames data set from {modeldata} in this example. The {recipes} step step_corrr() performs the simple correlation filter described at the beginning of this chapter.\n\nlibrary(recipes)\nlibrary(modeldata)\n\ncorr_rec &lt;- recipe(Sale_Price ~ ., data = ames) |&gt;\n  step_corr(all_numeric_predictors(), threshold = 0.75) |&gt;\n  prep()\n\nWe can see the variables that were removed with the tidy() method\n\ncorr_rec |&gt;\n  tidy(1)\n\n# A tibble: 3 × 2\n  terms        id        \n  &lt;chr&gt;        &lt;chr&gt;     \n1 First_Flr_SF corr_Bp5vK\n2 Gr_Liv_Area  corr_Bp5vK\n3 Garage_Cars  corr_Bp5vK\n\n\nWe can see that when we lower this threshold to the extreme, more predictors are removed.\n\nrecipe(Sale_Price ~ ., data = ames) |&gt;\n  step_corr(all_numeric_predictors(), threshold = 0.25) |&gt;\n  prep() |&gt;\n  tidy(1)\n\n# A tibble: 13 × 2\n   terms          id        \n   &lt;chr&gt;          &lt;chr&gt;     \n 1 Bsmt_Unf_SF    corr_RUieL\n 2 Total_Bsmt_SF  corr_RUieL\n 3 First_Flr_SF   corr_RUieL\n 4 Gr_Liv_Area    corr_RUieL\n 5 Bsmt_Full_Bath corr_RUieL\n 6 Full_Bath      corr_RUieL\n 7 TotRms_AbvGrd  corr_RUieL\n 8 Fireplaces     corr_RUieL\n 9 Garage_Cars    corr_RUieL\n10 Garage_Area    corr_RUieL\n11 Year_Built     corr_RUieL\n12 Second_Flr_SF  corr_RUieL\n13 Year_Remod_Add corr_RUieL",
    "crumbs": [
      "Correlated Data",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>High Correlation Filter</span>"
    ]
  },
  {
    "objectID": "correlated-filter.html#python-examples",
    "href": "correlated-filter.html#python-examples",
    "title": "80  High Correlation Filter",
    "section": "80.4 Python Examples",
    "text": "80.4 Python Examples\nI’m not aware of a good way to do this in a scikit-learn way. Please file an issue on github if you know of a good way.",
    "crumbs": [
      "Correlated Data",
      "<span class='chapter-number'>80</span>  <span class='chapter-title'>High Correlation Filter</span>"
    ]
  },
  {
    "objectID": "outliers.html",
    "href": "outliers.html",
    "title": "81  Outliers Overview",
    "section": "",
    "text": "81.1 Outliers Overview",
    "crumbs": [
      "Outliers",
      "<span class='chapter-number'>81</span>  <span class='chapter-title'>Outliers Overview</span>"
    ]
  },
  {
    "objectID": "outliers-remove.html",
    "href": "outliers-remove.html",
    "title": "82  🏗️ Removal",
    "section": "",
    "text": "82.1 Removal",
    "crumbs": [
      "Outliers",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>🏗️ Removal</span>"
    ]
  },
  {
    "objectID": "outliers-remove.html#pros-and-cons",
    "href": "outliers-remove.html#pros-and-cons",
    "title": "82  🏗️ Removal",
    "section": "82.2 Pros and Cons",
    "text": "82.2 Pros and Cons\n\n82.2.1 Pros\n\n\n82.2.2 Cons",
    "crumbs": [
      "Outliers",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>🏗️ Removal</span>"
    ]
  },
  {
    "objectID": "outliers-remove.html#r-examples",
    "href": "outliers-remove.html#r-examples",
    "title": "82  🏗️ Removal",
    "section": "82.3 R Examples",
    "text": "82.3 R Examples",
    "crumbs": [
      "Outliers",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>🏗️ Removal</span>"
    ]
  },
  {
    "objectID": "outliers-remove.html#python-examples",
    "href": "outliers-remove.html#python-examples",
    "title": "82  🏗️ Removal",
    "section": "82.4 Python Examples",
    "text": "82.4 Python Examples",
    "crumbs": [
      "Outliers",
      "<span class='chapter-number'>82</span>  <span class='chapter-title'>🏗️ Removal</span>"
    ]
  },
  {
    "objectID": "outliers-imputation.html",
    "href": "outliers-imputation.html",
    "title": "83  🏗️ Imputation",
    "section": "",
    "text": "83.1 Imputation",
    "crumbs": [
      "Outliers",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>🏗️ Imputation</span>"
    ]
  },
  {
    "objectID": "outliers-imputation.html#pros-and-cons",
    "href": "outliers-imputation.html#pros-and-cons",
    "title": "83  🏗️ Imputation",
    "section": "83.2 Pros and Cons",
    "text": "83.2 Pros and Cons\n\n83.2.1 Pros\n\n\n83.2.2 Cons",
    "crumbs": [
      "Outliers",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>🏗️ Imputation</span>"
    ]
  },
  {
    "objectID": "outliers-imputation.html#r-examples",
    "href": "outliers-imputation.html#r-examples",
    "title": "83  🏗️ Imputation",
    "section": "83.3 R Examples",
    "text": "83.3 R Examples",
    "crumbs": [
      "Outliers",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>🏗️ Imputation</span>"
    ]
  },
  {
    "objectID": "outliers-imputation.html#python-examples",
    "href": "outliers-imputation.html#python-examples",
    "title": "83  🏗️ Imputation",
    "section": "83.4 Python Examples",
    "text": "83.4 Python Examples",
    "crumbs": [
      "Outliers",
      "<span class='chapter-number'>83</span>  <span class='chapter-title'>🏗️ Imputation</span>"
    ]
  },
  {
    "objectID": "outliers-indicate.html",
    "href": "outliers-indicate.html",
    "title": "84  🏗️ Indicate",
    "section": "",
    "text": "84.1 Indicate",
    "crumbs": [
      "Outliers",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>🏗️ Indicate</span>"
    ]
  },
  {
    "objectID": "outliers-indicate.html#pros-and-cons",
    "href": "outliers-indicate.html#pros-and-cons",
    "title": "84  🏗️ Indicate",
    "section": "84.2 Pros and Cons",
    "text": "84.2 Pros and Cons\n\n84.2.1 Pros\n\n\n84.2.2 Cons",
    "crumbs": [
      "Outliers",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>🏗️ Indicate</span>"
    ]
  },
  {
    "objectID": "outliers-indicate.html#r-examples",
    "href": "outliers-indicate.html#r-examples",
    "title": "84  🏗️ Indicate",
    "section": "84.3 R Examples",
    "text": "84.3 R Examples",
    "crumbs": [
      "Outliers",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>🏗️ Indicate</span>"
    ]
  },
  {
    "objectID": "outliers-indicate.html#python-examples",
    "href": "outliers-indicate.html#python-examples",
    "title": "84  🏗️ Indicate",
    "section": "84.4 Python Examples",
    "text": "84.4 Python Examples",
    "crumbs": [
      "Outliers",
      "<span class='chapter-number'>84</span>  <span class='chapter-title'>🏗️ Indicate</span>"
    ]
  },
  {
    "objectID": "imbalenced.html",
    "href": "imbalenced.html",
    "title": "85  Imbalanced Overview",
    "section": "",
    "text": "85.1 Imbalanced Overview",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>85</span>  <span class='chapter-title'>Imbalanced Overview</span>"
    ]
  },
  {
    "objectID": "imbalenced-upsample.html",
    "href": "imbalenced-upsample.html",
    "title": "86  🏗️ Up-Sampling",
    "section": "",
    "text": "86.1 Up-Sampling",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>🏗️ Up-Sampling</span>"
    ]
  },
  {
    "objectID": "imbalenced-upsample.html#pros-and-cons",
    "href": "imbalenced-upsample.html#pros-and-cons",
    "title": "86  🏗️ Up-Sampling",
    "section": "86.2 Pros and Cons",
    "text": "86.2 Pros and Cons\n\n86.2.1 Pros\n\n\n86.2.2 Cons",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>🏗️ Up-Sampling</span>"
    ]
  },
  {
    "objectID": "imbalenced-upsample.html#r-examples",
    "href": "imbalenced-upsample.html#r-examples",
    "title": "86  🏗️ Up-Sampling",
    "section": "86.3 R Examples",
    "text": "86.3 R Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>🏗️ Up-Sampling</span>"
    ]
  },
  {
    "objectID": "imbalenced-upsample.html#python-examples",
    "href": "imbalenced-upsample.html#python-examples",
    "title": "86  🏗️ Up-Sampling",
    "section": "86.4 Python Examples",
    "text": "86.4 Python Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>86</span>  <span class='chapter-title'>🏗️ Up-Sampling</span>"
    ]
  },
  {
    "objectID": "imbalenced-rose.html",
    "href": "imbalenced-rose.html",
    "title": "87  🏗️ ROSE",
    "section": "",
    "text": "87.1 ROSE",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>🏗️ ROSE</span>"
    ]
  },
  {
    "objectID": "imbalenced-rose.html#pros-and-cons",
    "href": "imbalenced-rose.html#pros-and-cons",
    "title": "87  🏗️ ROSE",
    "section": "87.2 Pros and Cons",
    "text": "87.2 Pros and Cons\n\n87.2.1 Pros\n\n\n87.2.2 Cons",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>🏗️ ROSE</span>"
    ]
  },
  {
    "objectID": "imbalenced-rose.html#r-examples",
    "href": "imbalenced-rose.html#r-examples",
    "title": "87  🏗️ ROSE",
    "section": "87.3 R Examples",
    "text": "87.3 R Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>🏗️ ROSE</span>"
    ]
  },
  {
    "objectID": "imbalenced-rose.html#python-examples",
    "href": "imbalenced-rose.html#python-examples",
    "title": "87  🏗️ ROSE",
    "section": "87.4 Python Examples",
    "text": "87.4 Python Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>87</span>  <span class='chapter-title'>🏗️ ROSE</span>"
    ]
  },
  {
    "objectID": "imbalenced-smote.html",
    "href": "imbalenced-smote.html",
    "title": "88  🏗️ SMOTE",
    "section": "",
    "text": "88.1 SMOTE",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>🏗️ SMOTE</span>"
    ]
  },
  {
    "objectID": "imbalenced-smote.html#pros-and-cons",
    "href": "imbalenced-smote.html#pros-and-cons",
    "title": "88  🏗️ SMOTE",
    "section": "88.2 Pros and Cons",
    "text": "88.2 Pros and Cons\n\n88.2.1 Pros\n\n\n88.2.2 Cons",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>🏗️ SMOTE</span>"
    ]
  },
  {
    "objectID": "imbalenced-smote.html#r-examples",
    "href": "imbalenced-smote.html#r-examples",
    "title": "88  🏗️ SMOTE",
    "section": "88.3 R Examples",
    "text": "88.3 R Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>🏗️ SMOTE</span>"
    ]
  },
  {
    "objectID": "imbalenced-smote.html#python-examples",
    "href": "imbalenced-smote.html#python-examples",
    "title": "88  🏗️ SMOTE",
    "section": "88.4 Python Examples",
    "text": "88.4 Python Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>88</span>  <span class='chapter-title'>🏗️ SMOTE</span>"
    ]
  },
  {
    "objectID": "imbalenced-smote-variants.html",
    "href": "imbalenced-smote-variants.html",
    "title": "89  🏗️ SMOTE Variants",
    "section": "",
    "text": "89.1 SMOTE Variants",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>🏗️ SMOTE Variants</span>"
    ]
  },
  {
    "objectID": "imbalenced-smote-variants.html#pros-and-cons",
    "href": "imbalenced-smote-variants.html#pros-and-cons",
    "title": "89  🏗️ SMOTE Variants",
    "section": "89.2 Pros and Cons",
    "text": "89.2 Pros and Cons\n\n89.2.1 Pros\n\n\n89.2.2 Cons",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>🏗️ SMOTE Variants</span>"
    ]
  },
  {
    "objectID": "imbalenced-smote-variants.html#r-examples",
    "href": "imbalenced-smote-variants.html#r-examples",
    "title": "89  🏗️ SMOTE Variants",
    "section": "89.3 R Examples",
    "text": "89.3 R Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>🏗️ SMOTE Variants</span>"
    ]
  },
  {
    "objectID": "imbalenced-smote-variants.html#python-examples",
    "href": "imbalenced-smote-variants.html#python-examples",
    "title": "89  🏗️ SMOTE Variants",
    "section": "89.4 Python Examples",
    "text": "89.4 Python Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>89</span>  <span class='chapter-title'>🏗️ SMOTE Variants</span>"
    ]
  },
  {
    "objectID": "imbalenced-borderline-smote.html",
    "href": "imbalenced-borderline-smote.html",
    "title": "90  🏗️ Borderline SMOTE",
    "section": "",
    "text": "90.1 Borderline SMOTE",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>🏗️ Borderline SMOTE</span>"
    ]
  },
  {
    "objectID": "imbalenced-borderline-smote.html#pros-and-cons",
    "href": "imbalenced-borderline-smote.html#pros-and-cons",
    "title": "90  🏗️ Borderline SMOTE",
    "section": "90.2 Pros and Cons",
    "text": "90.2 Pros and Cons\n\n90.2.1 Pros\n\n\n90.2.2 Cons",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>🏗️ Borderline SMOTE</span>"
    ]
  },
  {
    "objectID": "imbalenced-borderline-smote.html#r-examples",
    "href": "imbalenced-borderline-smote.html#r-examples",
    "title": "90  🏗️ Borderline SMOTE",
    "section": "90.3 R Examples",
    "text": "90.3 R Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>🏗️ Borderline SMOTE</span>"
    ]
  },
  {
    "objectID": "imbalenced-borderline-smote.html#python-examples",
    "href": "imbalenced-borderline-smote.html#python-examples",
    "title": "90  🏗️ Borderline SMOTE",
    "section": "90.4 Python Examples",
    "text": "90.4 Python Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>90</span>  <span class='chapter-title'>🏗️ Borderline SMOTE</span>"
    ]
  },
  {
    "objectID": "imbalenced-adasyn.html",
    "href": "imbalenced-adasyn.html",
    "title": "91  🏗️ Adaptive Synthetic Algorithm",
    "section": "",
    "text": "91.1 Adaptive Synthetic Algorithm",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>🏗️ Adaptive Synthetic Algorithm</span>"
    ]
  },
  {
    "objectID": "imbalenced-adasyn.html#pros-and-cons",
    "href": "imbalenced-adasyn.html#pros-and-cons",
    "title": "91  🏗️ Adaptive Synthetic Algorithm",
    "section": "91.2 Pros and Cons",
    "text": "91.2 Pros and Cons\n\n91.2.1 Pros\n\n\n91.2.2 Cons",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>🏗️ Adaptive Synthetic Algorithm</span>"
    ]
  },
  {
    "objectID": "imbalenced-adasyn.html#r-examples",
    "href": "imbalenced-adasyn.html#r-examples",
    "title": "91  🏗️ Adaptive Synthetic Algorithm",
    "section": "91.3 R Examples",
    "text": "91.3 R Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>🏗️ Adaptive Synthetic Algorithm</span>"
    ]
  },
  {
    "objectID": "imbalenced-adasyn.html#python-examples",
    "href": "imbalenced-adasyn.html#python-examples",
    "title": "91  🏗️ Adaptive Synthetic Algorithm",
    "section": "91.4 Python Examples",
    "text": "91.4 Python Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>91</span>  <span class='chapter-title'>🏗️ Adaptive Synthetic Algorithm</span>"
    ]
  },
  {
    "objectID": "imbalenced-downsample.html",
    "href": "imbalenced-downsample.html",
    "title": "92  🏗️ Down-Sampling",
    "section": "",
    "text": "92.1 Down-Sampling",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>🏗️ Down-Sampling</span>"
    ]
  },
  {
    "objectID": "imbalenced-downsample.html#pros-and-cons",
    "href": "imbalenced-downsample.html#pros-and-cons",
    "title": "92  🏗️ Down-Sampling",
    "section": "92.2 Pros and Cons",
    "text": "92.2 Pros and Cons\n\n92.2.1 Pros\n\n\n92.2.2 Cons",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>🏗️ Down-Sampling</span>"
    ]
  },
  {
    "objectID": "imbalenced-downsample.html#r-examples",
    "href": "imbalenced-downsample.html#r-examples",
    "title": "92  🏗️ Down-Sampling",
    "section": "92.3 R Examples",
    "text": "92.3 R Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>🏗️ Down-Sampling</span>"
    ]
  },
  {
    "objectID": "imbalenced-downsample.html#python-examples",
    "href": "imbalenced-downsample.html#python-examples",
    "title": "92  🏗️ Down-Sampling",
    "section": "92.4 Python Examples",
    "text": "92.4 Python Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>92</span>  <span class='chapter-title'>🏗️ Down-Sampling</span>"
    ]
  },
  {
    "objectID": "imbalenced-nearmiss.html",
    "href": "imbalenced-nearmiss.html",
    "title": "93  🏗️ Near-Miss",
    "section": "",
    "text": "93.1 Near-Miss",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>93</span>  <span class='chapter-title'>🏗️ Near-Miss</span>"
    ]
  },
  {
    "objectID": "imbalenced-nearmiss.html#pros-and-cons",
    "href": "imbalenced-nearmiss.html#pros-and-cons",
    "title": "93  🏗️ Near-Miss",
    "section": "93.2 Pros and Cons",
    "text": "93.2 Pros and Cons\n\n93.2.1 Pros\n\n\n93.2.2 Cons",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>93</span>  <span class='chapter-title'>🏗️ Near-Miss</span>"
    ]
  },
  {
    "objectID": "imbalenced-nearmiss.html#r-examples",
    "href": "imbalenced-nearmiss.html#r-examples",
    "title": "93  🏗️ Near-Miss",
    "section": "93.3 R Examples",
    "text": "93.3 R Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>93</span>  <span class='chapter-title'>🏗️ Near-Miss</span>"
    ]
  },
  {
    "objectID": "imbalenced-nearmiss.html#python-examples",
    "href": "imbalenced-nearmiss.html#python-examples",
    "title": "93  🏗️ Near-Miss",
    "section": "93.4 Python Examples",
    "text": "93.4 Python Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>93</span>  <span class='chapter-title'>🏗️ Near-Miss</span>"
    ]
  },
  {
    "objectID": "imbalenced-tomek.html",
    "href": "imbalenced-tomek.html",
    "title": "94  🏗️ Tomek Links",
    "section": "",
    "text": "94.1 Tomek Links",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>🏗️ Tomek Links</span>"
    ]
  },
  {
    "objectID": "imbalenced-tomek.html#pros-and-cons",
    "href": "imbalenced-tomek.html#pros-and-cons",
    "title": "94  🏗️ Tomek Links",
    "section": "94.2 Pros and Cons",
    "text": "94.2 Pros and Cons\n\n94.2.1 Pros\n\n\n94.2.2 Cons",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>🏗️ Tomek Links</span>"
    ]
  },
  {
    "objectID": "imbalenced-tomek.html#r-examples",
    "href": "imbalenced-tomek.html#r-examples",
    "title": "94  🏗️ Tomek Links",
    "section": "94.3 R Examples",
    "text": "94.3 R Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>🏗️ Tomek Links</span>"
    ]
  },
  {
    "objectID": "imbalenced-tomek.html#python-examples",
    "href": "imbalenced-tomek.html#python-examples",
    "title": "94  🏗️ Tomek Links",
    "section": "94.4 Python Examples",
    "text": "94.4 Python Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>94</span>  <span class='chapter-title'>🏗️ Tomek Links</span>"
    ]
  },
  {
    "objectID": "imbalenced-cnn.html",
    "href": "imbalenced-cnn.html",
    "title": "95  🏗️ Condensed Nearest Neighbor",
    "section": "",
    "text": "95.1 Condensed Nearest Neighbor",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>95</span>  <span class='chapter-title'>🏗️ Condensed Nearest Neighbor</span>"
    ]
  },
  {
    "objectID": "imbalenced-cnn.html#pros-and-cons",
    "href": "imbalenced-cnn.html#pros-and-cons",
    "title": "95  🏗️ Condensed Nearest Neighbor",
    "section": "95.2 Pros and Cons",
    "text": "95.2 Pros and Cons\n\n95.2.1 Pros\n\n\n95.2.2 Cons",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>95</span>  <span class='chapter-title'>🏗️ Condensed Nearest Neighbor</span>"
    ]
  },
  {
    "objectID": "imbalenced-cnn.html#r-examples",
    "href": "imbalenced-cnn.html#r-examples",
    "title": "95  🏗️ Condensed Nearest Neighbor",
    "section": "95.3 R Examples",
    "text": "95.3 R Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>95</span>  <span class='chapter-title'>🏗️ Condensed Nearest Neighbor</span>"
    ]
  },
  {
    "objectID": "imbalenced-cnn.html#python-examples",
    "href": "imbalenced-cnn.html#python-examples",
    "title": "95  🏗️ Condensed Nearest Neighbor",
    "section": "95.4 Python Examples",
    "text": "95.4 Python Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>95</span>  <span class='chapter-title'>🏗️ Condensed Nearest Neighbor</span>"
    ]
  },
  {
    "objectID": "imbalenced-enn.html",
    "href": "imbalenced-enn.html",
    "title": "96  🏗️ Edited Nearest Neighbor",
    "section": "",
    "text": "96.1 Edited Nearest Neighbor",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>🏗️ Edited Nearest Neighbor</span>"
    ]
  },
  {
    "objectID": "imbalenced-enn.html#pros-and-cons",
    "href": "imbalenced-enn.html#pros-and-cons",
    "title": "96  🏗️ Edited Nearest Neighbor",
    "section": "96.2 Pros and Cons",
    "text": "96.2 Pros and Cons\n\n96.2.1 Pros\n\n\n96.2.2 Cons",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>🏗️ Edited Nearest Neighbor</span>"
    ]
  },
  {
    "objectID": "imbalenced-enn.html#r-examples",
    "href": "imbalenced-enn.html#r-examples",
    "title": "96  🏗️ Edited Nearest Neighbor",
    "section": "96.3 R Examples",
    "text": "96.3 R Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>🏗️ Edited Nearest Neighbor</span>"
    ]
  },
  {
    "objectID": "imbalenced-enn.html#python-examples",
    "href": "imbalenced-enn.html#python-examples",
    "title": "96  🏗️ Edited Nearest Neighbor",
    "section": "96.4 Python Examples",
    "text": "96.4 Python Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>96</span>  <span class='chapter-title'>🏗️ Edited Nearest Neighbor</span>"
    ]
  },
  {
    "objectID": "imbalenced-hardness-threshold.html",
    "href": "imbalenced-hardness-threshold.html",
    "title": "97  🏗️ Instance Hardness Threshold",
    "section": "",
    "text": "97.1 Instance Hardness Threshold",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>🏗️ Instance Hardness Threshold</span>"
    ]
  },
  {
    "objectID": "imbalenced-hardness-threshold.html#pros-and-cons",
    "href": "imbalenced-hardness-threshold.html#pros-and-cons",
    "title": "97  🏗️ Instance Hardness Threshold",
    "section": "97.2 Pros and Cons",
    "text": "97.2 Pros and Cons\n\n97.2.1 Pros\n\n\n97.2.2 Cons",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>🏗️ Instance Hardness Threshold</span>"
    ]
  },
  {
    "objectID": "imbalenced-hardness-threshold.html#r-examples",
    "href": "imbalenced-hardness-threshold.html#r-examples",
    "title": "97  🏗️ Instance Hardness Threshold",
    "section": "97.3 R Examples",
    "text": "97.3 R Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>🏗️ Instance Hardness Threshold</span>"
    ]
  },
  {
    "objectID": "imbalenced-hardness-threshold.html#python-examples",
    "href": "imbalenced-hardness-threshold.html#python-examples",
    "title": "97  🏗️ Instance Hardness Threshold",
    "section": "97.4 Python Examples",
    "text": "97.4 Python Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>97</span>  <span class='chapter-title'>🏗️ Instance Hardness Threshold</span>"
    ]
  },
  {
    "objectID": "imbalenced-one-sided.html",
    "href": "imbalenced-one-sided.html",
    "title": "98  🏗️ One Sided Selection",
    "section": "",
    "text": "98.1 One Sided Selection",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>98</span>  <span class='chapter-title'>🏗️ One Sided Selection</span>"
    ]
  },
  {
    "objectID": "imbalenced-one-sided.html#pros-and-cons",
    "href": "imbalenced-one-sided.html#pros-and-cons",
    "title": "98  🏗️ One Sided Selection",
    "section": "98.2 Pros and Cons",
    "text": "98.2 Pros and Cons\n\n98.2.1 Pros\n\n\n98.2.2 Cons",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>98</span>  <span class='chapter-title'>🏗️ One Sided Selection</span>"
    ]
  },
  {
    "objectID": "imbalenced-one-sided.html#r-examples",
    "href": "imbalenced-one-sided.html#r-examples",
    "title": "98  🏗️ One Sided Selection",
    "section": "98.3 R Examples",
    "text": "98.3 R Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>98</span>  <span class='chapter-title'>🏗️ One Sided Selection</span>"
    ]
  },
  {
    "objectID": "imbalenced-one-sided.html#python-examples",
    "href": "imbalenced-one-sided.html#python-examples",
    "title": "98  🏗️ One Sided Selection",
    "section": "98.4 Python Examples",
    "text": "98.4 Python Examples",
    "crumbs": [
      "Imbalanced Data",
      "<span class='chapter-number'>98</span>  <span class='chapter-title'>🏗️ One Sided Selection</span>"
    ]
  },
  {
    "objectID": "miscellaneous.html",
    "href": "miscellaneous.html",
    "title": "99  Miscellaneous Overview",
    "section": "",
    "text": "99.1 Miscellaneous Overview",
    "crumbs": [
      "Miscellaneous",
      "<span class='chapter-number'>99</span>  <span class='chapter-title'>Miscellaneous Overview</span>"
    ]
  },
  {
    "objectID": "miscellaneous-id.html",
    "href": "miscellaneous-id.html",
    "title": "100  🏗️ IDs",
    "section": "",
    "text": "100.1 IDs",
    "crumbs": [
      "Miscellaneous",
      "<span class='chapter-number'>100</span>  <span class='chapter-title'>🏗️ IDs</span>"
    ]
  },
  {
    "objectID": "miscellaneous-id.html#pros-and-cons",
    "href": "miscellaneous-id.html#pros-and-cons",
    "title": "100  🏗️ IDs",
    "section": "100.2 Pros and Cons",
    "text": "100.2 Pros and Cons\n\n100.2.1 Pros\n\n\n100.2.2 Cons",
    "crumbs": [
      "Miscellaneous",
      "<span class='chapter-number'>100</span>  <span class='chapter-title'>🏗️ IDs</span>"
    ]
  },
  {
    "objectID": "miscellaneous-id.html#r-examples",
    "href": "miscellaneous-id.html#r-examples",
    "title": "100  🏗️ IDs",
    "section": "100.3 R Examples",
    "text": "100.3 R Examples",
    "crumbs": [
      "Miscellaneous",
      "<span class='chapter-number'>100</span>  <span class='chapter-title'>🏗️ IDs</span>"
    ]
  },
  {
    "objectID": "miscellaneous-id.html#python-examples",
    "href": "miscellaneous-id.html#python-examples",
    "title": "100  🏗️ IDs",
    "section": "100.4 Python Examples",
    "text": "100.4 Python Examples",
    "crumbs": [
      "Miscellaneous",
      "<span class='chapter-number'>100</span>  <span class='chapter-title'>🏗️ IDs</span>"
    ]
  },
  {
    "objectID": "miscellaneous-color.html",
    "href": "miscellaneous-color.html",
    "title": "101  🏗️ Colors",
    "section": "",
    "text": "101.1 Colors",
    "crumbs": [
      "Miscellaneous",
      "<span class='chapter-number'>101</span>  <span class='chapter-title'>🏗️ Colors</span>"
    ]
  },
  {
    "objectID": "miscellaneous-color.html#pros-and-cons",
    "href": "miscellaneous-color.html#pros-and-cons",
    "title": "101  🏗️ Colors",
    "section": "101.2 Pros and Cons",
    "text": "101.2 Pros and Cons\n\n101.2.1 Pros\n\n\n101.2.2 Cons",
    "crumbs": [
      "Miscellaneous",
      "<span class='chapter-number'>101</span>  <span class='chapter-title'>🏗️ Colors</span>"
    ]
  },
  {
    "objectID": "miscellaneous-color.html#r-examples",
    "href": "miscellaneous-color.html#r-examples",
    "title": "101  🏗️ Colors",
    "section": "101.3 R Examples",
    "text": "101.3 R Examples",
    "crumbs": [
      "Miscellaneous",
      "<span class='chapter-number'>101</span>  <span class='chapter-title'>🏗️ Colors</span>"
    ]
  },
  {
    "objectID": "miscellaneous-color.html#python-examples",
    "href": "miscellaneous-color.html#python-examples",
    "title": "101  🏗️ Colors",
    "section": "101.4 Python Examples",
    "text": "101.4 Python Examples",
    "crumbs": [
      "Miscellaneous",
      "<span class='chapter-number'>101</span>  <span class='chapter-title'>🏗️ Colors</span>"
    ]
  },
  {
    "objectID": "miscellaneous-zipcodes.html",
    "href": "miscellaneous-zipcodes.html",
    "title": "102  🏗️ Zip Codes",
    "section": "",
    "text": "102.1 Zip Codes",
    "crumbs": [
      "Miscellaneous",
      "<span class='chapter-number'>102</span>  <span class='chapter-title'>🏗️ Zip Codes</span>"
    ]
  },
  {
    "objectID": "miscellaneous-zipcodes.html#pros-and-cons",
    "href": "miscellaneous-zipcodes.html#pros-and-cons",
    "title": "102  🏗️ Zip Codes",
    "section": "102.2 Pros and Cons",
    "text": "102.2 Pros and Cons\n\n102.2.1 Pros\n\n\n102.2.2 Cons",
    "crumbs": [
      "Miscellaneous",
      "<span class='chapter-number'>102</span>  <span class='chapter-title'>🏗️ Zip Codes</span>"
    ]
  },
  {
    "objectID": "miscellaneous-zipcodes.html#r-examples",
    "href": "miscellaneous-zipcodes.html#r-examples",
    "title": "102  🏗️ Zip Codes",
    "section": "102.3 R Examples",
    "text": "102.3 R Examples",
    "crumbs": [
      "Miscellaneous",
      "<span class='chapter-number'>102</span>  <span class='chapter-title'>🏗️ Zip Codes</span>"
    ]
  },
  {
    "objectID": "miscellaneous-zipcodes.html#python-examples",
    "href": "miscellaneous-zipcodes.html#python-examples",
    "title": "102  🏗️ Zip Codes",
    "section": "102.4 Python Examples",
    "text": "102.4 Python Examples",
    "crumbs": [
      "Miscellaneous",
      "<span class='chapter-number'>102</span>  <span class='chapter-title'>🏗️ Zip Codes</span>"
    ]
  },
  {
    "objectID": "miscellaneous-email.html",
    "href": "miscellaneous-email.html",
    "title": "103  🏗️ Emails",
    "section": "",
    "text": "103.1 Emails",
    "crumbs": [
      "Miscellaneous",
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>🏗️ Emails</span>"
    ]
  },
  {
    "objectID": "miscellaneous-email.html#pros-and-cons",
    "href": "miscellaneous-email.html#pros-and-cons",
    "title": "103  🏗️ Emails",
    "section": "103.2 Pros and Cons",
    "text": "103.2 Pros and Cons\n\n103.2.1 Pros\n\n\n103.2.2 Cons",
    "crumbs": [
      "Miscellaneous",
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>🏗️ Emails</span>"
    ]
  },
  {
    "objectID": "miscellaneous-email.html#r-examples",
    "href": "miscellaneous-email.html#r-examples",
    "title": "103  🏗️ Emails",
    "section": "103.3 R Examples",
    "text": "103.3 R Examples",
    "crumbs": [
      "Miscellaneous",
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>🏗️ Emails</span>"
    ]
  },
  {
    "objectID": "miscellaneous-email.html#python-examples",
    "href": "miscellaneous-email.html#python-examples",
    "title": "103  🏗️ Emails",
    "section": "103.4 Python Examples",
    "text": "103.4 Python Examples",
    "crumbs": [
      "Miscellaneous",
      "<span class='chapter-number'>103</span>  <span class='chapter-title'>🏗️ Emails</span>"
    ]
  },
  {
    "objectID": "spatial.html",
    "href": "spatial.html",
    "title": "104  Spatial Overview",
    "section": "",
    "text": "104.1 Spatial Overview",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>104</span>  <span class='chapter-title'>Spatial Overview</span>"
    ]
  },
  {
    "objectID": "spatial-distance.html",
    "href": "spatial-distance.html",
    "title": "105  🏗️ Spatial Distance",
    "section": "",
    "text": "105.1 Spatial Distance",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>105</span>  <span class='chapter-title'>🏗️ Spatial Distance</span>"
    ]
  },
  {
    "objectID": "spatial-distance.html#pros-and-cons",
    "href": "spatial-distance.html#pros-and-cons",
    "title": "105  🏗️ Spatial Distance",
    "section": "105.2 Pros and Cons",
    "text": "105.2 Pros and Cons\n\n105.2.1 Pros\n\n\n105.2.2 Cons",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>105</span>  <span class='chapter-title'>🏗️ Spatial Distance</span>"
    ]
  },
  {
    "objectID": "spatial-distance.html#r-examples",
    "href": "spatial-distance.html#r-examples",
    "title": "105  🏗️ Spatial Distance",
    "section": "105.3 R Examples",
    "text": "105.3 R Examples",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>105</span>  <span class='chapter-title'>🏗️ Spatial Distance</span>"
    ]
  },
  {
    "objectID": "spatial-distance.html#python-examples",
    "href": "spatial-distance.html#python-examples",
    "title": "105  🏗️ Spatial Distance",
    "section": "105.4 Python Examples",
    "text": "105.4 Python Examples",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>105</span>  <span class='chapter-title'>🏗️ Spatial Distance</span>"
    ]
  },
  {
    "objectID": "spatial-nearest.html",
    "href": "spatial-nearest.html",
    "title": "106  🏗️ Spatial Nearest",
    "section": "",
    "text": "106.1 Spatial Nearest",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>106</span>  <span class='chapter-title'>🏗️ Spatial Nearest</span>"
    ]
  },
  {
    "objectID": "spatial-nearest.html#pros-and-cons",
    "href": "spatial-nearest.html#pros-and-cons",
    "title": "106  🏗️ Spatial Nearest",
    "section": "106.2 Pros and Cons",
    "text": "106.2 Pros and Cons\n\n106.2.1 Pros\n\n\n106.2.2 Cons",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>106</span>  <span class='chapter-title'>🏗️ Spatial Nearest</span>"
    ]
  },
  {
    "objectID": "spatial-nearest.html#r-examples",
    "href": "spatial-nearest.html#r-examples",
    "title": "106  🏗️ Spatial Nearest",
    "section": "106.3 R Examples",
    "text": "106.3 R Examples",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>106</span>  <span class='chapter-title'>🏗️ Spatial Nearest</span>"
    ]
  },
  {
    "objectID": "spatial-nearest.html#python-examples",
    "href": "spatial-nearest.html#python-examples",
    "title": "106  🏗️ Spatial Nearest",
    "section": "106.4 Python Examples",
    "text": "106.4 Python Examples",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>106</span>  <span class='chapter-title'>🏗️ Spatial Nearest</span>"
    ]
  },
  {
    "objectID": "spatial-count.html",
    "href": "spatial-count.html",
    "title": "107  🏗️ Spatial Count",
    "section": "",
    "text": "107.1 Spatial Count",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>107</span>  <span class='chapter-title'>🏗️ Spatial Count</span>"
    ]
  },
  {
    "objectID": "spatial-count.html#pros-and-cons",
    "href": "spatial-count.html#pros-and-cons",
    "title": "107  🏗️ Spatial Count",
    "section": "107.2 Pros and Cons",
    "text": "107.2 Pros and Cons\n\n107.2.1 Pros\n\n\n107.2.2 Cons",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>107</span>  <span class='chapter-title'>🏗️ Spatial Count</span>"
    ]
  },
  {
    "objectID": "spatial-count.html#r-examples",
    "href": "spatial-count.html#r-examples",
    "title": "107  🏗️ Spatial Count",
    "section": "107.3 R Examples",
    "text": "107.3 R Examples",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>107</span>  <span class='chapter-title'>🏗️ Spatial Count</span>"
    ]
  },
  {
    "objectID": "spatial-count.html#python-examples",
    "href": "spatial-count.html#python-examples",
    "title": "107  🏗️ Spatial Count",
    "section": "107.4 Python Examples",
    "text": "107.4 Python Examples",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>107</span>  <span class='chapter-title'>🏗️ Spatial Count</span>"
    ]
  },
  {
    "objectID": "spatial-query.html",
    "href": "spatial-query.html",
    "title": "108  🏗️ Spatial Query",
    "section": "",
    "text": "108.1 Spatial Query",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>108</span>  <span class='chapter-title'>🏗️ Spatial Query</span>"
    ]
  },
  {
    "objectID": "spatial-query.html#pros-and-cons",
    "href": "spatial-query.html#pros-and-cons",
    "title": "108  🏗️ Spatial Query",
    "section": "108.2 Pros and Cons",
    "text": "108.2 Pros and Cons\n\n108.2.1 Pros\n\n\n108.2.2 Cons",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>108</span>  <span class='chapter-title'>🏗️ Spatial Query</span>"
    ]
  },
  {
    "objectID": "spatial-query.html#r-examples",
    "href": "spatial-query.html#r-examples",
    "title": "108  🏗️ Spatial Query",
    "section": "108.3 R Examples",
    "text": "108.3 R Examples",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>108</span>  <span class='chapter-title'>🏗️ Spatial Query</span>"
    ]
  },
  {
    "objectID": "spatial-query.html#python-examples",
    "href": "spatial-query.html#python-examples",
    "title": "108  🏗️ Spatial Query",
    "section": "108.4 Python Examples",
    "text": "108.4 Python Examples",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>108</span>  <span class='chapter-title'>🏗️ Spatial Query</span>"
    ]
  },
  {
    "objectID": "spatial-embedding.html",
    "href": "spatial-embedding.html",
    "title": "109  🏗️ Spatial Embedding",
    "section": "",
    "text": "109.1 Spatial Embedding",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>109</span>  <span class='chapter-title'>🏗️ Spatial Embedding</span>"
    ]
  },
  {
    "objectID": "spatial-embedding.html#pros-and-cons",
    "href": "spatial-embedding.html#pros-and-cons",
    "title": "109  🏗️ Spatial Embedding",
    "section": "109.2 Pros and Cons",
    "text": "109.2 Pros and Cons\n\n109.2.1 Pros\n\n\n109.2.2 Cons",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>109</span>  <span class='chapter-title'>🏗️ Spatial Embedding</span>"
    ]
  },
  {
    "objectID": "spatial-embedding.html#r-examples",
    "href": "spatial-embedding.html#r-examples",
    "title": "109  🏗️ Spatial Embedding",
    "section": "109.3 R Examples",
    "text": "109.3 R Examples",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>109</span>  <span class='chapter-title'>🏗️ Spatial Embedding</span>"
    ]
  },
  {
    "objectID": "spatial-embedding.html#python-examples",
    "href": "spatial-embedding.html#python-examples",
    "title": "109  🏗️ Spatial Embedding",
    "section": "109.4 Python Examples",
    "text": "109.4 Python Examples",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>109</span>  <span class='chapter-title'>🏗️ Spatial Embedding</span>"
    ]
  },
  {
    "objectID": "spatial-characteristics.html",
    "href": "spatial-characteristics.html",
    "title": "110  🏗️ Spatial Characteristics",
    "section": "",
    "text": "110.1 Spatial Characteristics",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>110</span>  <span class='chapter-title'>🏗️ Spatial Characteristics</span>"
    ]
  },
  {
    "objectID": "spatial-characteristics.html#pros-and-cons",
    "href": "spatial-characteristics.html#pros-and-cons",
    "title": "110  🏗️ Spatial Characteristics",
    "section": "110.2 Pros and Cons",
    "text": "110.2 Pros and Cons\n\n110.2.1 Pros\n\n\n110.2.2 Cons",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>110</span>  <span class='chapter-title'>🏗️ Spatial Characteristics</span>"
    ]
  },
  {
    "objectID": "spatial-characteristics.html#r-examples",
    "href": "spatial-characteristics.html#r-examples",
    "title": "110  🏗️ Spatial Characteristics",
    "section": "110.3 R Examples",
    "text": "110.3 R Examples",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>110</span>  <span class='chapter-title'>🏗️ Spatial Characteristics</span>"
    ]
  },
  {
    "objectID": "spatial-characteristics.html#python-examples",
    "href": "spatial-characteristics.html#python-examples",
    "title": "110  🏗️ Spatial Characteristics",
    "section": "110.4 Python Examples",
    "text": "110.4 Python Examples",
    "crumbs": [
      "Spatial",
      "<span class='chapter-number'>110</span>  <span class='chapter-title'>🏗️ Spatial Characteristics</span>"
    ]
  },
  {
    "objectID": "time-series.html",
    "href": "time-series.html",
    "title": "111  Time-series Overview",
    "section": "",
    "text": "111.1 Time-series Overview",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>111</span>  <span class='chapter-title'>Time-series Overview</span>"
    ]
  },
  {
    "objectID": "time-series-smooth.html",
    "href": "time-series-smooth.html",
    "title": "112  🏗️ Smoothing",
    "section": "",
    "text": "112.1 Smoothing",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>112</span>  <span class='chapter-title'>🏗️ Smoothing</span>"
    ]
  },
  {
    "objectID": "time-series-smooth.html#pros-and-cons",
    "href": "time-series-smooth.html#pros-and-cons",
    "title": "112  🏗️ Smoothing",
    "section": "112.2 Pros and Cons",
    "text": "112.2 Pros and Cons\n\n112.2.1 Pros\n\n\n112.2.2 Cons",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>112</span>  <span class='chapter-title'>🏗️ Smoothing</span>"
    ]
  },
  {
    "objectID": "time-series-smooth.html#r-examples",
    "href": "time-series-smooth.html#r-examples",
    "title": "112  🏗️ Smoothing",
    "section": "112.3 R Examples",
    "text": "112.3 R Examples",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>112</span>  <span class='chapter-title'>🏗️ Smoothing</span>"
    ]
  },
  {
    "objectID": "time-series-smooth.html#python-examples",
    "href": "time-series-smooth.html#python-examples",
    "title": "112  🏗️ Smoothing",
    "section": "112.4 Python Examples",
    "text": "112.4 Python Examples",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>112</span>  <span class='chapter-title'>🏗️ Smoothing</span>"
    ]
  },
  {
    "objectID": "time-series-sliding.html",
    "href": "time-series-sliding.html",
    "title": "113  🏗️ Sliding",
    "section": "",
    "text": "113.1 Sliding",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>113</span>  <span class='chapter-title'>🏗️ Sliding</span>"
    ]
  },
  {
    "objectID": "time-series-sliding.html#pros-and-cons",
    "href": "time-series-sliding.html#pros-and-cons",
    "title": "113  🏗️ Sliding",
    "section": "113.2 Pros and Cons",
    "text": "113.2 Pros and Cons\n\n113.2.1 Pros\n\n\n113.2.2 Cons",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>113</span>  <span class='chapter-title'>🏗️ Sliding</span>"
    ]
  },
  {
    "objectID": "time-series-sliding.html#r-examples",
    "href": "time-series-sliding.html#r-examples",
    "title": "113  🏗️ Sliding",
    "section": "113.3 R Examples",
    "text": "113.3 R Examples",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>113</span>  <span class='chapter-title'>🏗️ Sliding</span>"
    ]
  },
  {
    "objectID": "time-series-sliding.html#python-examples",
    "href": "time-series-sliding.html#python-examples",
    "title": "113  🏗️ Sliding",
    "section": "113.4 Python Examples",
    "text": "113.4 Python Examples",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>113</span>  <span class='chapter-title'>🏗️ Sliding</span>"
    ]
  },
  {
    "objectID": "time-series-log-interval.html",
    "href": "time-series-log-interval.html",
    "title": "114  🏗️ Log Interval",
    "section": "",
    "text": "114.1 Log Interval",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>114</span>  <span class='chapter-title'>🏗️ Log Interval</span>"
    ]
  },
  {
    "objectID": "time-series-log-interval.html#pros-and-cons",
    "href": "time-series-log-interval.html#pros-and-cons",
    "title": "114  🏗️ Log Interval",
    "section": "114.2 Pros and Cons",
    "text": "114.2 Pros and Cons\n\n114.2.1 Pros\n\n\n114.2.2 Cons",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>114</span>  <span class='chapter-title'>🏗️ Log Interval</span>"
    ]
  },
  {
    "objectID": "time-series-log-interval.html#r-examples",
    "href": "time-series-log-interval.html#r-examples",
    "title": "114  🏗️ Log Interval",
    "section": "114.3 R Examples",
    "text": "114.3 R Examples",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>114</span>  <span class='chapter-title'>🏗️ Log Interval</span>"
    ]
  },
  {
    "objectID": "time-series-log-interval.html#python-examples",
    "href": "time-series-log-interval.html#python-examples",
    "title": "114  🏗️ Log Interval",
    "section": "114.4 Python Examples",
    "text": "114.4 Python Examples",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>114</span>  <span class='chapter-title'>🏗️ Log Interval</span>"
    ]
  },
  {
    "objectID": "time-series-missing.html",
    "href": "time-series-missing.html",
    "title": "115  🏗️ Time series Missing values",
    "section": "",
    "text": "115.1 Time series Missing values",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>115</span>  <span class='chapter-title'>🏗️ Time series Missing values</span>"
    ]
  },
  {
    "objectID": "time-series-missing.html#pros-and-cons",
    "href": "time-series-missing.html#pros-and-cons",
    "title": "115  🏗️ Time series Missing values",
    "section": "115.2 Pros and Cons",
    "text": "115.2 Pros and Cons\n\n115.2.1 Pros\n\n\n115.2.2 Cons",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>115</span>  <span class='chapter-title'>🏗️ Time series Missing values</span>"
    ]
  },
  {
    "objectID": "time-series-missing.html#r-examples",
    "href": "time-series-missing.html#r-examples",
    "title": "115  🏗️ Time series Missing values",
    "section": "115.3 R Examples",
    "text": "115.3 R Examples",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>115</span>  <span class='chapter-title'>🏗️ Time series Missing values</span>"
    ]
  },
  {
    "objectID": "time-series-missing.html#python-examples",
    "href": "time-series-missing.html#python-examples",
    "title": "115  🏗️ Time series Missing values",
    "section": "115.4 Python Examples",
    "text": "115.4 Python Examples",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>115</span>  <span class='chapter-title'>🏗️ Time series Missing values</span>"
    ]
  },
  {
    "objectID": "time-series-outliers.html",
    "href": "time-series-outliers.html",
    "title": "116  🏗️ Time Series outliers",
    "section": "",
    "text": "116.1 Time Series outliers",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>116</span>  <span class='chapter-title'>🏗️ Time Series outliers</span>"
    ]
  },
  {
    "objectID": "time-series-outliers.html#pros-and-cons",
    "href": "time-series-outliers.html#pros-and-cons",
    "title": "116  🏗️ Time Series outliers",
    "section": "116.2 Pros and Cons",
    "text": "116.2 Pros and Cons\n\n116.2.1 Pros\n\n\n116.2.2 Cons",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>116</span>  <span class='chapter-title'>🏗️ Time Series outliers</span>"
    ]
  },
  {
    "objectID": "time-series-outliers.html#r-examples",
    "href": "time-series-outliers.html#r-examples",
    "title": "116  🏗️ Time Series outliers",
    "section": "116.3 R Examples",
    "text": "116.3 R Examples",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>116</span>  <span class='chapter-title'>🏗️ Time Series outliers</span>"
    ]
  },
  {
    "objectID": "time-series-outliers.html#python-examples",
    "href": "time-series-outliers.html#python-examples",
    "title": "116  🏗️ Time Series outliers",
    "section": "116.4 Python Examples",
    "text": "116.4 Python Examples",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>116</span>  <span class='chapter-title'>🏗️ Time Series outliers</span>"
    ]
  },
  {
    "objectID": "time-series-diff.html",
    "href": "time-series-diff.html",
    "title": "117  🏗️ Differences",
    "section": "",
    "text": "117.1 Differences",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>117</span>  <span class='chapter-title'>🏗️ Differences</span>"
    ]
  },
  {
    "objectID": "time-series-diff.html#pros-and-cons",
    "href": "time-series-diff.html#pros-and-cons",
    "title": "117  🏗️ Differences",
    "section": "117.2 Pros and Cons",
    "text": "117.2 Pros and Cons\n\n117.2.1 Pros\n\n\n117.2.2 Cons",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>117</span>  <span class='chapter-title'>🏗️ Differences</span>"
    ]
  },
  {
    "objectID": "time-series-diff.html#r-examples",
    "href": "time-series-diff.html#r-examples",
    "title": "117  🏗️ Differences",
    "section": "117.3 R Examples",
    "text": "117.3 R Examples",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>117</span>  <span class='chapter-title'>🏗️ Differences</span>"
    ]
  },
  {
    "objectID": "time-series-diff.html#python-examples",
    "href": "time-series-diff.html#python-examples",
    "title": "117  🏗️ Differences",
    "section": "117.4 Python Examples",
    "text": "117.4 Python Examples",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>117</span>  <span class='chapter-title'>🏗️ Differences</span>"
    ]
  },
  {
    "objectID": "time-series-lag.html",
    "href": "time-series-lag.html",
    "title": "118  🏗️ Lagging Features",
    "section": "",
    "text": "118.1 Lagging Features",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>118</span>  <span class='chapter-title'>🏗️ Lagging Features</span>"
    ]
  },
  {
    "objectID": "time-series-lag.html#pros-and-cons",
    "href": "time-series-lag.html#pros-and-cons",
    "title": "118  🏗️ Lagging Features",
    "section": "118.2 Pros and Cons",
    "text": "118.2 Pros and Cons\n\n118.2.1 Pros\n\n\n118.2.2 Cons",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>118</span>  <span class='chapter-title'>🏗️ Lagging Features</span>"
    ]
  },
  {
    "objectID": "time-series-lag.html#r-examples",
    "href": "time-series-lag.html#r-examples",
    "title": "118  🏗️ Lagging Features",
    "section": "118.3 R Examples",
    "text": "118.3 R Examples",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>118</span>  <span class='chapter-title'>🏗️ Lagging Features</span>"
    ]
  },
  {
    "objectID": "time-series-lag.html#python-examples",
    "href": "time-series-lag.html#python-examples",
    "title": "118  🏗️ Lagging Features",
    "section": "118.4 Python Examples",
    "text": "118.4 Python Examples",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>118</span>  <span class='chapter-title'>🏗️ Lagging Features</span>"
    ]
  },
  {
    "objectID": "time-series-rolling-window.html",
    "href": "time-series-rolling-window.html",
    "title": "119  🏗️ Rolling Window",
    "section": "",
    "text": "119.1 Rolling Window",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>119</span>  <span class='chapter-title'>🏗️ Rolling Window</span>"
    ]
  },
  {
    "objectID": "time-series-rolling-window.html#pros-and-cons",
    "href": "time-series-rolling-window.html#pros-and-cons",
    "title": "119  🏗️ Rolling Window",
    "section": "119.2 Pros and Cons",
    "text": "119.2 Pros and Cons\n\n119.2.1 Pros\n\n\n119.2.2 Cons",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>119</span>  <span class='chapter-title'>🏗️ Rolling Window</span>"
    ]
  },
  {
    "objectID": "time-series-rolling-window.html#r-examples",
    "href": "time-series-rolling-window.html#r-examples",
    "title": "119  🏗️ Rolling Window",
    "section": "119.3 R Examples",
    "text": "119.3 R Examples",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>119</span>  <span class='chapter-title'>🏗️ Rolling Window</span>"
    ]
  },
  {
    "objectID": "time-series-rolling-window.html#python-examples",
    "href": "time-series-rolling-window.html#python-examples",
    "title": "119  🏗️ Rolling Window",
    "section": "119.4 Python Examples",
    "text": "119.4 Python Examples",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>119</span>  <span class='chapter-title'>🏗️ Rolling Window</span>"
    ]
  },
  {
    "objectID": "time-series-expanding-window.html",
    "href": "time-series-expanding-window.html",
    "title": "120  🏗️ Expanding Window",
    "section": "",
    "text": "120.1 Expanding Window",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>120</span>  <span class='chapter-title'>🏗️ Expanding Window</span>"
    ]
  },
  {
    "objectID": "time-series-expanding-window.html#pros-and-cons",
    "href": "time-series-expanding-window.html#pros-and-cons",
    "title": "120  🏗️ Expanding Window",
    "section": "120.2 Pros and Cons",
    "text": "120.2 Pros and Cons\n\n120.2.1 Pros\n\n\n120.2.2 Cons",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>120</span>  <span class='chapter-title'>🏗️ Expanding Window</span>"
    ]
  },
  {
    "objectID": "time-series-expanding-window.html#r-examples",
    "href": "time-series-expanding-window.html#r-examples",
    "title": "120  🏗️ Expanding Window",
    "section": "120.3 R Examples",
    "text": "120.3 R Examples",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>120</span>  <span class='chapter-title'>🏗️ Expanding Window</span>"
    ]
  },
  {
    "objectID": "time-series-expanding-window.html#python-examples",
    "href": "time-series-expanding-window.html#python-examples",
    "title": "120  🏗️ Expanding Window",
    "section": "120.4 Python Examples",
    "text": "120.4 Python Examples",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>120</span>  <span class='chapter-title'>🏗️ Expanding Window</span>"
    ]
  },
  {
    "objectID": "time-series-fourier.html",
    "href": "time-series-fourier.html",
    "title": "121  🏗️ Fourier Features",
    "section": "",
    "text": "121.1 Fourier Features",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>121</span>  <span class='chapter-title'>🏗️ Fourier Features</span>"
    ]
  },
  {
    "objectID": "time-series-fourier.html#pros-and-cons",
    "href": "time-series-fourier.html#pros-and-cons",
    "title": "121  🏗️ Fourier Features",
    "section": "121.2 Pros and Cons",
    "text": "121.2 Pros and Cons\n\n121.2.1 Pros\n\n\n121.2.2 Cons",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>121</span>  <span class='chapter-title'>🏗️ Fourier Features</span>"
    ]
  },
  {
    "objectID": "time-series-fourier.html#r-examples",
    "href": "time-series-fourier.html#r-examples",
    "title": "121  🏗️ Fourier Features",
    "section": "121.3 R Examples",
    "text": "121.3 R Examples",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>121</span>  <span class='chapter-title'>🏗️ Fourier Features</span>"
    ]
  },
  {
    "objectID": "time-series-fourier.html#python-examples",
    "href": "time-series-fourier.html#python-examples",
    "title": "121  🏗️ Fourier Features",
    "section": "121.4 Python Examples",
    "text": "121.4 Python Examples",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>121</span>  <span class='chapter-title'>🏗️ Fourier Features</span>"
    ]
  },
  {
    "objectID": "time-series-wavelet.html",
    "href": "time-series-wavelet.html",
    "title": "122  🏗️ Wavelet",
    "section": "",
    "text": "122.1 Wavelet",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>122</span>  <span class='chapter-title'>🏗️ Wavelet</span>"
    ]
  },
  {
    "objectID": "time-series-wavelet.html#pros-and-cons",
    "href": "time-series-wavelet.html#pros-and-cons",
    "title": "122  🏗️ Wavelet",
    "section": "122.2 Pros and Cons",
    "text": "122.2 Pros and Cons\n\n122.2.1 Pros\n\n\n122.2.2 Cons",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>122</span>  <span class='chapter-title'>🏗️ Wavelet</span>"
    ]
  },
  {
    "objectID": "time-series-wavelet.html#r-examples",
    "href": "time-series-wavelet.html#r-examples",
    "title": "122  🏗️ Wavelet",
    "section": "122.3 R Examples",
    "text": "122.3 R Examples",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>122</span>  <span class='chapter-title'>🏗️ Wavelet</span>"
    ]
  },
  {
    "objectID": "time-series-wavelet.html#python-examples",
    "href": "time-series-wavelet.html#python-examples",
    "title": "122  🏗️ Wavelet",
    "section": "122.4 Python Examples",
    "text": "122.4 Python Examples",
    "crumbs": [
      "Time-Series Data",
      "<span class='chapter-number'>122</span>  <span class='chapter-title'>🏗️ Wavelet</span>"
    ]
  },
  {
    "objectID": "image.html",
    "href": "image.html",
    "title": "123  Image Overview",
    "section": "",
    "text": "123.1 Image Overview",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>123</span>  <span class='chapter-title'>Image Overview</span>"
    ]
  },
  {
    "objectID": "image.html#feature-extraction",
    "href": "image.html#feature-extraction",
    "title": "123  Image Overview",
    "section": "123.2 Feature Extraction",
    "text": "123.2 Feature Extraction\nIn the extraction setting, we take the images and try to extract smaller, hopefully smaller vectors of information. These could be simple statistics or larger and more complicated methods. One does not need to do this right away, and sometimes it is beneficial to apply some of the image modification methods below before doing the extraction.\n\nEdge detection and corner detection in Chapter 124\ntexture analysis in Chapter 125",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>123</span>  <span class='chapter-title'>Image Overview</span>"
    ]
  },
  {
    "objectID": "image.html#image-modification",
    "href": "image.html#image-modification",
    "title": "123  Image Overview",
    "section": "123.3 Image Modification",
    "text": "123.3 Image Modification\nSometimes the images you get will not be in the best shape for your task at hand. This could be for various reasons. Applying color changes of different kinds can help highlight the important parts of the image, such that later preprocessing steps or models have an easier time picking up on it. Likewise, you might need to scale the data to help the model and well as reduce noise. Lastly, you will most likely need to resize your images as many deep-learning image modes work on fixed input sizes.\n\nGrayscale conversion in Chapter 126\ncolor modifications in Chapter 127\nnoise reduction in Chapter 128\nValue normalization in Chapter 129\nresizing in Chapter 130",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>123</span>  <span class='chapter-title'>Image Overview</span>"
    ]
  },
  {
    "objectID": "image.html#augmentation",
    "href": "image.html#augmentation",
    "title": "123  Image Overview",
    "section": "123.4 Augmentation",
    "text": "123.4 Augmentation\nA common trick when working with image data is to do augmentation. What we mean by that, is that we do different kinds of transformations to generate new images that contain the same information but in different ways. It creates a larger data set. With the hopes of increasing the performance and generalization. Being able to detect cat pictures regardless if they are centered in the image or not.\n\nChanging brightness in Chapter 131\nShifting, Flipping, Rotation in Chapter 132\nCropping and scaling in Chapter 133",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>123</span>  <span class='chapter-title'>Image Overview</span>"
    ]
  },
  {
    "objectID": "image.html#embeddings",
    "href": "image.html#embeddings",
    "title": "123  Image Overview",
    "section": "123.5 Embeddings",
    "text": "123.5 Embeddings\nWe can also take advantage of transfer learning. People have fit image deep learning models on many images before us. And some of these trained models can be reused for us. We will look at that in Chapter 134.",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>123</span>  <span class='chapter-title'>Image Overview</span>"
    ]
  },
  {
    "objectID": "image-edge-corner.html",
    "href": "image-edge-corner.html",
    "title": "124  🏗️ Edge and corner detection",
    "section": "",
    "text": "124.1 Edge and corner detection",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>124</span>  <span class='chapter-title'>🏗️ Edge and corner detection</span>"
    ]
  },
  {
    "objectID": "image-edge-corner.html#pros-and-cons",
    "href": "image-edge-corner.html#pros-and-cons",
    "title": "124  🏗️ Edge and corner detection",
    "section": "124.2 Pros and Cons",
    "text": "124.2 Pros and Cons\n\n124.2.1 Pros\n\n\n124.2.2 Cons",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>124</span>  <span class='chapter-title'>🏗️ Edge and corner detection</span>"
    ]
  },
  {
    "objectID": "image-edge-corner.html#r-examples",
    "href": "image-edge-corner.html#r-examples",
    "title": "124  🏗️ Edge and corner detection",
    "section": "124.3 R Examples",
    "text": "124.3 R Examples",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>124</span>  <span class='chapter-title'>🏗️ Edge and corner detection</span>"
    ]
  },
  {
    "objectID": "image-edge-corner.html#python-examples",
    "href": "image-edge-corner.html#python-examples",
    "title": "124  🏗️ Edge and corner detection",
    "section": "124.4 Python Examples",
    "text": "124.4 Python Examples",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>124</span>  <span class='chapter-title'>🏗️ Edge and corner detection</span>"
    ]
  },
  {
    "objectID": "image-texture.html",
    "href": "image-texture.html",
    "title": "125  🏗️ Texture Analysis",
    "section": "",
    "text": "125.1 Texture Analysis",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>125</span>  <span class='chapter-title'>🏗️ Texture Analysis</span>"
    ]
  },
  {
    "objectID": "image-texture.html#pros-and-cons",
    "href": "image-texture.html#pros-and-cons",
    "title": "125  🏗️ Texture Analysis",
    "section": "125.2 Pros and Cons",
    "text": "125.2 Pros and Cons\n\n125.2.1 Pros\n\n\n125.2.2 Cons",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>125</span>  <span class='chapter-title'>🏗️ Texture Analysis</span>"
    ]
  },
  {
    "objectID": "image-texture.html#r-examples",
    "href": "image-texture.html#r-examples",
    "title": "125  🏗️ Texture Analysis",
    "section": "125.3 R Examples",
    "text": "125.3 R Examples",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>125</span>  <span class='chapter-title'>🏗️ Texture Analysis</span>"
    ]
  },
  {
    "objectID": "image-texture.html#python-examples",
    "href": "image-texture.html#python-examples",
    "title": "125  🏗️ Texture Analysis",
    "section": "125.4 Python Examples",
    "text": "125.4 Python Examples",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>125</span>  <span class='chapter-title'>🏗️ Texture Analysis</span>"
    ]
  },
  {
    "objectID": "image-grayscale.html",
    "href": "image-grayscale.html",
    "title": "126  🏗️ Greyscale conversion",
    "section": "",
    "text": "126.1 Greyscale conversion",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>126</span>  <span class='chapter-title'>🏗️ Greyscale conversion</span>"
    ]
  },
  {
    "objectID": "image-grayscale.html#pros-and-cons",
    "href": "image-grayscale.html#pros-and-cons",
    "title": "126  🏗️ Greyscale conversion",
    "section": "126.2 Pros and Cons",
    "text": "126.2 Pros and Cons\n\n126.2.1 Pros\n\n\n126.2.2 Cons",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>126</span>  <span class='chapter-title'>🏗️ Greyscale conversion</span>"
    ]
  },
  {
    "objectID": "image-grayscale.html#r-examples",
    "href": "image-grayscale.html#r-examples",
    "title": "126  🏗️ Greyscale conversion",
    "section": "126.3 R Examples",
    "text": "126.3 R Examples",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>126</span>  <span class='chapter-title'>🏗️ Greyscale conversion</span>"
    ]
  },
  {
    "objectID": "image-grayscale.html#python-examples",
    "href": "image-grayscale.html#python-examples",
    "title": "126  🏗️ Greyscale conversion",
    "section": "126.4 Python Examples",
    "text": "126.4 Python Examples",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>126</span>  <span class='chapter-title'>🏗️ Greyscale conversion</span>"
    ]
  },
  {
    "objectID": "image-colors.html",
    "href": "image-colors.html",
    "title": "127  🏗️ Color Modifications",
    "section": "",
    "text": "127.1 Color Modifications",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>127</span>  <span class='chapter-title'>🏗️ Color Modifications</span>"
    ]
  },
  {
    "objectID": "image-colors.html#pros-and-cons",
    "href": "image-colors.html#pros-and-cons",
    "title": "127  🏗️ Color Modifications",
    "section": "127.2 Pros and Cons",
    "text": "127.2 Pros and Cons\n\n127.2.1 Pros\n\n\n127.2.2 Cons",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>127</span>  <span class='chapter-title'>🏗️ Color Modifications</span>"
    ]
  },
  {
    "objectID": "image-colors.html#r-examples",
    "href": "image-colors.html#r-examples",
    "title": "127  🏗️ Color Modifications",
    "section": "127.3 R Examples",
    "text": "127.3 R Examples",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>127</span>  <span class='chapter-title'>🏗️ Color Modifications</span>"
    ]
  },
  {
    "objectID": "image-colors.html#python-examples",
    "href": "image-colors.html#python-examples",
    "title": "127  🏗️ Color Modifications",
    "section": "127.4 Python Examples",
    "text": "127.4 Python Examples",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>127</span>  <span class='chapter-title'>🏗️ Color Modifications</span>"
    ]
  },
  {
    "objectID": "image-noise.html",
    "href": "image-noise.html",
    "title": "128  🏗️ Noise Reduction",
    "section": "",
    "text": "128.1 Noise Reduction",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>128</span>  <span class='chapter-title'>🏗️ Noise Reduction</span>"
    ]
  },
  {
    "objectID": "image-noise.html#pros-and-cons",
    "href": "image-noise.html#pros-and-cons",
    "title": "128  🏗️ Noise Reduction",
    "section": "128.2 Pros and Cons",
    "text": "128.2 Pros and Cons\n\n128.2.1 Pros\n\n\n128.2.2 Cons",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>128</span>  <span class='chapter-title'>🏗️ Noise Reduction</span>"
    ]
  },
  {
    "objectID": "image-noise.html#r-examples",
    "href": "image-noise.html#r-examples",
    "title": "128  🏗️ Noise Reduction",
    "section": "128.3 R Examples",
    "text": "128.3 R Examples",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>128</span>  <span class='chapter-title'>🏗️ Noise Reduction</span>"
    ]
  },
  {
    "objectID": "image-noise.html#python-examples",
    "href": "image-noise.html#python-examples",
    "title": "128  🏗️ Noise Reduction",
    "section": "128.4 Python Examples",
    "text": "128.4 Python Examples",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>128</span>  <span class='chapter-title'>🏗️ Noise Reduction</span>"
    ]
  },
  {
    "objectID": "image-normalization.html",
    "href": "image-normalization.html",
    "title": "129  🏗️ Value Normalization",
    "section": "",
    "text": "129.1 Value Normalization",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>129</span>  <span class='chapter-title'>🏗️ Value Normalization</span>"
    ]
  },
  {
    "objectID": "image-normalization.html#pros-and-cons",
    "href": "image-normalization.html#pros-and-cons",
    "title": "129  🏗️ Value Normalization",
    "section": "129.2 Pros and Cons",
    "text": "129.2 Pros and Cons\n\n129.2.1 Pros\n\n\n129.2.2 Cons",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>129</span>  <span class='chapter-title'>🏗️ Value Normalization</span>"
    ]
  },
  {
    "objectID": "image-normalization.html#r-examples",
    "href": "image-normalization.html#r-examples",
    "title": "129  🏗️ Value Normalization",
    "section": "129.3 R Examples",
    "text": "129.3 R Examples",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>129</span>  <span class='chapter-title'>🏗️ Value Normalization</span>"
    ]
  },
  {
    "objectID": "image-normalization.html#python-examples",
    "href": "image-normalization.html#python-examples",
    "title": "129  🏗️ Value Normalization",
    "section": "129.4 Python Examples",
    "text": "129.4 Python Examples",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>129</span>  <span class='chapter-title'>🏗️ Value Normalization</span>"
    ]
  },
  {
    "objectID": "image-resize.html",
    "href": "image-resize.html",
    "title": "130  🏗️ Resizing",
    "section": "",
    "text": "130.1 Resizing",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>130</span>  <span class='chapter-title'>🏗️ Resizing</span>"
    ]
  },
  {
    "objectID": "image-resize.html#pros-and-cons",
    "href": "image-resize.html#pros-and-cons",
    "title": "130  🏗️ Resizing",
    "section": "130.2 Pros and Cons",
    "text": "130.2 Pros and Cons\n\n130.2.1 Pros\n\n\n130.2.2 Cons",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>130</span>  <span class='chapter-title'>🏗️ Resizing</span>"
    ]
  },
  {
    "objectID": "image-resize.html#r-examples",
    "href": "image-resize.html#r-examples",
    "title": "130  🏗️ Resizing",
    "section": "130.3 R Examples",
    "text": "130.3 R Examples",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>130</span>  <span class='chapter-title'>🏗️ Resizing</span>"
    ]
  },
  {
    "objectID": "image-resize.html#python-examples",
    "href": "image-resize.html#python-examples",
    "title": "130  🏗️ Resizing",
    "section": "130.4 Python Examples",
    "text": "130.4 Python Examples",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>130</span>  <span class='chapter-title'>🏗️ Resizing</span>"
    ]
  },
  {
    "objectID": "image-brightness.html",
    "href": "image-brightness.html",
    "title": "131  🏗️ Changing Brightness",
    "section": "",
    "text": "131.1 Changing Brightness",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>131</span>  <span class='chapter-title'>🏗️ Changing Brightness</span>"
    ]
  },
  {
    "objectID": "image-brightness.html#pros-and-cons",
    "href": "image-brightness.html#pros-and-cons",
    "title": "131  🏗️ Changing Brightness",
    "section": "131.2 Pros and Cons",
    "text": "131.2 Pros and Cons\n\n131.2.1 Pros\n\n\n131.2.2 Cons",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>131</span>  <span class='chapter-title'>🏗️ Changing Brightness</span>"
    ]
  },
  {
    "objectID": "image-brightness.html#r-examples",
    "href": "image-brightness.html#r-examples",
    "title": "131  🏗️ Changing Brightness",
    "section": "131.3 R Examples",
    "text": "131.3 R Examples",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>131</span>  <span class='chapter-title'>🏗️ Changing Brightness</span>"
    ]
  },
  {
    "objectID": "image-brightness.html#python-examples",
    "href": "image-brightness.html#python-examples",
    "title": "131  🏗️ Changing Brightness",
    "section": "131.4 Python Examples",
    "text": "131.4 Python Examples",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>131</span>  <span class='chapter-title'>🏗️ Changing Brightness</span>"
    ]
  },
  {
    "objectID": "image-shift-flip-rotate.html",
    "href": "image-shift-flip-rotate.html",
    "title": "132  🏗️ Shifting, Flipping, and Rotation",
    "section": "",
    "text": "132.1 Shifting, Flipping, and Rotation",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>132</span>  <span class='chapter-title'>🏗️ Shifting, Flipping, and Rotation</span>"
    ]
  },
  {
    "objectID": "image-shift-flip-rotate.html#pros-and-cons",
    "href": "image-shift-flip-rotate.html#pros-and-cons",
    "title": "132  🏗️ Shifting, Flipping, and Rotation",
    "section": "132.2 Pros and Cons",
    "text": "132.2 Pros and Cons\n\n132.2.1 Pros\n\n\n132.2.2 Cons",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>132</span>  <span class='chapter-title'>🏗️ Shifting, Flipping, and Rotation</span>"
    ]
  },
  {
    "objectID": "image-shift-flip-rotate.html#r-examples",
    "href": "image-shift-flip-rotate.html#r-examples",
    "title": "132  🏗️ Shifting, Flipping, and Rotation",
    "section": "132.3 R Examples",
    "text": "132.3 R Examples",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>132</span>  <span class='chapter-title'>🏗️ Shifting, Flipping, and Rotation</span>"
    ]
  },
  {
    "objectID": "image-shift-flip-rotate.html#python-examples",
    "href": "image-shift-flip-rotate.html#python-examples",
    "title": "132  🏗️ Shifting, Flipping, and Rotation",
    "section": "132.4 Python Examples",
    "text": "132.4 Python Examples",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>132</span>  <span class='chapter-title'>🏗️ Shifting, Flipping, and Rotation</span>"
    ]
  },
  {
    "objectID": "image-crop-scale.html",
    "href": "image-crop-scale.html",
    "title": "133  🏗️ Cropping and Scaling",
    "section": "",
    "text": "133.1 Cropping and Scaling",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>133</span>  <span class='chapter-title'>🏗️ Cropping and Scaling</span>"
    ]
  },
  {
    "objectID": "image-crop-scale.html#pros-and-cons",
    "href": "image-crop-scale.html#pros-and-cons",
    "title": "133  🏗️ Cropping and Scaling",
    "section": "133.2 Pros and Cons",
    "text": "133.2 Pros and Cons\n\n133.2.1 Pros\n\n\n133.2.2 Cons",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>133</span>  <span class='chapter-title'>🏗️ Cropping and Scaling</span>"
    ]
  },
  {
    "objectID": "image-crop-scale.html#r-examples",
    "href": "image-crop-scale.html#r-examples",
    "title": "133  🏗️ Cropping and Scaling",
    "section": "133.3 R Examples",
    "text": "133.3 R Examples",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>133</span>  <span class='chapter-title'>🏗️ Cropping and Scaling</span>"
    ]
  },
  {
    "objectID": "image-crop-scale.html#python-examples",
    "href": "image-crop-scale.html#python-examples",
    "title": "133  🏗️ Cropping and Scaling",
    "section": "133.4 Python Examples",
    "text": "133.4 Python Examples",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>133</span>  <span class='chapter-title'>🏗️ Cropping and Scaling</span>"
    ]
  },
  {
    "objectID": "image-embeddings.html",
    "href": "image-embeddings.html",
    "title": "134  🏗️ Image embeddings",
    "section": "",
    "text": "134.1 Image embeddings",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>134</span>  <span class='chapter-title'>🏗️ Image embeddings</span>"
    ]
  },
  {
    "objectID": "image-embeddings.html#pros-and-cons",
    "href": "image-embeddings.html#pros-and-cons",
    "title": "134  🏗️ Image embeddings",
    "section": "134.2 Pros and Cons",
    "text": "134.2 Pros and Cons\n\n134.2.1 Pros\n\n\n134.2.2 Cons",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>134</span>  <span class='chapter-title'>🏗️ Image embeddings</span>"
    ]
  },
  {
    "objectID": "image-embeddings.html#r-examples",
    "href": "image-embeddings.html#r-examples",
    "title": "134  🏗️ Image embeddings",
    "section": "134.3 R Examples",
    "text": "134.3 R Examples",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>134</span>  <span class='chapter-title'>🏗️ Image embeddings</span>"
    ]
  },
  {
    "objectID": "image-embeddings.html#python-examples",
    "href": "image-embeddings.html#python-examples",
    "title": "134  🏗️ Image embeddings",
    "section": "134.4 Python Examples",
    "text": "134.4 Python Examples",
    "crumbs": [
      "Image Data",
      "<span class='chapter-number'>134</span>  <span class='chapter-title'>🏗️ Image embeddings</span>"
    ]
  },
  {
    "objectID": "relational.html",
    "href": "relational.html",
    "title": "135  Relational Overview",
    "section": "",
    "text": "135.1 Relational Overview",
    "crumbs": [
      "Ralational Data",
      "<span class='chapter-number'>135</span>  <span class='chapter-title'>Relational Overview</span>"
    ]
  },
  {
    "objectID": "relational-manual.html",
    "href": "relational-manual.html",
    "title": "136  🏗️ Manual",
    "section": "",
    "text": "136.1 Manual",
    "crumbs": [
      "Ralational Data",
      "<span class='chapter-number'>136</span>  <span class='chapter-title'>🏗️ Manual</span>"
    ]
  },
  {
    "objectID": "relational-manual.html#pros-and-cons",
    "href": "relational-manual.html#pros-and-cons",
    "title": "136  🏗️ Manual",
    "section": "136.2 Pros and Cons",
    "text": "136.2 Pros and Cons\n\n136.2.1 Pros\n\n\n136.2.2 Cons",
    "crumbs": [
      "Ralational Data",
      "<span class='chapter-number'>136</span>  <span class='chapter-title'>🏗️ Manual</span>"
    ]
  },
  {
    "objectID": "relational-manual.html#r-examples",
    "href": "relational-manual.html#r-examples",
    "title": "136  🏗️ Manual",
    "section": "136.3 R Examples",
    "text": "136.3 R Examples",
    "crumbs": [
      "Ralational Data",
      "<span class='chapter-number'>136</span>  <span class='chapter-title'>🏗️ Manual</span>"
    ]
  },
  {
    "objectID": "relational-manual.html#python-examples",
    "href": "relational-manual.html#python-examples",
    "title": "136  🏗️ Manual",
    "section": "136.4 Python Examples",
    "text": "136.4 Python Examples",
    "crumbs": [
      "Ralational Data",
      "<span class='chapter-number'>136</span>  <span class='chapter-title'>🏗️ Manual</span>"
    ]
  },
  {
    "objectID": "relational-auto.html",
    "href": "relational-auto.html",
    "title": "137  🏗️ Automatic",
    "section": "",
    "text": "137.1 Automatic",
    "crumbs": [
      "Ralational Data",
      "<span class='chapter-number'>137</span>  <span class='chapter-title'>🏗️ Automatic</span>"
    ]
  },
  {
    "objectID": "relational-auto.html#pros-and-cons",
    "href": "relational-auto.html#pros-and-cons",
    "title": "137  🏗️ Automatic",
    "section": "137.2 Pros and Cons",
    "text": "137.2 Pros and Cons\n\n137.2.1 Pros\n\n\n137.2.2 Cons",
    "crumbs": [
      "Ralational Data",
      "<span class='chapter-number'>137</span>  <span class='chapter-title'>🏗️ Automatic</span>"
    ]
  },
  {
    "objectID": "relational-auto.html#r-examples",
    "href": "relational-auto.html#r-examples",
    "title": "137  🏗️ Automatic",
    "section": "137.3 R Examples",
    "text": "137.3 R Examples",
    "crumbs": [
      "Ralational Data",
      "<span class='chapter-number'>137</span>  <span class='chapter-title'>🏗️ Automatic</span>"
    ]
  },
  {
    "objectID": "relational-auto.html#python-examples",
    "href": "relational-auto.html#python-examples",
    "title": "137  🏗️ Automatic",
    "section": "137.4 Python Examples",
    "text": "137.4 Python Examples",
    "crumbs": [
      "Ralational Data",
      "<span class='chapter-number'>137</span>  <span class='chapter-title'>🏗️ Automatic</span>"
    ]
  },
  {
    "objectID": "video.html",
    "href": "video.html",
    "title": "138  Video Overview",
    "section": "",
    "text": "138.1 Video Overview",
    "crumbs": [
      "Video Data",
      "<span class='chapter-number'>138</span>  <span class='chapter-title'>Video Overview</span>"
    ]
  },
  {
    "objectID": "video-tmp.html",
    "href": "video-tmp.html",
    "title": "139  🏗️ Temporary",
    "section": "",
    "text": "139.1 Temprary",
    "crumbs": [
      "Video Data",
      "<span class='chapter-number'>139</span>  <span class='chapter-title'>🏗️ Temporary</span>"
    ]
  },
  {
    "objectID": "video-tmp.html#pros-and-cons",
    "href": "video-tmp.html#pros-and-cons",
    "title": "139  🏗️ Temporary",
    "section": "139.2 Pros and Cons",
    "text": "139.2 Pros and Cons\n\n139.2.1 Pros\n\n\n139.2.2 Cons",
    "crumbs": [
      "Video Data",
      "<span class='chapter-number'>139</span>  <span class='chapter-title'>🏗️ Temporary</span>"
    ]
  },
  {
    "objectID": "video-tmp.html#r-examples",
    "href": "video-tmp.html#r-examples",
    "title": "139  🏗️ Temporary",
    "section": "139.3 R Examples",
    "text": "139.3 R Examples",
    "crumbs": [
      "Video Data",
      "<span class='chapter-number'>139</span>  <span class='chapter-title'>🏗️ Temporary</span>"
    ]
  },
  {
    "objectID": "video-tmp.html#python-examples",
    "href": "video-tmp.html#python-examples",
    "title": "139  🏗️ Temporary",
    "section": "139.4 Python Examples",
    "text": "139.4 Python Examples",
    "crumbs": [
      "Video Data",
      "<span class='chapter-number'>139</span>  <span class='chapter-title'>🏗️ Temporary</span>"
    ]
  },
  {
    "objectID": "sound.html",
    "href": "sound.html",
    "title": "140  Sound Overview",
    "section": "",
    "text": "140.1 Sound Overview",
    "crumbs": [
      "Sound Data",
      "<span class='chapter-number'>140</span>  <span class='chapter-title'>Sound Overview</span>"
    ]
  },
  {
    "objectID": "sound-tmp.html",
    "href": "sound-tmp.html",
    "title": "141  🏗️ Temporary",
    "section": "",
    "text": "141.1 Temporary",
    "crumbs": [
      "Sound Data",
      "<span class='chapter-number'>141</span>  <span class='chapter-title'>🏗️ Temporary</span>"
    ]
  },
  {
    "objectID": "sound-tmp.html#pros-and-cons",
    "href": "sound-tmp.html#pros-and-cons",
    "title": "141  🏗️ Temporary",
    "section": "141.2 Pros and Cons",
    "text": "141.2 Pros and Cons\n\n141.2.1 Pros\n\n\n141.2.2 Cons",
    "crumbs": [
      "Sound Data",
      "<span class='chapter-number'>141</span>  <span class='chapter-title'>🏗️ Temporary</span>"
    ]
  },
  {
    "objectID": "sound-tmp.html#r-examples",
    "href": "sound-tmp.html#r-examples",
    "title": "141  🏗️ Temporary",
    "section": "141.3 R Examples",
    "text": "141.3 R Examples",
    "crumbs": [
      "Sound Data",
      "<span class='chapter-number'>141</span>  <span class='chapter-title'>🏗️ Temporary</span>"
    ]
  },
  {
    "objectID": "sound-tmp.html#python-examples",
    "href": "sound-tmp.html#python-examples",
    "title": "141  🏗️ Temporary",
    "section": "141.4 Python Examples",
    "text": "141.4 Python Examples",
    "crumbs": [
      "Sound Data",
      "<span class='chapter-number'>141</span>  <span class='chapter-title'>🏗️ Temporary</span>"
    ]
  },
  {
    "objectID": "order.html",
    "href": "order.html",
    "title": "142  🏗️ Order of transformations",
    "section": "",
    "text": "142.1 Order of transformations",
    "crumbs": [
      "<span class='chapter-number'>142</span>  <span class='chapter-title'>🏗️ Order of transformations</span>"
    ]
  },
  {
    "objectID": "sparse.html",
    "href": "sparse.html",
    "title": "143  🏗️ What should you do if you have sparse data?",
    "section": "",
    "text": "143.1 What should you do if you have sparse data?",
    "crumbs": [
      "<span class='chapter-number'>143</span>  <span class='chapter-title'>🏗️ What should you do if you have sparse data?</span>"
    ]
  },
  {
    "objectID": "models.html",
    "href": "models.html",
    "title": "144  🏗️ How Different Models Deal With Input",
    "section": "",
    "text": "144.1 How different Models Deal With Input",
    "crumbs": [
      "<span class='chapter-number'>144</span>  <span class='chapter-title'>🏗️ How Different Models Deal With Input</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "145  🏗️ Summary",
    "section": "",
    "text": "145.1 Summary",
    "crumbs": [
      "<span class='chapter-number'>145</span>  <span class='chapter-title'>🏗️ Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Buuren, S. van. 2012. Flexible Imputation of Missing Data.\nChapman & Hall/CRC Interdisciplinary Statistics. CRC Press. https://books.google.com/books?id=elDNBQAAQBAJ.\n\n\nGalli, S. 2020. Python Feature Engineering Cookbook: Over 70 Recipes\nfor Creating, Engineering, and Transforming Features to Build Machine\nLearning Models. Packt Publishing. https://books.google.com/books?id=2c_LDwAAQBAJ.\n\n\nGéron, Aurélien. 2017. Hands-on Machine Learning with Scikit-Learn\nand TensorFlow : Concepts, Tools, and Techniques to Build Intelligent\nSystems. Sebastopol, CA: O’Reilly Media.\n\n\nHonnibal, Matthew, Ines Montani, Sofie Van Landeghem, and Adriane Boyd.\n2020. “spaCy: Industrial-strength Natural\nLanguage Processing in Python.” https://doi.org/10.5281/zenodo.1212303.\n\n\nKuhn, M., and K. Johnson. 2013. Applied Predictive Modeling.\nSpringerLink : Bücher. Springer New York. https://books.google.com/books?id=xYRDAAAAQBAJ.\n\n\n———. 2019. Feature Engineering and Selection: A Practical Approach\nfor Predictive Models. Chapman & Hall/CRC Data Science Series.\nCRC Press. https://books.google.com/books?id=q5alDwAAQBAJ.\n\n\nKuhn, M., and J. Silge. 2022. Tidy Modeling with r. O’Reilly\nMedia. https://books.google.com/books?id=98J6EAAAQBAJ.\n\n\nMicci-Barreca, Daniele. 2001. “A Preprocessing Scheme for\nHigh-Cardinality Categorical Attributes in Classification and Prediction\nProblems.” SIGKDD Explor. Newsl. 3 (1): 27–32. https://doi.org/10.1145/507533.507538.\n\n\nOzdemir, S. 2022. Feature Engineering Bookcamp. Manning. https://books.google.com/books?id=3n6HEAAAQBAJ.\n\n\nPorter, Martin F. 1980. “An Algorithm for Suffix\nStripping.” Program 14 (3): 130–37. https://doi.org/10.1108/eb046814.\n\n\nRUBIN, DONALD B. 1976. “Inference and missing\ndata.” Biometrika 63 (3): 581–92. https://doi.org/10.1093/biomet/63.3.581.\n\n\nThakur, A. 2020. Approaching (Almost) Any Machine Learning\nProblem. Amazon Digital Services LLC - Kdp. https://books.google.com/books?id=ZbgAEAAAQBAJ.",
    "crumbs": [
      "References"
    ]
  }
]