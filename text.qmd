# Overview {#sec-text}

Sometimes you have fields that are free long form text. This cannot be dealt with using the methods we saw in @sec-categorical, as the natural text will have enough variation that counting the full text fields is not going to be fruitful. Imagine this fictitious short book reviews

- This book is excellent
- Best book I have read all year
- This book is absolutely excellent
- This book is far form excellent
- Not worth your time

On a character-level, these are all uniquely different. But to us English speakers, the first 3 are positive, and the last 2 are negative. We will in the upcoming chapters look at all the methods and their details, to see how we can modify and extract as much information out of this as we can.

We will adhere to the #BenderRule[^1] and make it clear that while the examples you will see in this book are going to be in English, it doesn't mean that the results you see can be replicated in other languages. All languages have unique things about them that makes these types calculations harder or easier to use.

[^1]: https://thegradient.pub/the-benderrule-on-naming-the-languages-we-study-and-why-it-matters/

In these chapters, we will be studying methods to work with text. Notably, text and language are different things, with many languages starting as spoken words, and smaller number of these develop a writing system. This is important to remember, as written text will almost always has lower information than the language it is transcribing. You have seen examples of this when you send a text message that wasn't received correctly, because of the missing non-verbal information.

Text data, like all other types of data, isn't guaranteed to contain information that help your modeling data at hand. This is especially true with shorter text fields, but can be true with just about anything. 

The types of operations you do to get text data into numeric data is various, but they can usually be split into a number of different tasks. You don't have to do everything in this list to get good results, and some off-the-shelf methods will sometimes combine 2 or more of these steps into one. This is another reason why it is important to read the documentation of the implementation you are using. 

There is also the possibility that you know exactly what type of information is important in your text field. In that case you will be better served by manually extract the information with regular expression or related text processing tools, we look at examples of that in @sec-text-manual.

## Text cleaning

In @sec-text-cleaning, we will look over the ways we take raw text and get it ready for later tasks. This work deals with encoding issues, standardization, cases and sometimes you need to get rid of a lot of unwanted chunks.

## Tokenization

Once the text is cleaned, we need to split it into a smaller unit of information such that we can count it, this is called tokenization and we will visit that in @sec-text-tokenization.

## Modifying tokens

Once you have the data as tokens, once of the things you might want to do is modifying them in various ways. This could things like changing the endings to words or changing the words entirely. We see examples of this in @sec-text-stemming, and @sec-text-ngrams.

## Filtering tokens

The tokens you are created might not all be of the same quality. Depending on your choice of tokenizer, there will be reasons for you to remove some of the tokens you have created. We see examples of this in @sec-text-stopwords and @sec-text-filter.

## Counting tokens

We have gotten to the end of the line and we are ready to turn the tokens into numeric variables we can use. There are many different ways are we look at them in @sec-text-tf, @sec-text-tfidf, @sec-text-hashing, @sec-text-onehot, and @sec-text-lda.

## Embeddings

Another way to use text is to work with embeddings, this is another powerful tool that can give you good performance. We look at some of them in @sec-text-word2vec and @sec-text-bert.
