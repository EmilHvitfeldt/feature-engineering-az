---
pagetitle: "Feature Engineering A-Z | Leaf Encoding"
---

# Leaf Encoding {#sec-categorical-leaf}

::: {style="visibility: hidden; height: 0px;"}
## Leaf Encoding
:::

Leaf encoding, also called **decision tree encoding**, is a method where a single decision tree fits using a target, typically the outcome, and a single categorical variable as the predictor. The encoding is then done by using the predictions of the tree to replace the categorical labels.

This should work in both classification and regression settings, but they serve different purposes. If used in a classification setting, we are replacing a categorial predictor with another categorical predictor with fewer levels. For regression settings, we have that the categorical predictor is replaced with a numeric variable. In some ways, this feels much like target encoding explored in @sec-categorical-target.

Suppose we use leaf encoding on the `MS_SubClass` predictor of the `ames` data set, using the numeric target `Sale_Price`. A possible fitted tree on that data would yield the following encoding table.

```{r}
#| echo: false
library(tidymodels)
set.seed(1234)

data(ames, package = "modeldata")

tree_spec <- decision_tree() |>
  set_mode("regression")

tree_fit <- fit(tree_spec, Sale_Price ~ MS_SubClass, data = ames)

res <- augment(tree_fit, distinct(ames, MS_SubClass)) |>
  rename(leaf = .pred) |>
  arrange(leaf)

knitr::kable(res)
```

This table has `r dplyr::n_distinct(res$leaf)` different values, meaning that the tree has 4 different leafs. Now prediction happens by using this lookup table.

Instead, let's see what happens if we choose a categorical target. Using the same `MS_SubClass` predictor, but instead using the categorical variable `Lot_Shape` as the target.

```{r}
#| echo: false
library(tidymodels)
set.seed(1234)

data(ames, package = "modeldata")

tree_spec <- decision_tree() |>
  set_mode("classification")

tree_fit <- fit(tree_spec, Lot_Shape ~ MS_SubClass, data = ames)

res <- augment(tree_fit, distinct(ames, MS_SubClass)) |>
  rename(leaf = .pred_class) |>
  arrange(leaf) |>
  select(leaf, MS_SubClass) |>
  mutate(leaf = paste0("leaf", as.integer(leaf)))

knitr::kable(res)
```

And we now have a mapping that takes `r length(res$MS_SubClass)` levels and compresses them into `n_distinct(res$leaf)` levels. We note two insights for the categorical target case. Firstly, the number of unique levels can't exceed the number of levels in the target. Because it is not possible to predict a level that doesn't exist for the target. Secondly, you will produce the same or fewer levels in your leaf. We saw earlier that it is possible to produce fewer. To produce the same about of levels, we would need a target with the same or more levels than the predictor and have each predictor level map to a different target level.

Since we are fitting a tree, it has the opportunity to be hyper-parameter-tuned, as the size and shape tree will affect the encoding. You will be fitting a different tree for each of the categorical variables you are encoding, and they likely won't have the same optimal tree size. Here you have to make a choice. Either meticulously tune each tree in the broader scope of the model, or use decent defaults. The latter choice is likely the best one.

Lastly, this method doesn't work with unseen levels as talked about in @sec-categorical-unseen, as decision trees generally don't have a way to handle unseen levels.

https://feature-engine.trainindata.com/en/1.7.x/user_guide/encoding/index.html#decision-tree-encoding


## Pros and Cons

### Pros

- Produces a single column.

### Cons

- Doesn't handle unseen levels.
- Can be unstable, due to using a decision tree.
- It may be overly simplistic.

## R Examples

To be implemented

## Python Examples

```{python}
#| echo: false
import pandas as pd
from sklearn import set_config

set_config(transform_output="pandas")
pd.set_option('display.precision', 3)
```

We are using the `ames` data set for examples.
{feature_engine} provided the `YeoJohnsonTransformer()` that we can use.

```{python}
from feazdata import ames
from sklearn.compose import ColumnTransformer
from feature_engine.encoding import DecisionTreeEncoder

ct = ColumnTransformer(
    [('treeEncoding', DecisionTreeEncoder(), ['MS_SubClass'])], 
    remainder="passthrough")

ct.fit(ames, y=ames[["Sale_Price"]].values.flatten())
ct.transform(ames).filter(regex="treeEncoding.*")
```